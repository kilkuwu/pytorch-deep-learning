{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kilkuwu/pytorch-deep-learning/blob/main/lessons/04/lesson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Tập dữ liệu tùy chỉnh trong PyTorch (PyTorch Custom Datasets)\n",
    "\n",
    "Trong notebook trước, [notebook 03](https://www.learnpytorch.io/03_pytorch_computer_vision/), chúng ta đã tìm hiểu cách xây dựng các mô hình thị giác máy tính (computer vision) trên một tập dữ liệu (dataset) có sẵn trong PyTorch (FashionMNIST).\n",
    "\n",
    "Các bước chúng ta đã thực hiện tương tự nhau trong nhiều vấn đề khác nhau của học máy (machine learning).\n",
    "\n",
    "Tìm một tập dữ liệu (dataset), chuyển đổi tập dữ liệu thành các con số, xây dựng một mô hình (model) (hoặc tìm một mô hình có sẵn) để tìm ra các mẫu (patterns) trong những con số đó có thể được sử dụng để dự đoán (prediction).\n",
    "\n",
    "PyTorch có nhiều tập dữ liệu (datasets) có sẵn được sử dụng cho một số lượng lớn các benchmark học máy (machine learning), tuy nhiên, bạn thường sẽ muốn sử dụng **tập dữ liệu tùy chỉnh (custom dataset)** của riêng mình."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tập dữ liệu tùy chỉnh (custom dataset) là gì?\n",
    "\n",
    "**Tập dữ liệu tùy chỉnh (custom dataset)** là một tập hợp dữ liệu liên quan đến một vấn đề cụ thể mà bạn đang làm việc.\n",
    "\n",
    "Về bản chất, một **tập dữ liệu tùy chỉnh (custom dataset)** có thể bao gồm hầu hết mọi thứ.\n",
    "\n",
    "Ví dụ, nếu chúng ta đang xây dựng một ứng dụng phân loại hình ảnh thực phẩm như [Nutrify](https://nutrify.app), tập dữ liệu tùy chỉnh (custom dataset) của chúng ta có thể là các hình ảnh thực phẩm.\n",
    "\n",
    "Hoặc nếu chúng ta đang cố gắng xây dựng một mô hình (model) để phân loại liệu một đánh giá dựa trên văn bản trên một trang web là tích cực hay tiêu cực, tập dữ liệu tùy chỉnh (custom dataset) của chúng ta có thể là các ví dụ về đánh giá của khách hàng hiện có và xếp hạng của họ.\n",
    "\n",
    "Hoặc nếu chúng ta đang cố gắng xây dựng một ứng dụng phân loại âm thanh, tập dữ liệu tùy chỉnh (custom dataset) của chúng ta có thể là các mẫu âm thanh cùng với nhãn mẫu (labels) của chúng.\n",
    "\n",
    "Hoặc nếu chúng ta đang cố gắng xây dựng một hệ thống gợi ý (recommendation system) cho khách hàng mua hàng trên trang web của chúng ta, tập dữ liệu tùy chỉnh (custom dataset) của chúng ta có thể là các ví dụ về sản phẩm mà người khác đã mua.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pytorch-domain-libraries.png\" alt=\"different pytorch domain libraries can be used for specific PyTorch problems\" width=1000/>\n",
    "\n",
    "*PyTorch bao gồm nhiều hàm (functions) có sẵn để tải các tập dữ liệu tùy chỉnh (custom datasets) khác nhau trong các thư viện miền (domain libraries) [`TorchVision`](https://pytorch.org/vision/stable/index.html), [`TorchText`](https://pytorch.org/text/stable/index.html), [`TorchAudio`](https://pytorch.org/audio/stable/index.html) và [`TorchRec`](https://pytorch.org/torchrec/).*\n",
    "\n",
    "Nhưng đôi khi những hàm (functions) có sẵn này có thể không đủ.\n",
    "\n",
    "Trong trường hợp đó, chúng ta luôn có thể tạo lớp con (subclass) của `torch.utils.data.Dataset` và tùy chỉnh nó theo ý thích của chúng ta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Những gì chúng ta sẽ tìm hiểu\n",
    "\n",
    "Chúng ta sẽ áp dụng Quy trình PyTorch (PyTorch Workflow) mà chúng ta đã tìm hiểu trong [notebook 01](https://www.learnpytorch.io/01_pytorch_workflow/) và [notebook 02](https://www.learnpytorch.io/02_pytorch_classification/) vào một vấn đề thị giác máy tính (computer vision).\n",
    "\n",
    "Nhưng thay vì sử dụng một tập dữ liệu (dataset) có sẵn trong PyTorch, chúng ta sẽ sử dụng tập dữ liệu (dataset) của riêng mình gồm các hình ảnh pizza, steak và sushi.\n",
    "\n",
    "Mục tiêu sẽ là tải các hình ảnh này và sau đó xây dựng một mô hình (model) để huấn luyện (train) và dự đoán (predict) trên chúng.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pytorch-food-vision-layout.png\" alt=\"building a pipeline to load in food images and then building a pytorch model to classify those food images\" width=800 />\n",
    "\n",
    "*Những gì chúng ta sẽ xây dựng. Chúng ta sẽ sử dụng `torchvision.datasets` cũng như lớp `Dataset` tùy chỉnh (custom) của riêng chúng ta để tải các hình ảnh thực phẩm và sau đó chúng ta sẽ xây dựng một mô hình thị giác máy tính (computer vision model) PyTorch để hy vọng có thể phân loại chúng.*\n",
    "\n",
    "Cụ thể, chúng ta sẽ tìm hiểu:\n",
    "\n",
    "| **Chủ đề (Topic)** | **Nội dung (Contents)** |\n",
    "| ----- | ----- |\n",
    "| **0. Import PyTorch và thiết lập mã không phụ thuộc thiết bị (device-agnostic code)** | Hãy tải PyTorch và sau đó tuân theo thực hành tốt nhất để thiết lập mã của chúng ta không phụ thuộc vào thiết bị (device-agnostic). |\n",
    "| **1. Lấy dữ liệu (Get data)** | Chúng ta sẽ sử dụng **tập dữ liệu tùy chỉnh (custom dataset)** của riêng mình gồm các hình ảnh pizza, steak và sushi. |\n",
    "| **2. Hiểu rõ dữ liệu (chuẩn bị dữ liệu - data preparation)** | Ở đầu của bất kỳ vấn đề học máy (machine learning) mới nào, điều quan trọng nhất là hiểu dữ liệu mà bạn đang làm việc. Ở đây chúng ta sẽ thực hiện một số bước để tìm hiểu dữ liệu mà chúng ta có. |\n",
    "| **3. Biến đổi dữ liệu (Transforming data)** | Thường thì, dữ liệu bạn nhận được sẽ không 100% sẵn sàng để sử dụng với một mô hình học máy (machine learning model), ở đây chúng ta sẽ xem xét một số bước chúng ta có thể thực hiện để *biến đổi (transform)* hình ảnh của chúng ta để chúng sẵn sàng được sử dụng với một mô hình (model). | \n",
    "| **4. Tải dữ liệu với `ImageFolder` (tùy chọn 1)** | PyTorch có nhiều hàm tải dữ liệu (data loading functions) có sẵn cho các loại dữ liệu phổ biến. `ImageFolder` hữu ích nếu hình ảnh của chúng ta ở định dạng phân loại hình ảnh tiêu chuẩn (standard image classification format). |\n",
    "| **5. Tải dữ liệu hình ảnh với `Dataset` tùy chỉnh (custom)** | Điều gì sẽ xảy ra nếu PyTorch không có hàm có sẵn (in-built function) để tải dữ liệu? Đây là nơi chúng ta có thể xây dựng lớp con tùy chỉnh (custom subclass) của riêng mình từ `torch.utils.data.Dataset`. |\n",
    "| **6. Các hình thức biến đổi khác (tăng cường dữ liệu - data augmentation)** | Tăng cường dữ liệu (data augmentation) là một kỹ thuật phổ biến để mở rộng tính đa dạng của dữ liệu huấn luyện (training data) của bạn. Ở đây chúng ta sẽ khám phá một số hàm tăng cường dữ liệu (data augmentation functions) có sẵn của `torchvision`. |\n",
    "| **7. Mô hình 0 (Model 0): TinyVGG không có tăng cường dữ liệu (data augmentation)** | Đến giai đoạn này, chúng ta sẽ có dữ liệu sẵn sàng, hãy xây dựng một mô hình (model) có khả năng khớp với nó. Chúng ta cũng sẽ tạo một số hàm huấn luyện (training functions) và kiểm tra (testing functions) để huấn luyện (train) và đánh giá (evaluate) mô hình (model) của chúng ta. |\n",
    "| **8. Khám phá đường cong mất mát (loss curves)** | Đường cong mất mát (loss curves) là một cách tuyệt vời để xem mô hình (model) của bạn đang huấn luyện (training)/cải thiện như thế nào theo thời gian. Chúng cũng là một cách tốt để xem liệu mô hình (model) của bạn có bị **thiếu khớp (underfitting)** hay **quá khớp (overfitting)** không. |\n",
    "| **9. Mô hình 1 (Model 1): TinyVGG với tăng cường dữ liệu (data augmentation)** | Bây giờ, chúng ta đã thử một mô hình (model) *không có*, còn thử một mô hình *có* tăng cường dữ liệu (data augmentation) thì sao? |\n",
    "| **10. So sánh kết quả mô hình (Compare model results)** | Hãy so sánh đường cong mất mát (loss curves) của các mô hình (models) khác nhau và xem mô hình nào hoạt động tốt hơn và thảo luận một số tùy chọn để cải thiện hiệu suất (performance). |\n",
    "| **11. Thực hiện dự đoán (prediction) trên hình ảnh tùy chỉnh (custom image)** | Mô hình (model) của chúng ta được huấn luyện (trained) trên một tập dữ liệu (dataset) gồm các hình ảnh pizza, steak và sushi. Trong phần này, chúng ta sẽ tìm hiểu cách sử dụng mô hình đã huấn luyện (trained model) của chúng ta để dự đoán (predict) trên một hình ảnh *bên ngoài* tập dữ liệu (dataset) hiện có của chúng ta. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import PyTorch và thiết lập mã không phụ thuộc thiết bị (device-agnostic code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Lưu ý: notebook này yêu cầu torch >= 1.10.0\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Và bây giờ hãy tuân theo thực hành tốt nhất và thiết lập mã không phụ thuộc thiết bị (device-agnostic code).\n",
    "\n",
    "> **Lưu ý:** Nếu bạn đang sử dụng Google Colab và chưa bật GPU, thì đây là lúc để bật nó qua `Runtime -> Change runtime type -> Hardware accelerator -> GPU`. Nếu bạn làm điều này, runtime của bạn có thể sẽ reset và bạn sẽ phải chạy lại tất cả các cell ở trên bằng cách chọn `Runtime -> Run before`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thiết lập mã không phụ thuộc thiết bị (device-agnostic code)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lấy dữ liệu (Get data)\n",
    "\n",
    "Trước tiên, chúng ta cần một số dữ liệu (data).\n",
    "\n",
    "Và giống như bất kỳ chương trình nấu ăn tốt nào, một số dữ liệu (data) đã được chuẩn bị sẵn cho chúng ta.\n",
    "\n",
    "Chúng ta sẽ bắt đầu từ nhỏ.\n",
    "\n",
    "Bởi vì chúng ta không muốn huấn luyện (train) mô hình (model) lớn nhất hoặc sử dụng tập dữ liệu (dataset) lớn nhất ngay từ đầu.\n",
    "\n",
    "Học máy (machine learning) là một quá trình lặp đi lặp lại, bắt đầu từ nhỏ, làm cho cái gì đó hoạt động và tăng lên khi cần thiết.\n",
    "\n",
    "Dữ liệu (data) mà chúng ta sẽ sử dụng là một tập con của [tập dữ liệu Food101 (Food101 dataset)](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/).\n",
    "\n",
    "Food101 là một benchmark thị giác máy tính (computer vision) phổ biến vì nó chứa 1000 hình ảnh của 101 loại thực phẩm khác nhau, tổng cộng 101,000 hình ảnh (75,750 hình ảnh huấn luyện - train và 25,250 hình ảnh kiểm tra - test).\n",
    "\n",
    "Bạn có thể nghĩ ra 101 loại thực phẩm khác nhau không?\n",
    "\n",
    "Bạn có thể nghĩ ra một chương trình máy tính để phân loại 101 loại thực phẩm không?\n",
    "\n",
    "Tôi có thể.\n",
    "\n",
    "Một mô hình học máy (machine learning model)! \n",
    "\n",
    "Cụ thể, một mô hình thị giác máy tính (computer vision model) PyTorch như chúng ta đã tìm hiểu trong [notebook 03](https://www.learnpytorch.io/03_pytorch_computer_vision/).\n",
    "\n",
    "Tuy nhiên, thay vì 101 lớp thực phẩm (food classes), chúng ta sẽ bắt đầu với 3 lớp: pizza, steak và sushi.\n",
    "\n",
    "Và thay vì 1,000 hình ảnh cho mỗi lớp (class), chúng ta sẽ bắt đầu với 10% ngẫu nhiên (bắt đầu từ nhỏ, tăng lên khi cần thiết).\n",
    "\n",
    "Nếu bạn muốn xem dữ liệu (data) đến từ đâu, bạn có thể xem các tài nguyên sau:\n",
    "* [Trang web tập dữ liệu và bài báo Food101 gốc (Original Food101 dataset and paper website)](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/).\n",
    "* [`torchvision.datasets.Food101`](https://pytorch.org/vision/main/generated/torchvision.datasets.Food101.html) - phiên bản dữ liệu (data) mà tôi đã tải xuống cho notebook này.\n",
    "* [`extras/04_custom_data_creation.ipynb`](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb) - một notebook mà tôi đã sử dụng để định dạng tập dữ liệu Food101 (Food101 dataset) để sử dụng cho notebook này.\n",
    "* [`data/pizza_steak_sushi.zip`](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi.zip) - tệp nén (zip archive) của các hình ảnh pizza, steak và sushi từ Food101, được tạo bằng notebook được liên kết ở trên.\n",
    "\n",
    "Hãy viết một số mã (code) để tải xuống dữ liệu (data) đã được định dạng từ GitHub.\n",
    "\n",
    "> **Lưu ý:** Tập dữ liệu (dataset) mà chúng ta sắp sử dụng đã được định dạng trước cho những gì chúng ta muốn sử dụng. Tuy nhiên, bạn thường sẽ phải định dạng tập dữ liệu (datasets) của riêng mình cho bất kỳ vấn đề nào bạn đang làm việc. Đây là một thực hành thường xuyên trong thế giới học máy (machine learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Thiết lập đường dẫn đến thư mục dữ liệu (data folder)\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "# Nếu thư mục hình ảnh không tồn tại, tải xuống và chuẩn bị nó... \n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory exists.\")\n",
    "else:\n",
    "    print(f\"Did not find {image_path} directory, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Tải xuống dữ liệu pizza, steak, sushi\n",
    "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "        print(\"Downloading pizza, steak, sushi data...\")\n",
    "        f.write(request.content)\n",
    "\n",
    "    # Giải nén dữ liệu pizza, steak, sushi\n",
    "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "        print(\"Unzipping pizza, steak, sushi data...\") \n",
    "        zip_ref.extractall(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hiểu rõ dữ liệu (chuẩn bị dữ liệu - data preparation)\n",
    "\n",
    "Tập dữ liệu (dataset) đã được tải xuống!\n",
    "\n",
    "Đã đến lúc hiểu rõ nó.\n",
    "\n",
    "Đây là một bước quan trọng khác trước khi xây dựng một mô hình (model).\n",
    "\n",
    "Như Abraham Lossfunction đã nói...\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-abraham-lossfunction.png\" alt=\"tweet by mrdbourke, if I had eight hours to build a machine learning model, I'd spend the first 6 hours preparing my dataset\" width=800/>\n",
    "\n",
    "*Chuẩn bị dữ liệu (data preparation) là tối quan trọng. Trước khi xây dựng một mô hình (model), hãy hiểu rõ dữ liệu (data). Hãy tự hỏi: Tôi đang cố gắng làm gì ở đây? Nguồn: [@mrdbourke Twitter](https://twitter.com/mrdbourke).*\n",
    "\n",
    "Việc kiểm tra dữ liệu (data) và hiểu rõ nó là gì? \n",
    "\n",
    "Trước khi bắt đầu một dự án hoặc xây dựng bất kỳ loại mô hình (model) nào, điều quan trọng là phải biết bạn đang làm việc với dữ liệu (data) gì.\n",
    "\n",
    "Trong trường hợp của chúng ta, chúng ta có các hình ảnh pizza, steak và sushi ở định dạng phân loại hình ảnh tiêu chuẩn (standard image classification format).\n",
    "\n",
    "Định dạng phân loại hình ảnh (image classification format) chứa các lớp hình ảnh (classes of images) riêng biệt trong các thư mục riêng biệt được đặt tên với tên lớp (class name) cụ thể.\n",
    "\n",
    "Ví dụ, tất cả các hình ảnh của `pizza` được chứa trong thư mục `pizza/`.\n",
    "\n",
    "Định dạng này phổ biến trên nhiều benchmark phân loại hình ảnh (image classification benchmarks) khác nhau, bao gồm [ImageNet](https://www.image-net.org/) (một trong những tập dữ liệu benchmark thị giác máy tính - computer vision benchmark datasets phổ biến nhất).\n",
    "\n",
    "Bạn có thể xem một ví dụ về định dạng lưu trữ bên dưới, các số hình ảnh là tùy ý.\n",
    "\n",
    "```\n",
    "pizza_steak_sushi/ <- thư mục tập dữ liệu tổng thể (overall dataset folder)\n",
    "    train/ <- hình ảnh huấn luyện (training images)\n",
    "        pizza/ <- tên lớp làm tên thư mục (class name as folder name)\n",
    "            image01.jpeg\n",
    "            image02.jpeg\n",
    "            ...\n",
    "        steak/\n",
    "            image24.jpeg\n",
    "            image25.jpeg\n",
    "            ...\n",
    "        sushi/\n",
    "            image37.jpeg\n",
    "            ...\n",
    "    test/ <- hình ảnh kiểm tra (testing images)\n",
    "        pizza/\n",
    "            image101.jpeg\n",
    "            image102.jpeg\n",
    "            ...\n",
    "        steak/\n",
    "            image154.jpeg\n",
    "            image155.jpeg\n",
    "            ...\n",
    "        sushi/\n",
    "            image167.jpeg\n",
    "            ...\n",
    "```\n",
    "\n",
    "Mục tiêu sẽ là **lấy cấu trúc lưu trữ dữ liệu (data storage structure) này và biến nó thành một tập dữ liệu (dataset) có thể sử dụng được với PyTorch**.\n",
    "\n",
    "> **Lưu ý:** Cấu trúc của dữ liệu (data) mà bạn làm việc sẽ khác nhau tùy thuộc vào vấn đề bạn đang làm việc. Nhưng tiền đề vẫn còn: hiểu rõ dữ liệu (data), sau đó tìm cách tốt nhất để biến nó thành một tập dữ liệu (dataset) tương thích với PyTorch.\n",
    "\n",
    "Chúng ta có thể kiểm tra những gì có trong thư mục dữ liệu (data directory) của chúng ta bằng cách viết một hàm trợ giúp nhỏ (helper function) để duyệt qua từng thư mục con và đếm các tệp hiện có.\n",
    "\n",
    "Để làm điều đó, chúng ta sẽ sử dụng [`os.walk()`](https://docs.python.org/3/library/os.html#os.walk) có sẵn của Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def walk_through_dir(dir_path):\n",
    "  \"\"\"\n",
    "  Duyệt qua dir_path trả về nội dung của nó.\n",
    "  Args:\n",
    "    dir_path (str or pathlib.Path): thư mục đích (target directory)\n",
    "  \n",
    "  Returns:\n",
    "    In ra:\n",
    "      số lượng thư mục con trong dir_path\n",
    "      số lượng hình ảnh (files) trong mỗi thư mục con\n",
    "      tên của mỗi thư mục con\n",
    "  \"\"\"\n",
    "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_through_dir(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuyệt vời!\n",
    "\n",
    "Có vẻ như chúng ta có khoảng 75 hình ảnh cho mỗi lớp huấn luyện (training class) và 25 hình ảnh cho mỗi lớp kiểm tra (testing class).\n",
    "\n",
    "Điều đó sẽ đủ để bắt đầu.\n",
    "\n",
    "Hãy nhớ rằng, những hình ảnh này là tập con của tập dữ liệu Food101 gốc (original Food101 dataset).\n",
    "\n",
    "Bạn có thể xem cách chúng được tạo ra trong [notebook tạo dữ liệu (data creation notebook)](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb).\n",
    "\n",
    "Trong khi chúng ta đang làm điều này, hãy thiết lập các đường dẫn huấn luyện (training) và kiểm tra (testing) của chúng ta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thiết lập đường dẫn huấn luyện (training) và kiểm tra (testing)\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Trực quan hóa một hình ảnh (Visualize an image)\n",
    "\n",
    "Được rồi, chúng ta đã thấy cấu trúc thư mục của chúng ta được định dạng như thế nào.\n",
    "\n",
    "Bây giờ theo tinh thần của nhà khám phá dữ liệu (data explorer), đã đến lúc *trực quan hóa, trực quan hóa, trực quan hóa!*\n",
    "\n",
    "Hãy viết một số mã (code) để:\n",
    "1. Lấy tất cả các đường dẫn hình ảnh bằng cách sử dụng [`pathlib.Path.glob()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.glob) để tìm tất cả các tệp kết thúc bằng `.jpg`. \n",
    "2. Chọn một đường dẫn hình ảnh ngẫu nhiên bằng cách sử dụng [`random.choice()`](https://docs.python.org/3/library/random.html#random.choice) của Python.\n",
    "3. Lấy tên lớp hình ảnh (image class name) bằng cách sử dụng [`pathlib.Path.parent.stem`](https://docs.python.org/3/library/pathlib.html#pathlib.PurePath.parent).\n",
    "4. Và vì chúng ta đang làm việc với hình ảnh, chúng ta sẽ mở đường dẫn hình ảnh ngẫu nhiên bằng cách sử dụng [`PIL.Image.open()`](https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.open) (PIL là viết tắt của Python Image Library).\n",
    "5. Sau đó chúng ta sẽ hiển thị hình ảnh và in một số metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Thiết lập seed\n",
    "random.seed(42) # <- thử thay đổi cái này và xem điều gì sẽ xảy ra\n",
    "\n",
    "# 1. Lấy tất cả đường dẫn hình ảnh (* có nghĩa là \"bất kỳ tổ hợp nào\")\n",
    "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
    "\n",
    "# 2. Lấy đường dẫn hình ảnh ngẫu nhiên\n",
    "random_image_path = random.choice(image_path_list)\n",
    "\n",
    "# 3. Lấy lớp hình ảnh từ tên đường dẫn (lớp hình ảnh là tên của thư mục nơi hình ảnh được lưu trữ)\n",
    "image_class = random_image_path.parent.stem\n",
    "\n",
    "# 4. Mở hình ảnh\n",
    "img = Image.open(random_image_path)\n",
    "\n",
    "# 5. In metadata\n",
    "print(f\"Random image path: {random_image_path}\")\n",
    "print(f\"Image class: {image_class}\")\n",
    "print(f\"Image height: {img.height}\") \n",
    "print(f\"Image width: {img.width}\")\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta có thể làm tương tự với [`matplotlib.pyplot.imshow()`](https://matplotlib.org/3.5.0/api/_as_gen/matplotlib.pyplot.imshow.html), ngoại trừ việc chúng ta phải chuyển đổi hình ảnh thành mảng NumPy trước."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Chuyển hình ảnh thành một mảng (array)\n",
    "img_as_array = np.asarray(img)\n",
    "\n",
    "# Vẽ hình ảnh với matplotlib\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(img_as_array)\n",
    "plt.title(f\"Image class: {image_class} | Image shape: {img_as_array.shape} -> [height, width, color_channels]\")\n",
    "plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Biến đổi dữ liệu (Transforming data)\n",
    "\n",
    "Bây giờ nếu chúng ta muốn tải dữ liệu hình ảnh (image data) của chúng ta vào PyTorch thì sao?\n",
    "\n",
    "Trước khi chúng ta có thể sử dụng dữ liệu hình ảnh (image data) của mình với PyTorch, chúng ta cần:\n",
    "\n",
    "1. Biến nó thành tensor (biểu diễn số học của hình ảnh của chúng ta).\n",
    "2. Biến nó thành `torch.utils.data.Dataset` và sau đó thành `torch.utils.data.DataLoader`, chúng ta sẽ gọi chúng là `Dataset` và `DataLoader` cho ngắn gọn.\n",
    "\n",
    "Có một số loại tập dữ liệu (datasets) và trình tải tập dữ liệu (dataset loaders) được xây dựng sẵn khác nhau cho PyTorch, tùy thuộc vào vấn đề bạn đang làm việc.\n",
    "\n",
    "| **Không gian vấn đề (Problem space)** | **Tập dữ liệu và hàm được xây dựng sẵn (Pre-built Datasets and Functions)** |\n",
    "| ----- | ----- |\n",
    "| **Thị giác (Vision)** | [`torchvision.datasets`](https://pytorch.org/vision/stable/datasets.html) |\n",
    "| **Âm thanh (Audio)** | [`torchaudio.datasets`](https://pytorch.org/audio/stable/datasets.html) |\n",
    "| **Văn bản (Text)** | [`torchtext.datasets`](https://pytorch.org/text/stable/datasets.html) |\n",
    "| **Hệ thống gợi ý (Recommendation system)** | [`torchrec.datasets`](https://pytorch.org/torchrec/torchrec.datasets.html) |\n",
    "\n",
    "Vì chúng ta đang làm việc với một vấn đề thị giác (vision problem), chúng ta sẽ xem xét `torchvision.datasets` cho các hàm tải dữ liệu (data loading functions) của chúng ta cũng như [`torchvision.transforms`](https://pytorch.org/vision/stable/transforms.html) để chuẩn bị dữ liệu (data) của chúng ta.\n",
    "\n",
    "Hãy import một số thư viện cơ bản."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1 Biến đổi dữ liệu với `torchvision.transforms`\n",
    "\n",
    "Chúng ta có các thư mục hình ảnh nhưng trước khi chúng ta có thể sử dụng chúng với PyTorch, chúng ta cần chuyển đổi chúng thành tensor.\n",
    "\n",
    "Một trong những cách chúng ta có thể làm điều này là bằng cách sử dụng module `torchvision.transforms`.\n",
    "\n",
    "`torchvision.transforms` chứa nhiều phương thức được xây dựng sẵn để định dạng hình ảnh, biến chúng thành tensor và thậm chí thao tác chúng cho mục đích **tăng cường dữ liệu (data augmentation)** (thực hành thay đổi dữ liệu để làm cho việc học của mô hình (model) khó khăn hơn, chúng ta sẽ thấy điều này sau).\n",
    "\n",
    "Để có kinh nghiệm với `torchvision.transforms`, hãy viết một loạt các bước biến đổi (transform steps) để:\n",
    "1. Thay đổi kích thước hình ảnh bằng cách sử dụng [`transforms.Resize()`](https://pytorch.org/vision/stable/generated/torchvision.transforms.Resize.html#torchvision.transforms.Resize) (từ khoảng 512x512 đến 64x64, cùng hình dạng với các hình ảnh trên [trang web CNN Explainer](https://poloclub.github.io/cnn-explainer/)).\n",
    "2. Lật hình ảnh của chúng ta một cách ngẫu nhiên theo chiều ngang bằng cách sử dụng [`transforms.RandomHorizontalFlip()`](https://pytorch.org/vision/stable/generated/torchvision.transforms.RandomHorizontalFlip.html#torchvision.transforms.RandomHorizontalFlip) (điều này có thể được coi là một hình thức tăng cường dữ liệu - data augmentation vì nó sẽ thay đổi dữ liệu hình ảnh (image data) của chúng ta một cách nhân tạo).\n",
    "3. Biến hình ảnh của chúng ta từ hình ảnh PIL thành tensor PyTorch bằng cách sử dụng [`transforms.ToTensor()`](https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor).\n",
    "\n",
    "Chúng ta có thể biên dịch tất cả các bước này bằng cách sử dụng [`torchvision.transforms.Compose()`](https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết transform cho hình ảnh\n",
    "data_transform = transforms.Compose([\n",
    "    # Thay đổi kích thước hình ảnh thành 64x64\n",
    "    transforms.Resize(size=(64, 64)),\n",
    "    # Lật hình ảnh ngẫu nhiên theo chiều ngang\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # p = xác suất lật, 0.5 = 50% cơ hội\n",
    "    # Biến hình ảnh thành torch.Tensor\n",
    "    transforms.ToTensor() # điều này cũng chuyển đổi tất cả giá trị pixel từ 0 đến 255 thành giữa 0.0 và 1.0 \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ chúng ta đã có một tập hợp các biến đổi (composition of transforms), hãy viết một hàm (function) để thử chúng trên nhiều hình ảnh khác nhau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transformed_images(image_paths, transform, n=3, seed=42):\n",
    "    \"\"\"Vẽ một loạt hình ảnh ngẫu nhiên từ image_paths.\n",
    "\n",
    "    Sẽ mở n đường dẫn hình ảnh từ image_paths, biến đổi chúng\n",
    "    với transform và vẽ chúng cạnh nhau.\n",
    "\n",
    "    Args:\n",
    "        image_paths (list): Danh sách các đường dẫn hình ảnh đích. \n",
    "        transform (PyTorch Transforms): Các biến đổi để áp dụng cho hình ảnh.\n",
    "        n (int, optional): Số lượng hình ảnh để vẽ. Mặc định là 3.\n",
    "        seed (int, optional): Seed ngẫu nhiên cho bộ tạo ngẫu nhiên. Mặc định là 42.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    random_image_paths = random.sample(image_paths, k=n)\n",
    "    for image_path in random_image_paths:\n",
    "        with Image.open(image_path) as f:\n",
    "            fig, ax = plt.subplots(1, 2)\n",
    "            ax[0].imshow(f) \n",
    "            ax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
    "            ax[0].axis(\"off\")\n",
    "\n",
    "            # Biến đổi và vẽ hình ảnh\n",
    "            # Lưu ý: permute() sẽ thay đổi hình dạng của hình ảnh để phù hợp với matplotlib \n",
    "            # (Mặc định của PyTorch là [C, H, W] nhưng Matplotlib là [H, W, C])\n",
    "            transformed_image = transform(f).permute(1, 2, 0) \n",
    "            ax[1].imshow(transformed_image) \n",
    "            ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
    "            ax[1].axis(\"off\")\n",
    "\n",
    "            fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16)\n",
    "\n",
    "plot_transformed_images(image_path_list, \n",
    "                        transform=data_transform, \n",
    "                        n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuyệt vời!\n",
    "\n",
    "Bây giờ chúng ta đã có một cách để chuyển đổi hình ảnh của chúng ta thành tensor bằng cách sử dụng `torchvision.transforms`.\n",
    "\n",
    "Chúng ta cũng thao tác kích thước và hướng của chúng nếu cần (một số mô hình - models thích hình ảnh có kích thước và hình dạng khác nhau).\n",
    "\n",
    "Nói chung, hình dạng (shape) của hình ảnh càng lớn, mô hình (model) càng có thể khôi phục nhiều thông tin hơn.\n",
    "\n",
    "Ví dụ, một hình ảnh có kích thước `[256, 256, 3]` sẽ có nhiều pixel gấp 16 lần so với hình ảnh có kích thước `[64, 64, 3]` (`(256*256*3)/(64*64*3)=16`).\n",
    "\n",
    "Tuy nhiên, sự đánh đổi (tradeoff) là nhiều pixel hơn đòi hỏi nhiều tính toán (computations) hơn.\n",
    "\n",
    "> **Bài tập (Exercise):** Thử comment out một trong các transform trong `data_transform` và chạy lại hàm vẽ `plot_transformed_images()`, điều gì sẽ xảy ra?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Tùy chọn 1 (Option 1): Tải dữ liệu hình ảnh bằng [`ImageFolder`](https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html#torchvision.datasets.ImageFolder)\n",
    "\n",
    "Được rồi, đã đến lúc biến dữ liệu hình ảnh (image data) của chúng ta thành một `Dataset` có khả năng được sử dụng với PyTorch.\n",
    "\n",
    "Vì dữ liệu (data) của chúng ta ở định dạng phân loại hình ảnh tiêu chuẩn (standard image classification format), chúng ta có thể sử dụng lớp (class) [`torchvision.datasets.ImageFolder`](https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html#torchvision.datasets.ImageFolder).\n",
    "\n",
    "Ở đây chúng ta có thể truyền cho nó đường dẫn tệp của thư mục hình ảnh đích (target image directory) cũng như một loạt các biến đổi (transforms) mà chúng ta muốn thực hiện trên hình ảnh của mình.\n",
    "\n",
    "Hãy thử nghiệm nó trên các thư mục dữ liệu (data folders) `train_dir` và `test_dir` của chúng ta, truyền vào `transform=data_transform` để biến hình ảnh của chúng ta thành tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sử dụng ImageFolder để tạo dataset(s)\n",
    "from torchvision import datasets\n",
    "train_data = datasets.ImageFolder(root=train_dir, # thư mục đích của hình ảnh\n",
    "                                  transform=data_transform, # các biến đổi để thực hiện trên dữ liệu (hình ảnh)\n",
    "                                  target_transform=None) # các biến đổi để thực hiện trên nhãn (nếu cần thiết)\n",
    "\n",
    "test_data = datasets.ImageFolder(root=test_dir, \n",
    "                                 transform=data_transform)\n",
    "\n",
    "print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuyệt vời!\n",
    "\n",
    "Có vẻ như PyTorch đã đăng ký `Dataset` của chúng ta.\n",
    "\n",
    "Hãy kiểm tra chúng bằng cách xem các thuộc tính `classes` và `class_to_idx` cũng như độ dài của các tập huấn luyện (training sets) và kiểm tra (test sets) của chúng ta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy tên các lớp (class names) dưới dạng danh sách (list)\n",
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cũng có thể lấy tên các lớp (class names) dưới dạng từ điển (dict)\n",
    "class_dict = train_data.class_to_idx\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra độ dài (lengths)\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuyệt! Có vẻ như chúng ta sẽ có thể sử dụng những thứ này để tham chiếu sau này.\n",
    "\n",
    "Còn hình ảnh và nhãn (labels) của chúng ta thì sao?\n",
    "\n",
    "Chúng trông như thế nào?\n",
    "\n",
    "Chúng ta có thể lập chỉ mục (index) trên `Dataset` `train_data` và `test_data` của chúng ta để tìm các mẫu (samples) và nhãn đích (target labels) của chúng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_data[0][0], train_data[0][1]\n",
    "print(f\"Image tensor:\\n{img}\")\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Image datatype: {img.dtype}\")\n",
    "print(f\"Image label: {label}\")\n",
    "print(f\"Label datatype: {type(label)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hình ảnh của chúng ta hiện đang ở dạng tensor (với hình dạng - shape `[3, 64, 64]`) và các nhãn (labels) ở dạng số nguyên liên quan đến một lớp (class) cụ thể (như được tham chiếu bởi thuộc tính `class_to_idx`).\n",
    "\n",
    "Còn việc vẽ một tensor hình ảnh đơn lẻ bằng `matplotlib` thì sao?\n",
    "\n",
    "Đầu tiên chúng ta sẽ phải permute (sắp xếp lại thứ tự các chiều của nó) để nó tương thích.\n",
    "\n",
    "Hiện tại các chiều hình ảnh (image dimensions) của chúng ta đang ở định dạng `CHW` (color channels, height, width) nhưng `matplotlib` thích `HWC` (height, width, color channels) hơn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sắp xếp lại thứ tự các chiều (dimensions)\n",
    "img_permute = img.permute(1, 2, 0)\n",
    "\n",
    "# In ra các hình dạng khác nhau (trước và sau permute)\n",
    "print(f\"Original shape: {img.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Image permute shape: {img_permute.shape} -> [height, width, color_channels]\")\n",
    "\n",
    "# Vẽ hình ảnh\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.axis(\"off\")\n",
    "plt.title(class_names[label], fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu ý rằng hình ảnh hiện tại bị pixelated hơn (chất lượng thấp hơn).\n",
    "\n",
    "Điều này là do nó được thay đổi kích thước từ `512x512` xuống `64x64` pixel.\n",
    "\n",
    "Trực giác ở đây là nếu bạn nghĩ rằng hình ảnh khó nhận ra hơn những gì đang diễn ra, thì rất có thể một mô hình (model) cũng sẽ khó hiểu hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Biến các hình ảnh đã tải thành `DataLoader`\n",
    "\n",
    "Chúng ta đã có hình ảnh dưới dạng `Dataset` của PyTorch nhưng bây giờ hãy biến chúng thành `DataLoader`.\n",
    "\n",
    "Chúng ta sẽ làm như vậy bằng cách sử dụng [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader).\n",
    "\n",
    "Biến `Dataset` của chúng ta thành `DataLoader` làm cho chúng có thể lặp lại (iterable) để một mô hình (model) có thể đi qua và học các mối quan hệ giữa các mẫu (samples) và đích (targets) (các đặc trưng - features và nhãn - labels).\n",
    "\n",
    "Để giữ mọi thứ đơn giản, chúng ta sẽ sử dụng `batch_size=1` và `num_workers=1`.\n",
    "\n",
    "`num_workers` là gì?\n",
    "\n",
    "Câu hỏi hay.\n",
    "\n",
    "Nó định nghĩa có bao nhiêu tiến trình con (subprocesses) sẽ được tạo để tải dữ liệu (data) của bạn.\n",
    "\n",
    "Hãy nghĩ về nó như thế này, giá trị `num_workers` được đặt càng cao, PyTorch sẽ sử dụng càng nhiều sức mạnh tính toán (compute power) để tải dữ liệu (data) của bạn.\n",
    "\n",
    "Cá nhân tôi, tôi thường đặt nó bằng tổng số CPU trên máy của tôi thông qua [`os.cpu_count()`](https://docs.python.org/3/library/os.html#os.cpu_count) của Python.\n",
    "\n",
    "Điều này đảm bảo `DataLoader` tuyển dụng càng nhiều lõi (cores) càng tốt để tải dữ liệu (data).\n",
    "\n",
    "> **Lưu ý:** Có nhiều tham số (parameters) hơn mà bạn có thể làm quen khi sử dụng `torch.utils.data.DataLoader` trong [tài liệu PyTorch](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biến Dataset huấn luyện (train) và kiểm tra (test) thành DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(dataset=train_data, \n",
    "                              batch_size=1, # bao nhiêu mẫu (samples) mỗi batch?\n",
    "                              num_workers=1, # bao nhiêu tiến trình con (subprocesses) để sử dụng cho việc tải dữ liệu? (cao hơn = nhiều hơn)\n",
    "                              shuffle=True) # xáo trộn dữ liệu (shuffle the data)?\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data, \n",
    "                             batch_size=1, \n",
    "                             num_workers=1, \n",
    "                             shuffle=False) # thường không cần xáo trộn dữ liệu kiểm tra (testing data)\n",
    "\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuyệt vời!\n",
    "\n",
    "Bây giờ dữ liệu (data) của chúng ta có thể lặp lại (iterable).\n",
    "\n",
    "Hãy thử nó và kiểm tra các hình dạng (shapes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = next(iter(train_dataloader))\n",
    "\n",
    "# Kích thước batch (batch size) bây giờ sẽ là 1, thử thay đổi tham số batch_size ở trên và xem điều gì sẽ xảy ra\n",
    "print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n",
    "print(f\"Label shape: {label.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ chúng ta có thể sử dụng những `DataLoader` này với vòng lặp huấn luyện (training) và kiểm tra (testing) để huấn luyện (train) một mô hình (model).\n",
    "\n",
    "Nhưng trước khi chúng ta làm điều đó, hãy xem một tùy chọn khác để tải hình ảnh (hoặc hầu hết bất kỳ loại dữ liệu nào khác)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tùy chọn 2 (Option 2): Tải dữ liệu hình ảnh với `Dataset` tùy chỉnh (Custom Dataset)\n",
    "\n",
    "Điều gì sẽ xảy ra nếu một trình tạo `Dataset` được xây dựng sẵn như [`torchvision.datasets.ImageFolder()`](https://pytorch.org/vision/stable/datasets.html#torchvision.datasets.ImageFolder) không tồn tại?\n",
    "\n",
    "Hoặc một cái dành cho vấn đề cụ thể của bạn không tồn tại?\n",
    "\n",
    "Vâng, bạn có thể xây dựng của riêng mình.\n",
    "\n",
    "Nhưng chờ đã, ưu và nhược điểm của việc tạo cách tùy chỉnh (custom) của riêng bạn để tải `Dataset` là gì?\n",
    "\n",
    "| Ưu điểm của việc tạo `Dataset` tùy chỉnh (custom) | Nhược điểm của việc tạo `Dataset` tùy chỉnh (custom) |\n",
    "| ----- | ----- |\n",
    "| Có thể tạo `Dataset` từ hầu hết mọi thứ. | Mặc dù bạn *có thể* tạo `Dataset` từ hầu hết mọi thứ, điều đó không có nghĩa là nó sẽ hoạt động. | \n",
    "| Không bị giới hạn bởi các hàm `Dataset` được xây dựng sẵn của PyTorch. | Sử dụng `Dataset` tùy chỉnh (custom) thường dẫn đến việc viết nhiều mã (code) hơn, có thể dễ gặp lỗi hoặc vấn đề về hiệu suất (performance). |\n",
    "\n",
    "Để thấy điều này trong hành động, hãy làm việc hướng tới việc sao chép `torchvision.datasets.ImageFolder()` bằng cách tạo lớp con (subclassing) `torch.utils.data.Dataset` (lớp cơ sở - base class cho tất cả `Dataset` trong PyTorch). \n",
    "\n",
    "Chúng ta sẽ bắt đầu bằng cách import các module chúng ta cần:\n",
    "* `os` của Python để xử lý các thư mục (dữ liệu của chúng ta được lưu trữ trong các thư mục).\n",
    "* `pathlib` của Python để xử lý các đường dẫn tệp (mỗi hình ảnh của chúng ta có một đường dẫn tệp duy nhất).\n",
    "* `torch` cho tất cả mọi thứ của PyTorch.\n",
    "* Lớp `Image` của PIL để tải hình ảnh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from typing import Tuple, Dict, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bạn có nhớ các thể hiện (instances) của `torchvision.datasets.ImageFolder()` của chúng ta đã cho phép chúng ta sử dụng các thuộc tính `classes` và `class_to_idx` không?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thể hiện (Instance) của torchvision.datasets.ImageFolder()\n",
    "train_data.classes, train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Tạo hàm trợ giúp (helper function) để lấy tên các lớp (class names)\n",
    "\n",
    "Hãy viết một hàm trợ giúp (helper function) có khả năng tạo danh sách tên các lớp (class names) và một từ điển (dictionary) gồm tên các lớp (class names) và chỉ số (indexes) của chúng được cung cấp một đường dẫn thư mục.\n",
    "\n",
    "Để làm điều đó, chúng ta sẽ:\n",
    "1. Lấy tên các lớp (class names) bằng cách sử dụng `os.scandir()` để duyệt qua thư mục đích (lý tưởng nhất là thư mục ở định dạng phân loại hình ảnh tiêu chuẩn).\n",
    "2. Đưa ra lỗi nếu không tìm thấy tên các lớp (class names) (nếu điều này xảy ra, có thể có gì đó không ổn với cấu trúc thư mục).\n",
    "3. Biến tên các lớp (class names) thành một từ điển (dictionary) của các nhãn số (numerical labels), một cho mỗi lớp (class).\n",
    "\n",
    "Hãy xem một ví dụ nhỏ của bước 1 trước khi chúng ta viết hàm đầy đủ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thiết lập đường dẫn cho thư mục đích (target directory)\n",
    "target_directory = train_dir\n",
    "print(f\"Target directory: {target_directory}\")\n",
    "\n",
    "# Lấy tên các lớp (class names) từ thư mục đích (target directory)\n",
    "class_names_found = sorted([entry.name for entry in list(os.scandir(image_path / \"train\"))])\n",
    "print(f\"Class names found: {class_names_found}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuyệt vời!\n",
    "\n",
    "Còn việc biến nó thành một hàm (function) đầy đủ thì sao?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo hàm để tìm các lớp (classes) trong thư mục đích (target directory)\n",
    "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "    \"\"\"Tìm tên các thư mục lớp (class folder names) trong thư mục đích (target directory).\n",
    "    \n",
    "    Giả định thư mục đích (target directory) ở định dạng phân loại hình ảnh tiêu chuẩn.\n",
    "\n",
    "    Args:\n",
    "        directory (str): thư mục đích để tải tên các lớp (classnames) từ đó.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], Dict[str, int]]: (list_of_class_names, dict(class_name: idx...))\n",
    "    \n",
    "    Example:\n",
    "        find_classes(\"food_images/train\")\n",
    "        >>> ([\"class_1\", \"class_2\"], {\"class_1\": 0, ...})\n",
    "    \"\"\"\n",
    "    # 1. Lấy tên các lớp (class names) bằng cách quét thư mục đích (target directory)\n",
    "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "    \n",
    "    # 2. Đưa ra lỗi nếu không tìm thấy tên các lớp (class names)\n",
    "    if not classes:\n",
    "        raise FileNotFoundError(f\"Couldn't find any classes in {directory}.\")\n",
    "        \n",
    "    # 3. Tạo một từ điển (dictionary) của các nhãn chỉ số (index labels) (máy tính thích nhãn số hơn nhãn chuỗi)\n",
    "    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "    return classes, class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trông tốt!\n",
    "\n",
    "Bây giờ hãy thử nghiệm hàm `find_classes()` của chúng ta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_classes(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woohoo! Trông tốt!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Tạo `Dataset` tùy chỉnh (custom) để sao chép `ImageFolder`\n",
    "\n",
    "Bây giờ chúng ta đã sẵn sàng xây dựng `Dataset` tùy chỉnh (custom) của riêng mình.\n",
    "\n",
    "Chúng ta sẽ xây dựng một cái để sao chép chức năng của `torchvision.datasets.ImageFolder()`. \n",
    "\n",
    "Đây sẽ là thực hành tốt, thêm vào đó, nó sẽ tiết lộ một số bước cần thiết để tạo `Dataset` tùy chỉnh (custom) của riêng bạn.\n",
    "\n",
    "Sẽ có khá nhiều mã (code)... nhưng không có gì chúng ta không thể xử lý được!\n",
    "\n",
    "Hãy chia nhỏ nó ra:\n",
    "1. Tạo lớp con (subclass) `torch.utils.data.Dataset`.\n",
    "2. Khởi tạo lớp con (subclass) của chúng ta với tham số `targ_dir` (thư mục dữ liệu đích - target data directory) và tham số `transform` (để chúng ta có tùy chọn biến đổi dữ liệu của mình nếu cần).\n",
    "3. Tạo một số thuộc tính (attributes) cho `paths` (đường dẫn của hình ảnh đích), `transform` (các biến đổi chúng ta có thể muốn sử dụng, điều này có thể là `None`), `classes` và `class_to_idx` (từ hàm `find_classes()` của chúng ta).\n",
    "4. Tạo một hàm để tải hình ảnh từ tệp và trả về chúng, điều này có thể sử dụng `PIL` hoặc [`torchvision.io`](https://pytorch.org/vision/stable/io.html#image) (cho input/output của dữ liệu thị giác - vision data). \n",
    "5. Ghi đè (overwrite) phương thức `__len__` của `torch.utils.data.Dataset` để trả về số lượng mẫu (samples) trong `Dataset`, điều này được khuyến nghị nhưng không bắt buộc. Điều này để bạn có thể gọi `len(Dataset)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết một lớp dataset tùy chỉnh (custom dataset class) (kế thừa từ torch.utils.data.Dataset)\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 1. Tạo lớp con (subclass) torch.utils.data.Dataset\n",
    "class ImageFolderCustom(Dataset):\n",
    "    \n",
    "    # 2. Khởi tạo với tham số targ_dir và transform (tùy chọn)\n",
    "    def __init__(self, targ_dir: str, transform=None) -> None:\n",
    "        \n",
    "        # 3. Tạo các thuộc tính lớp (class attributes)\n",
    "        # Lấy tất cả đường dẫn hình ảnh\n",
    "        self.paths = list(pathlib.Path(targ_dir).glob(\"*/*.jpg\")) # lưu ý: bạn sẽ phải cập nhật điều này nếu bạn có .png hoặc .jpeg\n",
    "        # Thiết lập các biến đổi (transforms)\n",
    "        self.transform = transform\n",
    "        # Tạo các thuộc tính classes và class_to_idx\n",
    "        self.classes, self.class_to_idx = find_classes(targ_dir)\n",
    "\n",
    "    # 4. Tạo hàm để tải hình ảnh\n",
    "    def load_image(self, index: int) -> Image.Image:\n",
    "        \"Mở một hình ảnh thông qua đường dẫn và trả về nó.\"\n",
    "        image_path = self.paths[index]\n",
    "        return Image.open(image_path) \n",
    "    \n",
    "    # 5. Ghi đè phương thức __len__() (tùy chọn nhưng được khuyến nghị cho các lớp con của torch.utils.data.Dataset)\n",
    "    def __len__(self) -> int:\n",
    "        \"Trả về tổng số mẫu (samples).\"\n",
    "        return len(self.paths)\n",
    "    \n",
    "    # 6. Ghi đè phương thức __getitem__() (bắt buộc cho các lớp con của torch.utils.data.Dataset)\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"Trả về một mẫu dữ liệu (sample of data), dữ liệu và nhãn (data and label) (X, y).\"\n",
    "        img = self.load_image(index)\n",
    "        class_name  = self.paths[index].parent.name # mong đợi đường dẫn trong data_folder/class_name/image.jpeg\n",
    "        class_idx = self.class_to_idx[class_name]\n",
    "\n",
    "        # Biến đổi nếu cần thiết\n",
    "        if self.transform:\n",
    "            return self.transform(img), class_idx # trả về dữ liệu, nhãn (data, label) (X, y)\n",
    "        else:\n",
    "            return img, class_idx # trả về dữ liệu, nhãn (data, label) (X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah! Rất nhiều mã (code) để tải hình ảnh của chúng ta.\n",
    "\n",
    "Đây là một trong những nhược điểm của việc tạo `Dataset` tùy chỉnh (custom) của riêng bạn.\n",
    "\n",
    "Tuy nhiên, bây giờ chúng ta đã viết nó một lần, chúng ta có thể chuyển nó vào một tệp `.py` như `data_loader.py` cùng với một số hàm dữ liệu hữu ích khác và sử dụng lại sau này.\n",
    "\n",
    "Trước khi chúng ta thử nghiệm lớp `ImageFolderCustom` mới của mình, hãy tạo một số biến đổi (transforms) để chuẩn bị hình ảnh của chúng ta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tăng cường dữ liệu huấn luyện (augment train data)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Không tăng cường dữ liệu kiểm tra (test data), chỉ thay đổi hình dạng (reshape)\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ là khoảnh khắc quyết định!\n",
    "\n",
    "Hãy biến hình ảnh huấn luyện (training images) của chúng ta (chứa trong `train_dir`) và hình ảnh kiểm tra (testing images) của chúng ta (chứa trong `test_dir`) thành `Dataset` bằng cách sử dụng lớp `ImageFolderCustom` của riêng chúng ta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_custom = ImageFolderCustom(targ_dir=train_dir, \n",
    "                                      transform=train_transforms)\n",
    "test_data_custom = ImageFolderCustom(targ_dir=test_dir, \n",
    "                                     transform=test_transforms)\n",
    "train_data_custom, test_data_custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm... không có lỗi, nó có hoạt động không?\n",
    "\n",
    "Hãy thử gọi `len()` trên `Dataset` mới của chúng ta và tìm các thuộc tính `classes` và `class_to_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data_custom), len(test_data_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_custom.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_custom.class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`len(test_data_custom) == len(test_data)` và `len(test_data_custom) == len(test_data)` Có!!!\n",
    "\n",
    "Có vẻ như nó đã hoạt động.\n",
    "\n",
    "Chúng ta cũng có thể kiểm tra sự bằng nhau với `Dataset` được tạo bởi lớp `torchvision.datasets.ImageFolder()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra sự bằng nhau giữa Dataset tùy chỉnh (custom) và ImageFolder Dataset của chúng ta\n",
    "print((len(train_data_custom) == len(train_data)) & (len(test_data_custom) == len(test_data)))\n",
    "print(train_data_custom.classes == train_data.classes)\n",
    "print(train_data_custom.class_to_idx == train_data.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ho ho!\n",
    "\n",
    "Nhìn chúng ta tiến bộ!\n",
    "\n",
    "Ba `True`!\n",
    "\n",
    "Bạn không thể có gì tốt hơn thế.\n",
    "\n",
    "Còn việc chúng ta nâng nó lên một tầm cao mới và vẽ một số hình ảnh ngẫu nhiên để kiểm tra việc ghi đè `__getitem__` của chúng ta thì sao?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Tạo hàm để hiển thị hình ảnh ngẫu nhiên\n",
    "\n",
    "Bạn biết bây giờ là lúc nào!\n",
    "\n",
    "Đã đến lúc đội mũ nhà khám phá dữ liệu (data explorer) của chúng ta và *trực quan hóa, trực quan hóa, trực quan hóa!*\n",
    "\n",
    "Hãy tạo một hàm trợ giúp (helper function) có tên `display_random_images()` giúp chúng ta trực quan hóa hình ảnh trong `Dataset` của chúng ta.\n",
    "\n",
    "Cụ thể, nó sẽ:\n",
    "1. Nhận vào một `Dataset` và một số tham số khác như `classes` (tên của các lớp đích - target classes), số lượng hình ảnh để hiển thị (`n`) và một random seed. \n",
    "2. Để ngăn việc hiển thị trở nên mất kiểm soát, chúng ta sẽ giới hạn `n` ở 10 hình ảnh.\n",
    "3. Đặt random seed để có các biểu đồ có thể tái tạo (nếu `seed` được đặt). \n",
    "4. Lấy danh sách các chỉ số mẫu ngẫu nhiên (chúng ta có thể sử dụng `random.sample()` của Python cho việc này) để vẽ.\n",
    "5. Thiết lập một biểu đồ `matplotlib`.\n",
    "6. Lặp qua các chỉ số mẫu ngẫu nhiên được tìm thấy ở bước 4 và vẽ chúng với `matplotlib`.\n",
    "7. Đảm bảo các hình ảnh mẫu có hình dạng `HWC` (height, width, color channels) để chúng ta có thể vẽ chúng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Nhận vào một Dataset cũng như danh sách tên các lớp (class names)\n",
    "def display_random_images(dataset: torch.utils.data.dataset.Dataset,\n",
    "                          classes: List[str] = None,\n",
    "                          n: int = 10,\n",
    "                          display_shape: bool = True,\n",
    "                          seed: int = None):\n",
    "    \n",
    "    # 2. Điều chỉnh hiển thị nếu n quá cao\n",
    "    if n > 10:\n",
    "        n = 10\n",
    "        display_shape = False\n",
    "        print(f\"For display purposes, n shouldn't be larger than 10, setting to 10 and removing shape display.\")\n",
    "    \n",
    "    # 3. Đặt random seed\n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "\n",
    "    # 4. Lấy các chỉ số mẫu ngẫu nhiên (random sample indexes)\n",
    "    random_samples_idx = random.sample(range(len(dataset)), k=n)\n",
    "\n",
    "    # 5. Thiết lập biểu đồ (setup plot)\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    # 6. Lặp qua các mẫu và hiển thị các mẫu ngẫu nhiên\n",
    "    for i, targ_sample in enumerate(random_samples_idx):\n",
    "        targ_image, targ_label = dataset[targ_sample][0], dataset[targ_sample][1]\n",
    "\n",
    "        # 7. Điều chỉnh hình dạng tensor hình ảnh để vẽ: [color_channels, height, width] -> [color_channels, height, width]\n",
    "        targ_image_adjust = targ_image.permute(1, 2, 0)\n",
    "\n",
    "        # Vẽ các mẫu đã điều chỉnh\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.imshow(targ_image_adjust)\n",
    "        plt.axis(\"off\")\n",
    "        if classes:\n",
    "            title = f\"class: {classes[targ_label]}\"\n",
    "            if display_shape:\n",
    "                title = title + f\"\\nshape: {targ_image_adjust.shape}\"\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một hàm (function) trông rất tốt!\n",
    "\n",
    "Hãy thử nghiệm nó trước với `Dataset` mà chúng ta đã tạo bằng `torchvision.datasets.ImageFolder()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiển thị hình ảnh ngẫu nhiên từ Dataset được tạo bởi ImageFolder\n",
    "display_random_images(train_data, \n",
    "                      n=5, \n",
    "                      classes=class_names,\n",
    "                      seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Và bây giờ với `Dataset` mà chúng ta đã tạo bằng `ImageFolderCustom` của riêng chúng ta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiển thị hình ảnh ngẫu nhiên từ ImageFolderCustom Dataset\n",
    "display_random_images(train_data_custom, \n",
    "                      n=12, \n",
    "                      classes=class_names,\n",
    "                      seed=None) # Thử đặt seed để có hình ảnh có thể tái tạo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuyệt!!!\n",
    "\n",
    "Có vẻ như `ImageFolderCustom` của chúng ta đang hoạt động đúng như chúng ta muốn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Biến hình ảnh được tải tùy chỉnh (custom loaded images) thành `DataLoader`\n",
    "\n",
    "Chúng ta đã có cách để biến hình ảnh thô (raw images) của chúng ta thành `Dataset` (các đặc trưng được ánh xạ tới nhãn hoặc `X` được ánh xạ tới `y`) thông qua lớp `ImageFolderCustom` của chúng ta.\n",
    "\n",
    "Bây giờ làm thế nào chúng ta có thể biến `Dataset` tùy chỉnh (custom) của chúng ta thành `DataLoader`?\n",
    "\n",
    "Nếu bạn đoán bằng cách sử dụng `torch.utils.data.DataLoader()`, bạn đã đúng!\n",
    "\n",
    "Bởi vì `Dataset` tùy chỉnh (custom) của chúng ta là lớp con (subclass) của `torch.utils.data.Dataset`, chúng ta có thể sử dụng chúng trực tiếp với `torch.utils.data.DataLoader()`.\n",
    "\n",
    "Và chúng ta có thể làm điều đó bằng cách sử dụng các bước rất tương tự như trước đây ngoại trừ lần này chúng ta sẽ sử dụng `Dataset` được tạo tùy chỉnh (custom created) của chúng ta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biến Dataset tùy chỉnh (custom) train và test thành DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader_custom = DataLoader(dataset=train_data_custom, # sử dụng Dataset train được tạo tùy chỉnh\n",
    "                                     batch_size=1, # bao nhiêu mẫu (samples) mỗi batch?\n",
    "                                     num_workers=0, # bao nhiêu tiến trình con (subprocesses) để sử dụng cho việc tải dữ liệu? (cao hơn = nhiều hơn)\n",
    "                                     shuffle=True) # xáo trộn dữ liệu (shuffle the data)?\n",
    "\n",
    "test_dataloader_custom = DataLoader(dataset=test_data_custom, # sử dụng Dataset test được tạo tùy chỉnh\n",
    "                                    batch_size=1, \n",
    "                                    num_workers=0, \n",
    "                                    shuffle=False) # thường không cần xáo trộn dữ liệu kiểm tra (testing data)\n",
    "\n",
    "train_dataloader_custom, test_dataloader_custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các hình dạng (shapes) của các mẫu (samples) có giống nhau không?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy hình ảnh và nhãn (label) từ DataLoader tùy chỉnh (custom)\n",
    "img_custom, label_custom = next(iter(train_dataloader_custom))\n",
    "\n",
    "# Kích thước batch (batch size) bây giờ sẽ là 1, thử thay đổi tham số batch_size ở trên và xem điều gì sẽ xảy ra\n",
    "print(f\"Image shape: {img_custom.shape} -> [batch_size, color_channels, height, width]\")\n",
    "print(f\"Label shape: {label_custom.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng chắc chắn giống nhau!\n",
    "\n",
    "Bây giờ hãy xem xét một số hình thức biến đổi dữ liệu (data transforms) khác."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Các hình thức biến đổi dữ liệu khác (data augmentation)\n",
    "\n",
    "Chúng ta đã thấy một vài phép biến đổi (transforms) trên dữ liệu của mình rồi nhưng còn nhiều loại khác nữa.\n",
    "\n",
    "Bạn có thể xem tất cả trong [tài liệu `torchvision.transforms`](https://pytorch.org/vision/stable/transforms.html).\n",
    "\n",
    "Mục đích của các phép biến đổi (transforms) là để thay đổi hình ảnh của bạn theo một cách nào đó.\n",
    "\n",
    "Điều đó có thể là chuyển đổi hình ảnh của bạn thành tensor (như chúng ta đã thấy trước đây).\n",
    "\n",
    "Hoặc cắt ảnh hoặc xóa ngẫu nhiên một phần hoặc xoay ngẫu nhiên chúng.\n",
    "\n",
    "Việc thực hiện các loại biến đổi này thường được gọi là **tăng cường dữ liệu (data augmentation)**.\n",
    "\n",
    "**Tăng cường dữ liệu (Data augmentation)** là quá trình thay đổi dữ liệu của bạn theo cách mà bạn *nhân tạo* tăng tính đa dạng của tập huấn luyện (training set).\n",
    "\n",
    "Huấn luyện (training) một mô hình trên tập dữ liệu (dataset) được thay đổi *nhân tạo* này hy vọng sẽ tạo ra một mô hình có khả năng *tổng quát hóa (generalization)* tốt hơn (các mẫu mà nó học được sẽ mạnh mẽ hơn đối với các ví dụ chưa thấy trong tương lai).\n",
    "\n",
    "Bạn có thể xem nhiều ví dụ khác nhau về tăng cường dữ liệu (data augmentation) được thực hiện trên hình ảnh bằng cách sử dụng `torchvision.transforms` trong [ví dụ Illustration of Transforms](https://pytorch.org/vision/main/auto_examples/transforms/plot_transforms_illustrations.html) của PyTorch.\n",
    "\n",
    "Nhưng chúng ta hãy thử một cái.\n",
    "\n",
    "Học máy (Machine learning) là tất cả về việc khai thác sức mạnh của tính ngẫu nhiên và nghiên cứu cho thấy rằng các phép biến đổi ngẫu nhiên (như [`transforms.RandAugment()`](https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#randaugment) và [`transforms.TrivialAugmentWide()`](https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#trivialaugmentwide)) thường hoạt động tốt hơn so với các phép biến đổi được chọn thủ công.\n",
    "\n",
    "Ý tưởng đằng sau [TrivialAugment](https://arxiv.org/abs/2103.10158) là... tầm thường.\n",
    "\n",
    "Bạn có một tập hợp các phép biến đổi (transforms) và bạn chọn ngẫu nhiên một số trong số chúng để thực hiện trên một hình ảnh và với cường độ ngẫu nhiên trong một phạm vi nhất định (cường độ cao hơn có nghĩa là mạnh mẽ hơn).\n",
    "\n",
    "Nhóm PyTorch thậm chí đã [sử dụng TrivialAugment để huấn luyện (training) các mô hình thị giác (vision models) hiện đại nhất của họ](https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/#break-down-of-key-accuracy-improvements).\n",
    "\n",
    "![trivial augment data augmentation being used for PyTorch state of the art training](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-trivial-augment-being-using-in-PyTorch-resize.png)\n",
    "\n",
    "*TrivialAugment là một trong những thành phần được sử dụng trong việc nâng cấp huấn luyện (training) hiện đại gần đây cho các mô hình thị giác PyTorch khác nhau.*\n",
    "\n",
    "Chúng ta hãy thử nghiệm nó trên một số hình ảnh của riêng chúng ta?\n",
    "\n",
    "Tham số chính cần chú ý trong `transforms.TrivialAugmentWide()` là `num_magnitude_bins=31`.\n",
    "\n",
    "Nó xác định phạm vi của giá trị cường độ sẽ được chọn để áp dụng một phép biến đổi (transform) nhất định, `0` là không có phạm vi và `31` là phạm vi tối đa (cơ hội cao nhất cho cường độ cao nhất).\n",
    "\n",
    "Chúng ta có thể kết hợp `transforms.TrivialAugmentWide()` vào `transforms.Compose()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.TrivialAugmentWide(num_magnitude_bins=31), # mức độ mạnh mẽ (how intense)\n",
    "    transforms.ToTensor() # sử dụng ToTensor() cuối cùng để có mọi thứ giữa 0 & 1 (use ToTensor() last to get everything between 0 & 1)\n",
    "])\n",
    "\n",
    "# Không cần thực hiện tăng cường dữ liệu (augmentation) trên dữ liệu test (Don't need to perform augmentation on the test data)\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Lưu ý:** Bạn thường không thực hiện tăng cường dữ liệu (data augmentation) trên tập test. Ý tưởng của tăng cường dữ liệu (data augmentation) là *nhân tạo* tăng tính đa dạng của tập huấn luyện (training set) để dự đoán tốt hơn trên tập test.\n",
    ">\n",
    "> Tuy nhiên, bạn cần đảm bảo rằng hình ảnh tập test được chuyển đổi thành tensors. Chúng ta cũng thay đổi kích thước hình ảnh test về cùng kích thước với hình ảnh huấn luyện (training), tuy nhiên, suy luận (inference) có thể được thực hiện trên các hình ảnh có kích thước khác nhau nếu cần thiết (mặc dù điều này có thể thay đổi hiệu suất).\n",
    "\n",
    "Tuyệt vời, bây giờ chúng ta đã có một phép biến đổi huấn luyện (training transform) (với tăng cường dữ liệu) và phép biến đổi test (test transform) (không có tăng cường dữ liệu).\n",
    "\n",
    "Hãy thử nghiệm tăng cường dữ liệu của chúng ta!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy tất cả đường dẫn hình ảnh (Get all image paths)\n",
    "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
    "\n",
    "# Vẽ hình ảnh ngẫu nhiên (Plot random images)\n",
    "plot_transformed_images(\n",
    "    image_paths=image_path_list,\n",
    "    transform=train_transforms,\n",
    "    n=3,\n",
    "    seed=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hãy thử chạy ô (cell) ở trên vài lần và xem hình ảnh gốc thay đổi như thế nào khi nó đi qua phép biến đổi (transform)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Mô hình 0: TinyVGG không có tăng cường dữ liệu (data augmentation)\n",
    "\n",
    "Được rồi, chúng ta đã thấy cách chuyển đổi dữ liệu từ hình ảnh trong thư mục thành tensors đã được biến đổi.\n",
    "\n",
    "Bây giờ hãy xây dựng một mô hình thị giác máy tính (computer vision model) để xem liệu chúng ta có thể phân loại hình ảnh là pizza, steak hay sushi hay không.\n",
    "\n",
    "Để bắt đầu, chúng ta sẽ bắt đầu với một phép biến đổi đơn giản, chỉ thay đổi kích thước hình ảnh thành `(64, 64)` và chuyển chúng thành tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Tạo transforms và tải dữ liệu cho Mô hình 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo phép biến đổi đơn giản (Create simple transform)\n",
    "simple_transform = transforms.Compose([ \n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuyệt vời, bây giờ chúng ta đã có một phép biến đổi đơn giản, hãy:\n",
    "1. Tải dữ liệu, chuyển đổi từng thư mục huấn luyện (training) và test trước tiên thành một `Dataset` với `torchvision.datasets.ImageFolder()` \n",
    "2. Sau đó thành một `DataLoader` bằng cách sử dụng `torch.utils.data.DataLoader()`.\n",
    "    * Chúng ta sẽ đặt `batch_size=32` và `num_workers` bằng số CPU trên máy của chúng ta (điều này sẽ phụ thuộc vào máy bạn đang sử dụng)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Tải và biến đổi dữ liệu (Load and transform data)\n",
    "from torchvision import datasets\n",
    "train_data_simple = datasets.ImageFolder(root=train_dir, transform=simple_transform)\n",
    "test_data_simple = datasets.ImageFolder(root=test_dir, transform=simple_transform)\n",
    "\n",
    "# 2. Chuyển dữ liệu thành DataLoaders (Turn data into DataLoaders)\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Thiết lập kích thước batch và số workers (Setup batch size and number of workers)\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "print(f\"Creating DataLoader's with batch size {BATCH_SIZE} and {NUM_WORKERS} workers.\")\n",
    "\n",
    "# Tạo DataLoader's (Create DataLoader's)\n",
    "train_dataloader_simple = DataLoader(train_data_simple, \n",
    "                                     batch_size=BATCH_SIZE, \n",
    "                                     shuffle=True, \n",
    "                                     num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataloader_simple = DataLoader(test_data_simple, \n",
    "                                    batch_size=BATCH_SIZE, \n",
    "                                    shuffle=False, \n",
    "                                    num_workers=NUM_WORKERS)\n",
    "\n",
    "train_dataloader_simple, test_dataloader_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataLoader`'s đã được tạo! \n",
    "\n",
    "Hãy xây dựng một mô hình."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Tạo lớp mô hình TinyVGG\n",
    "\n",
    "Trong [notebook 03](https://www.learnpytorch.io/03_pytorch_computer_vision/#7-model-2-building-a-convolutional-neural-network-cnn), chúng ta đã sử dụng mô hình TinyVGG từ [trang web CNN Explainer](https://poloclub.github.io/cnn-explainer/).\n",
    "\n",
    "Hãy tạo lại cùng một mô hình, ngoại trừ lần này chúng ta sẽ sử dụng hình ảnh màu thay vì thang độ xám (`in_channels=3` thay vì `in_channels=1` cho các pixel RGB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"\n",
    "    Kiến trúc mô hình sao chép TinyVGG từ: \n",
    "    https://poloclub.github.io/cnn-explainer/\n",
    "    (Model architecture copying TinyVGG from: \n",
    "    https://poloclub.github.io/cnn-explainer/)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, \n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3, # hình vuông đi qua hình ảnh lớn như thế nào? (how big is the square that's going over the image?)\n",
    "                      stride=1, # mặc định (default)\n",
    "                      padding=1), # tùy chọn = \"valid\" (không padding) hoặc \"same\" (đầu ra có cùng hình dạng với đầu vào) hoặc int cho số cụ thể (options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2) # giá trị stride mặc định giống với kernel_size (default stride value is same as kernel_size)\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # Hình dạng in_features này đến từ đâu? (Where did this in_features shape come from?)\n",
    "            # Đó là bởi vì mỗi lớp của mạng chúng ta nén và thay đổi hình dạng của dữ liệu đầu vào. (It's because each layer of our network compresses and changes the shape of our input data.)\n",
    "            nn.Linear(in_features=hidden_units*16*16,\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv_block_1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.conv_block_2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "        # return self.classifier(self.conv_block_2(self.conv_block_1(x))) # <- tận dụng lợi ích của operator fusion (leverage the benefits of operator fusion)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_0 = TinyVGG(input_shape=3, # số kênh màu (3 cho RGB) (number of color channels (3 for RGB))\n",
    "                  hidden_units=10, \n",
    "                  output_shape=len(train_data.classes)).to(device)\n",
    "model_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Lưu ý:** Một trong những cách để tăng tốc tính toán mô hình học sâu (deep learning) trên GPU là tận dụng **operator fusion**.\n",
    ">\n",
    "> Điều này có nghĩa là trong phương thức `forward()` trong mô hình của chúng ta ở trên, thay vì gọi một khối lớp (layer block) và gán lại `x` mỗi lần, chúng ta gọi từng khối liên tiếp (xem dòng cuối cùng của phương thức `forward()` trong mô hình ở trên để có ví dụ).\n",
    ">\n",
    "> Điều này tiết kiệm thời gian dành cho việc gán lại `x` (tốn nhiều bộ nhớ) và chỉ tập trung vào việc tính toán trên `x`.\n",
    "> \n",
    "> Xem [*Making Deep Learning Go Brrrr From First Principles*](https://horace.io/brrr_intro.html) của Horace He để biết thêm các cách tăng tốc mô hình học máy (machine learning).\n",
    "\n",
    "Bây giờ đó là một mô hình trông đẹp!\n",
    "\n",
    "Chúng ta hãy thử nghiệm nó với một lần forward pass trên một hình ảnh duy nhất?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Thử forward pass trên một hình ảnh duy nhất (để kiểm tra mô hình)\n",
    "\n",
    "Một cách tốt để kiểm tra mô hình là thực hiện forward pass trên một phần dữ liệu duy nhất.\n",
    "\n",
    "Đây cũng là cách hữu ích để kiểm tra hình dạng đầu vào và đầu ra của các lớp khác nhau.\n",
    "\n",
    "Để thực hiện forward pass trên một hình ảnh duy nhất, hãy:\n",
    "1. Lấy một batch hình ảnh và nhãn từ `DataLoader`.\n",
    "2. Lấy một hình ảnh duy nhất từ batch và `unsqueeze()` hình ảnh để nó có kích thước batch là `1` (để hình dạng của nó phù hợp với mô hình).\n",
    "3. Thực hiện suy luận (inference) trên một hình ảnh duy nhất (đảm bảo gửi hình ảnh đến `device` đích).\n",
    "4. In ra những gì đang xảy ra và chuyển đổi logits đầu ra thô của mô hình thành xác suất dự đoán với `torch.softmax()` (vì chúng ta đang làm việc với dữ liệu đa lớp) và chuyển đổi xác suất dự đoán thành nhãn dự đoán với `torch.argmax()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Lấy một batch hình ảnh và nhãn từ DataLoader (Get a batch of images and labels from the DataLoader)\n",
    "img_batch, label_batch = next(iter(train_dataloader_simple))\n",
    "\n",
    "# 2. Lấy một hình ảnh duy nhất từ batch và unsqueeze hình ảnh để hình dạng của nó phù hợp với mô hình (Get a single image from the batch and unsqueeze the image so its shape fits the model)\n",
    "img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n",
    "print(f\"Single image shape: {img_single.shape}\\n\")\n",
    "\n",
    "# 3. Thực hiện forward pass trên một hình ảnh duy nhất (Perform a forward pass on a single image)\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    pred = model_0(img_single.to(device))\n",
    "    \n",
    "# 4. In ra những gì đang xảy ra và chuyển đổi logits mô hình -> xác suất dự đoán -> nhãn dự đoán (Print out what's happening and convert model logits -> pred probs -> pred label)\n",
    "print(f\"Output logits:\\n{pred}\\n\")\n",
    "print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n",
    "print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n",
    "print(f\"Actual label:\\n{label_single}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuyệt vời, có vẻ như mô hình của chúng ta đang xuất ra những gì chúng ta mong đợi.\n",
    "\n",
    "Và bạn có thể sẽ nhận thấy các dự đoán thường sai.\n",
    "\n",
    "Điều này là có thể mong đợi được vì mô hình chưa được huấn luyện (trained) và về cơ bản nó đang đoán bằng cách sử dụng các trọng số ngẫu nhiên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 7.4 Sử dụng `torchinfo` để hiểu về các hình dạng đi qua mô hình của chúng ta\n",
    "\n",
    "In mô hình của chúng ta với `print(model)` cho chúng ta ý tưởng về những gì đang xảy ra với mô hình.\n",
    "\n",
    "Và chúng ta có thể in ra các hình dạng của dữ liệu trong suốt phương thức `forward()`.\n",
    "\n",
    "Tuy nhiên, một cách hữu ích để lấy thông tin từ mô hình của chúng ta là sử dụng [`torchinfo`](https://github.com/TylerYep/torchinfo).\n",
    "\n",
    "`torchinfo` đi kèm với một phương thức `summary()` nhận một mô hình PyTorch cũng như một `input_shape` và trả về những gì xảy ra khi một tensor di chuyển qua mô hình của bạn.\n",
    "\n",
    "> **Lưu ý:** Nếu bạn đang sử dụng Google Colab, bạn sẽ cần cài đặt `torchinfo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cài đặt torchinfo nếu nó không có sẵn, import nó nếu có (Install torchinfo if it's not available, import it if it is)\n",
    "try: \n",
    "    import torchinfo\n",
    "except:\n",
    "    %pip install torchinfo\n",
    "    import torchinfo\n",
    "    \n",
    "from torchinfo import summary\n",
    "summary(model_0, input_size=[1, 3, 64, 64]) # thực hiện một lần test pass qua với kích thước đầu vào ví dụ (do a test pass through of an example input size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuyệt vời! \n",
    "\n",
    "Đầu ra của `torchinfo.summary()` cung cấp cho chúng ta rất nhiều thông tin về mô hình.\n",
    "\n",
    "Chẳng hạn như `Total params`, tổng số tham số trong mô hình của chúng ta, `Estimated Total Size (MB)` là kích thước của mô hình.\n",
    "\n",
    "Bạn cũng có thể thấy sự thay đổi trong hình dạng đầu vào và đầu ra khi dữ liệu có `input_size` nhất định di chuyển qua mô hình của chúng ta.\n",
    "\n",
    "Hiện tại, số lượng tham số và tổng kích thước mô hình của chúng ta thấp.\n",
    "\n",
    "Điều này là do chúng ta đang bắt đầu với một mô hình nhỏ.\n",
    "\n",
    "Và nếu chúng ta cần tăng kích thước của nó sau này, chúng ta có thể."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Tạo các hàm vòng lặp huấn luyện và test\n",
    "\n",
    "Chúng ta đã có dữ liệu và chúng ta đã có mô hình.\n",
    "\n",
    "Bây giờ hãy tạo một số hàm vòng lặp huấn luyện (training) và test để huấn luyện (train) mô hình của chúng ta trên dữ liệu huấn luyện (training data) và đánh giá mô hình của chúng ta trên dữ liệu test.\n",
    "\n",
    "Và để đảm bảo chúng ta có thể sử dụng lại các vòng lặp huấn luyện (training) và test này, chúng ta sẽ chuyển chúng thành hàm.\n",
    "\n",
    "Cụ thể, chúng ta sẽ tạo ba hàm:\n",
    "1. `train_step()` - nhận vào một mô hình, một `DataLoader`, một hàm mất mát (loss function) và một optimizer và huấn luyện (trains) mô hình trên `DataLoader`.\n",
    "2. `test_step()` - nhận vào một mô hình, một `DataLoader` và một hàm mất mát (loss function) và đánh giá mô hình trên `DataLoader`.\n",
    "3. `train()` - thực hiện 1. và 2. cùng nhau trong một số epochs nhất định và trả về một từ điển kết quả.\n",
    "\n",
    "> **Lưu ý:** Chúng ta đã đề cập đến các bước trong vòng lặp tối ưu hóa PyTorch trong [notebook 01](https://www.learnpytorch.io/01_pytorch_workflow/#creating-an-optimization-loop-in-pytorch), cũng như [Unofficial PyTorch Optimization Loop Song](https://youtu.be/Nutpusq_AFw) và chúng ta đã xây dựng các hàm tương tự trong [notebook 03](https://www.learnpytorch.io/03_pytorch_computer_vision/#62-functionizing-training-and-test-loops).\n",
    "\n",
    "Hãy bắt đầu bằng cách xây dựng `train_step()`.\n",
    "\n",
    "Vì chúng ta đang xử lý các batches trong `DataLoader`'s, chúng ta sẽ tích lũy các giá trị mất mát (loss) và độ chính xác (accuracy) của mô hình trong quá trình huấn luyện (training) (bằng cách cộng chúng lại cho từng batch) và sau đó điều chỉnh chúng ở cuối trước khi chúng ta trả về chúng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer):\n",
    "    # Đặt mô hình ở chế độ train (Put model in train mode)\n",
    "    model.train()\n",
    "    \n",
    "    # Thiết lập giá trị train loss và train accuracy (Setup train loss and train accuracy values)\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    # Lặp qua các batches dữ liệu của data loader (Loop through data loader data batches)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Gửi dữ liệu đến target device (Send data to target device)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Tính toán và tích lũy loss (Calculate and accumulate loss)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item() \n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Tính toán và tích lũy các metrics accuracy qua tất cả batches (Calculate and accumulate accuracy metrics across all batches)\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "    # Điều chỉnh metrics để có loss và accuracy trung bình mỗi batch (Adjust metrics to get average loss and accuracy per batch)\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woohoo! Hàm `train_step()` hoàn thành.\n",
    "\n",
    "Bây giờ hãy làm tương tự cho hàm `test_step()`.\n",
    "\n",
    "Sự khác biệt chính ở đây là `test_step()` sẽ không nhận vào một optimizer và do đó sẽ không thực hiện gradient descent.\n",
    "\n",
    "Nhưng vì chúng ta sẽ thực hiện suy luận (inference), chúng ta sẽ đảm bảo bật context manager `torch.inference_mode()` để đưa ra dự đoán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module):\n",
    "    # Đặt mô hình ở chế độ eval (Put model in eval mode)\n",
    "    model.eval() \n",
    "    \n",
    "    # Thiết lập giá trị test loss và test accuracy (Setup test loss and test accuracy values)\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    # Bật inference context manager (Turn on inference context manager)\n",
    "    with torch.inference_mode():\n",
    "        # Lặp qua các batches của DataLoader (Loop through DataLoader batches)\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            # Gửi dữ liệu đến target device (Send data to target device)\n",
    "            X, y = X.to(device), y.to(device)\n",
    "    \n",
    "            # 1. Forward pass\n",
    "            test_pred_logits = model(X)\n",
    "\n",
    "            # 2. Tính toán và tích lũy loss (Calculate and accumulate loss)\n",
    "            loss = loss_fn(test_pred_logits, y)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Tính toán và tích lũy accuracy (Calculate and accumulate accuracy)\n",
    "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "            \n",
    "    # Điều chỉnh metrics để có loss và accuracy trung bình mỗi batch (Adjust metrics to get average loss and accuracy per batch)\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuyệt vời!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6 Tạo hàm `train()` để kết hợp `train_step()` và `test_step()`\n",
    "\n",
    "Bây giờ chúng ta cần một cách để kết hợp các hàm `train_step()` và `test_step()` lại với nhau.\n",
    "\n",
    "Để làm như vậy, chúng ta sẽ đóng gói chúng trong một hàm `train()`.\n",
    "\n",
    "Hàm này sẽ huấn luyện (train) mô hình cũng như đánh giá nó.\n",
    "\n",
    "Cụ thể, nó sẽ:\n",
    "1. Nhận vào một mô hình, một `DataLoader` cho tập huấn luyện (training) và test, một optimizer, một hàm mất mát (loss function) và số epochs để thực hiện từng bước huấn luyện (train) và test.\n",
    "2. Tạo một từ điển kết quả trống cho các giá trị `train_loss`, `train_acc`, `test_loss` và `test_acc` (chúng ta có thể điền vào khi quá trình huấn luyện diễn ra).\n",
    "3. Lặp qua các hàm bước huấn luyện (training) và test trong một số epochs.\n",
    "4. In ra những gì đang xảy ra ở cuối mỗi epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1. Nhận vào các tham số khác nhau cần thiết cho các bước huấn luyện và test (Take in various parameters required for training and test steps)\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int = 5):\n",
    "    \n",
    "    # 2. Tạo từ điển kết quả trống (Create empty results dictionary)\n",
    "    results = {\"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "    \n",
    "    # 3. Lặp qua các bước huấn luyện và test trong một số epochs (Loop through training and testing steps for a number of epochs)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn)\n",
    "        \n",
    "        # 4. In ra những gì đang xảy ra (Print out what's happening)\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # 5. Cập nhật từ điển kết quả (Update results dictionary)\n",
    "        # Đảm bảo tất cả dữ liệu được chuyển đến CPU và chuyển đổi thành float để lưu trữ (Ensure all data is moved to CPU and converted to float for storage)\n",
    "        results[\"train_loss\"].append(train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss)\n",
    "        results[\"train_acc\"].append(train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc)\n",
    "        results[\"test_loss\"].append(test_loss.item() if isinstance(test_loss, torch.Tensor) else test_loss)\n",
    "        results[\"test_acc\"].append(test_acc.item() if isinstance(test_acc, torch.Tensor) else test_acc)\n",
    "\n",
    "    # 6. Trả về kết quả đã điền ở cuối các epochs (Return the filled results at the end of the epochs)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7 Huấn luyện và Đánh giá Mô hình 0\n",
    "\n",
    "Được rồi, được rồi, được rồi, chúng ta đã có tất cả các thành phần cần thiết để huấn luyện (train) và đánh giá mô hình của mình.\n",
    "\n",
    "Đã đến lúc kết hợp mô hình `TinyVGG`, `DataLoader`'s và hàm `train()` của chúng ta để xem liệu chúng ta có thể xây dựng một mô hình có khả năng phân biệt giữa pizza, steak và sushi hay không!\n",
    "\n",
    "Hãy tạo lại `model_0` (chúng ta không cần thiết nhưng chúng ta sẽ làm để hoàn chỉnh) sau đó gọi hàm `train()` của chúng ta và truyền vào các tham số cần thiết.\n",
    "\n",
    "Để giữ cho các thí nghiệm của chúng ta nhanh chóng, chúng ta sẽ huấn luyện (train) mô hình của mình trong **5 epochs** (mặc dù bạn có thể tăng lên nếu muốn).\n",
    "\n",
    "Đối với **optimizer** và **hàm mất mát (loss function)**, chúng ta sẽ sử dụng `torch.nn.CrossEntropyLoss()` (vì chúng ta đang làm việc với dữ liệu phân loại đa lớp) và `torch.optim.Adam()` với tốc độ học (learning rate) là `1e-3` tương ứng.\n",
    "\n",
    "Để xem mọi thứ mất bao lâu, chúng ta sẽ import phương thức [`timeit.default_timer()`](https://docs.python.org/3/library/timeit.html#timeit.default_timer) của Python để tính thời gian huấn luyện (training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đặt random seeds (Set random seeds)\n",
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Đặt số epochs (Set number of epochs)\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# Tạo lại một instance của TinyVGG (Recreate an instance of TinyVGG)\n",
    "model_0 = TinyVGG(input_shape=3, # số kênh màu (3 cho RGB) (number of color channels (3 for RGB))\n",
    "                  hidden_units=10, \n",
    "                  output_shape=len(train_data.classes)).to(device)\n",
    "\n",
    "# Thiết lập loss function và optimizer (Setup loss function and optimizer)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)\n",
    "\n",
    "# Bắt đầu timer (Start the timer)\n",
    "from timeit import default_timer as timer \n",
    "start_time = timer()\n",
    "\n",
    "# Huấn luyện model_0 (Train model_0)\n",
    "model_0_results = train(model=model_0, \n",
    "                        train_dataloader=train_dataloader_simple,\n",
    "                        test_dataloader=test_dataloader_simple,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn, \n",
    "                        epochs=NUM_EPOCHS)\n",
    "\n",
    "# Kết thúc timer và in ra thời gian đã mất (End the timer and print out how long it took)\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm...\n",
    "\n",
    "Có vẻ như mô hình của chúng ta hoạt động khá kém.\n",
    "\n",
    "Nhưng điều đó không sao cho bây giờ, chúng ta sẽ tiếp tục kiên trì.\n",
    "\n",
    "Một số cách bạn có thể cải thiện nó là gì?\n",
    "\n",
    "> **Lưu ý:** Hãy xem [phần *Improving a model (from a model perspective)* trong notebook 02](https://www.learnpytorch.io/02_pytorch_classification/#5-improving-a-model-from-a-model-perspective) để có ý tưởng về việc cải thiện mô hình TinyVGG của chúng ta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.8 Vẽ đồ thị đường cong mất mát (loss curves) của Mô hình 0\n",
    "\n",
    "Từ các kết quả in ra của quá trình huấn luyện (training) `model_0`, có vẻ như nó không hoạt động quá tốt.\n",
    "\n",
    "Nhưng chúng ta có thể đánh giá thêm bằng cách vẽ **đường cong mất mát (loss curves)** của mô hình.\n",
    "\n",
    "**Đường cong mất mát (Loss curves)** hiển thị kết quả của mô hình theo thời gian.\n",
    "\n",
    "Và chúng là một cách tuyệt vời để xem mô hình của bạn hoạt động như thế nào trên các tập dữ liệu (datasets) khác nhau (ví dụ: huấn luyện và test).\n",
    "\n",
    "Hãy tạo một hàm để vẽ các giá trị trong từ điển `model_0_results` của chúng ta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra các keys của model_0_results (Check the model_0_results keys)\n",
    "model_0_results.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta sẽ cần trích xuất từng key này và chuyển chúng thành một biểu đồ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(results: Dict[str, List[float]]):\n",
    "    \"\"\"Vẽ đường cong huấn luyện của một từ điển kết quả.\n",
    "    (Plots training curves of a results dictionary.)\n",
    "\n",
    "    Args:\n",
    "        results (dict): từ điển chứa danh sách các giá trị, ví dụ:\n",
    "            {\"train_loss\": [...],\n",
    "             \"train_acc\": [...],\n",
    "             \"test_loss\": [...],\n",
    "             \"test_acc\": [...]}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lấy các giá trị loss của từ điển kết quả (huấn luyện và test) (Get the loss values of the results dictionary (training and test))\n",
    "    loss = results['train_loss']\n",
    "    test_loss = results['test_loss']\n",
    "\n",
    "    # Lấy các giá trị accuracy của từ điển kết quả (huấn luyện và test) (Get the accuracy values of the results dictionary (training and test))\n",
    "    accuracy = results['train_acc']\n",
    "    test_accuracy = results['test_acc']\n",
    "\n",
    "    # Tìm ra có bao nhiêu epochs (Figure out how many epochs there were)\n",
    "    epochs = range(len(results['train_loss']))\n",
    "\n",
    "    # Thiết lập một biểu đồ (Setup a plot)\n",
    "    plt.figure(figsize=(15, 7))\n",
    "\n",
    "    # Vẽ loss (Plot loss)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, label='train_loss')\n",
    "    plt.plot(epochs, test_loss, label='test_loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Vẽ accuracy (Plot accuracy)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracy, label='train_accuracy')\n",
    "    plt.plot(epochs, test_accuracy, label='test_accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Được rồi, hãy thử nghiệm hàm `plot_loss_curves()` của chúng ta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(model_0_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah.\n",
    "\n",
    "Có vẻ như mọi thứ đang rất lộn xộn...\n",
    "\n",
    "Nhưng chúng ta đã biết điều đó phần nào vì kết quả in ra của mô hình trong quá trình huấn luyện (training) không cho thấy nhiều triển vọng.\n",
    "\n",
    "Bạn có thể thử huấn luyện (train) mô hình lâu hơn và xem điều gì xảy ra khi bạn vẽ đường cong mất mát (loss curve) trong một khoảng thời gian dài hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Đường cong mất mát lý tưởng trông như thế nào?\n",
    "\n",
    "Quan sát các đường cong mất mát (loss curves) huấn luyện (training) và test là một cách tuyệt vời để xem liệu mô hình của bạn có đang **overfitting** hay không.\n",
    "\n",
    "Một mô hình overfitting là mô hình hoạt động tốt hơn (thường là với biên độ đáng kể) trên tập huấn luyện (training set) so với tập kiểm định/test (validation/test set).\n",
    "\n",
    "Nếu mất mát huấn luyện (training loss) của bạn thấp hơn nhiều so với mất mát test (test loss), mô hình của bạn đang **overfitting**.\n",
    "\n",
    "Như trong, nó đang học các mẫu trong quá trình huấn luyện (training) quá tốt và những mẫu đó không tổng quát hóa (generalizing) tốt cho dữ liệu test.\n",
    "\n",
    "Mặt khác là khi mất mát huấn luyện (training loss) và test của bạn không thấp như bạn muốn, điều này được coi là **underfitting**.\n",
    "\n",
    "Vị trí lý tưởng cho đường cong mất mát huấn luyện (training) và test là chúng thẳng hàng gần nhau.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-loss-curves-overfitting-underfitting-ideal.jpg\" alt=\"different training and test loss curves illustrating overfitting, underfitting and the ideal loss curves\" width=\"800\"/>\n",
    "\n",
    "*Trái: Nếu các đường cong mất mát huấn luyện (training) và test của bạn không thấp như bạn muốn, điều này được coi là **underfitting**. *Giữa:* Khi mất mát test/kiểm định (validation) cao hơn mất mát huấn luyện (training loss) của bạn, điều này được coi là **overfitting**. *Phải:* Tình huống lý tưởng là khi các đường cong mất mát huấn luyện (training) và test của bạn thẳng hàng theo thời gian. Điều này có nghĩa là mô hình của bạn đang tổng quát hóa (generalizing) tốt. Có nhiều tổ hợp và những điều khác nhau mà các đường cong mất mát có thể làm, để biết thêm về những điều này, hãy xem [hướng dẫn Interpreting Loss Curves](https://developers.google.com/machine-learning/testing-debugging/metrics/interpretic) của Google.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Cách xử lý overfitting\n",
    "\n",
    "Vì vấn đề chính với overfitting là mô hình của bạn đang khớp với dữ liệu huấn luyện (training data) *quá tốt*, bạn sẽ muốn sử dụng các kỹ thuật để \"kiềm chế nó\".\n",
    "\n",
    "Một kỹ thuật phổ biến để ngăn chặn overfitting được gọi là [**regularization**](https://ml-cheatsheet.readthedocs.io/en/latest/regularization.html).\n",
    "\n",
    "Tôi thích nghĩ về điều này như \"làm cho các mô hình của chúng ta trở nên thường xuyên hơn\", như trong, có khả năng phù hợp với *nhiều* loại dữ liệu hơn.\n",
    "\n",
    "Hãy thảo luận về một vài phương pháp để ngăn chặn overfitting.\n",
    "\n",
    "| **Phương pháp ngăn chặn overfitting** | **Nó là gì?** |\n",
    "| ----- | ----- |\n",
    "| **Lấy thêm dữ liệu** | Có nhiều dữ liệu hơn sẽ cho mô hình nhiều cơ hội hơn để học các mẫu, những mẫu có thể tổng quát hóa (generalizable) hơn cho các ví dụ mới. | \n",
    "| **Đơn giản hóa mô hình của bạn** | Nếu mô hình hiện tại đã overfitting dữ liệu huấn luyện (training data), nó có thể là một mô hình quá phức tạp. Điều này có nghĩa là nó đang học các mẫu của dữ liệu quá tốt và không thể tổng quát hóa (generalize) tốt cho dữ liệu chưa thấy. Một cách để đơn giản hóa mô hình là giảm số lượng lớp (layers) mà nó sử dụng hoặc giảm số lượng đơn vị ẩn (hidden units) trong mỗi lớp. | \n",
    "| **Sử dụng tăng cường dữ liệu (data augmentation)** | [**Tăng cường dữ liệu (Data augmentation)**](https://developers.google.com/machine-learning/glossary#data-augmentation) thao tác dữ liệu huấn luyện (training data) theo cách khiến mô hình khó học hơn vì nó nhân tạo thêm sự đa dạng vào dữ liệu. Nếu một mô hình có thể học các mẫu trong dữ liệu tăng cường (augmented data), mô hình có thể tổng quát hóa (generalize) tốt hơn cho dữ liệu chưa thấy. |\n",
    "| **Sử dụng transfer learning** | [**Transfer learning**](https://developers.google.com/machine-learning/glossary#transfer-learning) bao gồm việc tận dụng các mẫu (cũng được gọi là pretrained weights) mà một mô hình đã học để sử dụng làm nền tảng cho nhiệm vụ của riêng bạn. Trong trường hợp của chúng ta, chúng ta có thể sử dụng một mô hình thị giác máy tính (computer vision model) được huấn luyện trước (pretrained) trên nhiều loại hình ảnh khác nhau và sau đó điều chỉnh nhẹ để chuyên biệt hơn cho hình ảnh thực phẩm. |\n",
    "| **Sử dụng dropout layers** | Dropout layers ngẫu nhiên loại bỏ các kết nối giữa các lớp ẩn (hidden layers) trong mạng nơ-ron (neural networks), hiệu quả đơn giản hóa mô hình nhưng cũng làm cho các kết nối còn lại tốt hơn. Xem [`torch.nn.Dropout()`](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html) để biết thêm. | \n",
    "| **Sử dụng learning rate decay** | Ý tưởng ở đây là từ từ giảm tốc độ học (learning rate) khi mô hình huấn luyện (trains). Điều này giống như với tay lấy một đồng xu ở phía sau ghế dài. Càng gần, các bước của bạn càng nhỏ. Tương tự với tốc độ học (learning rate), càng gần [**convergence**](https://developers.google.com/machine-learning/glossary#convergence), bạn sẽ muốn các cập nhật trọng số (weight updates) của mình nhỏ hơn.  |\n",
    "| **Sử dụng early stopping** | [**Early stopping**](https://developers.google.com/machine-learning/glossary#early_stopping) dừng huấn luyện mô hình (model training) *trước khi* nó bắt đầu overfitting. Như trong, giả sử mất mát (loss) của mô hình đã ngừng giảm trong 10 epochs qua (con số này là tùy ý), bạn có thể muốn dừng huấn luyện mô hình (model training) tại đây và chọn trọng số mô hình (model weights) có mất mát thấp nhất (10 epochs trước). |\n",
    "\n",
    "Có nhiều phương pháp khác để xử lý overfitting nhưng đây là một số phương pháp chính.\n",
    "\n",
    "Khi bạn bắt đầu xây dựng ngày càng nhiều mô hình sâu (deep models), bạn sẽ thấy vì học sâu (deep learning) *rất giỏi* trong việc học các mẫu trong dữ liệu, việc xử lý overfitting là một trong những vấn đề chính của học sâu (deep learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Cách xử lý underfitting\n",
    "\n",
    "Khi một mô hình đang [**underfitting**](https://developers.google.com/machine-learning/glossary#underfitting), nó được coi là có sức mạnh dự đoán kém trên tập huấn luyện (training) và test.\n",
    "\n",
    "Về bản chất, một mô hình underfitting sẽ không thể giảm các giá trị mất mát (loss values) xuống mức mong muốn.\n",
    "\n",
    "Hiện tại, nhìn vào các đường cong mất mát (loss curves) hiện tại của chúng ta, tôi sẽ coi mô hình `TinyVGG` của chúng ta, `model_0`, là underfitting dữ liệu.\n",
    "\n",
    "Ý tưởng chính đằng sau việc xử lý underfitting là *tăng* sức mạnh dự đoán của mô hình.\n",
    "\n",
    "Có một số cách để làm điều này.\n",
    "\n",
    "| **Phương pháp ngăn chặn underfitting** | **Nó là gì?** |\n",
    "| ----- | ----- |\n",
    "| **Thêm nhiều lớp/đơn vị vào mô hình của bạn** | Nếu mô hình của bạn đang underfitting, nó có thể không có đủ khả năng để *học* các mẫu/trọng số/biểu diễn cần thiết của dữ liệu để có thể dự đoán. Một cách để thêm sức mạnh dự đoán cho mô hình của bạn là tăng số lượng lớp ẩn (hidden layers)/đơn vị trong các lớp đó. | \n",
    "| **Điều chỉnh tốc độ học (learning rate)** | Có lẽ tốc độ học (learning rate) của mô hình bạn quá cao từ đầu. Và nó đang cố gắng cập nhật trọng số của mình mỗi epoch quá nhiều, từ đó không học được gì. Trong trường hợp này, bạn có thể giảm tốc độ học (learning rate) và xem điều gì xảy ra. |\n",
    "| **Sử dụng transfer learning** | Transfer learning có khả năng ngăn chặn cả overfitting và underfitting. Nó bao gồm việc sử dụng các mẫu từ một mô hình đã hoạt động trước đây và điều chỉnh chúng cho vấn đề của riêng bạn. |\n",
    "| **Huấn luyện (train) lâu hơn** | Đôi khi một mô hình chỉ cần nhiều thời gian hơn để học các biểu diễn của dữ liệu. Nếu bạn thấy trong các thí nghiệm nhỏ hơn của mình mô hình không học được gì, có lẽ để nó huấn luyện (train) trong nhiều epochs hơn có thể dẫn đến hiệu suất tốt hơn. |\n",
    "| **Sử dụng ít regularization hơn** | Có lẽ mô hình của bạn đang underfitting vì bạn đang cố gắng ngăn chặn overfitting quá nhiều. Giữ lại các kỹ thuật regularization có thể giúp mô hình của bạn khớp với dữ liệu tốt hơn. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Sự cân bằng giữa overfitting và underfitting\n",
    "\n",
    "Không có phương pháp nào được thảo luận ở trên là viên đạn bạc, có nghĩa là, chúng không phải lúc nào cũng hoạt động.\n",
    "\n",
    "Và việc ngăn chặn overfitting và underfitting có thể là lĩnh vực nghiên cứu học máy (machine learning) tích cực nhất.\n",
    "\n",
    "Vì mọi người đều muốn mô hình của họ khớp tốt hơn (ít underfitting hơn) nhưng không quá tốt đến mức chúng không tổng quát hóa (generalize) tốt và hoạt động trong thế giới thực (ít overfitting hơn).\n",
    "\n",
    "Có một ranh giới mỏng giữa overfitting và underfitting.\n",
    "\n",
    "Bởi vì quá nhiều của mỗi cái có thể gây ra cái kia.\n",
    "\n",
    "Transfer learning có lẽ là một trong những kỹ thuật mạnh mẽ nhất khi nói đến việc xử lý cả overfitting và underfitting trên các vấn đề của riêng bạn.\n",
    "\n",
    "Thay vì tạo thủ công các kỹ thuật overfitting và underfitting khác nhau, transfer learning cho phép bạn lấy một mô hình đã hoạt động trong không gian vấn đề tương tự như của bạn (chẳng hạn như một mô hình từ [paperswithcode.com/sota](https://paperswithcode.com/sota) hoặc [Hugging Face models](https://huggingface.co/models)) và áp dụng nó cho tập dữ liệu (dataset) của riêng bạn.\n",
    "\n",
    "Chúng ta sẽ thấy sức mạnh của transfer learning trong một notebook sau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Mô hình 1: TinyVGG với Tăng cường Dữ liệu (Data Augmentation)\n",
    "\n",
    "Đã đến lúc thử một mô hình khác!\n",
    "\n",
    "Lần này, hãy tải dữ liệu và sử dụng **tăng cường dữ liệu (data augmentation)** để xem liệu nó có cải thiện kết quả của chúng ta theo cách nào đó hay không.\n",
    "\n",
    "Đầu tiên, chúng ta sẽ tạo một phép biến đổi huấn luyện (training transform) để bao gồm `transforms.TrivialAugmentWide()` cũng như thay đổi kích thước và chuyển hình ảnh của chúng ta thành tensors.\n",
    "\n",
    "Chúng ta sẽ làm tương tự cho một phép biến đổi test ngoại trừ việc không có tăng cường dữ liệu (data augmentation).\n",
    "\n",
    "### 9.1 Tạo transform với tăng cường dữ liệu (data augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo training transform với TrivialAugment (Create training transform with TrivialAugment)\n",
    "train_transform_trivial_augment = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "    transforms.ToTensor() \n",
    "])\n",
    "\n",
    "# Tạo testing transform (không có data augmentation) (Create testing transform (no data augmentation))\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuyệt vời!\n",
    "\n",
    "Bây giờ hãy chuyển hình ảnh của chúng ta thành `Dataset`'s bằng cách sử dụng `torchvision.datasets.ImageFolder()` và sau đó thành `DataLoader`'s với `torch.utils.data.DataLoader()`.\n",
    "\n",
    "### 9.2 Tạo `Dataset`'s và `DataLoader`'s train và test\n",
    "\n",
    "Chúng ta sẽ đảm bảo `Dataset` train sử dụng `train_transform_trivial_augment` và `Dataset` test sử dụng `test_transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển các thư mục hình ảnh thành Datasets (Turn image folders into Datasets)\n",
    "train_data_augmented = datasets.ImageFolder(train_dir, transform=train_transform_trivial_augment)\n",
    "test_data_simple = datasets.ImageFolder(test_dir, transform=test_transform)\n",
    "\n",
    "train_data_augmented, test_data_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Và chúng ta sẽ tạo `DataLoader`'s với `batch_size=32` và với `num_workers` được đặt thành số CPU có sẵn trên máy của chúng ta (chúng ta có thể lấy điều này bằng cách sử dụng `os.cpu_count()` của Python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển Datasets thành DataLoader's (Turn Datasets into DataLoader's)\n",
    "import os\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_dataloader_augmented = DataLoader(train_data_augmented, \n",
    "                                        batch_size=BATCH_SIZE, \n",
    "                                        shuffle=True,\n",
    "                                        num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataloader_simple = DataLoader(test_data_simple, \n",
    "                                    batch_size=BATCH_SIZE, \n",
    "                                    shuffle=False, \n",
    "                                    num_workers=NUM_WORKERS)\n",
    "\n",
    "train_dataloader_augmented, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Xây dựng và huấn luyện Mô hình 1\n",
    "\n",
    "Dữ liệu đã được tải!\n",
    "\n",
    "Bây giờ để xây dựng mô hình tiếp theo của chúng ta, `model_1`, chúng ta có thể tái sử dụng lớp `TinyVGG` từ trước.\n",
    "\n",
    "Chúng ta sẽ đảm bảo gửi nó đến target device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo model_1 và gửi nó đến target device (Create model_1 and send it to the target device)\n",
    "torch.manual_seed(42)\n",
    "model_1 = TinyVGG(\n",
    "    input_shape=3,\n",
    "    hidden_units=10,\n",
    "    output_shape=len(train_data_augmented.classes)).to(device)\n",
    "model_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mô hình đã sẵn sàng!\n",
    "\n",
    "Đã đến lúc huấn luyện (train)!\n",
    "\n",
    "Vì chúng ta đã có các hàm cho vòng lặp huấn luyện (training loop) (`train_step()`) và vòng lặp test (`test_step()`) và một hàm để kết hợp chúng trong `train()`, hãy tái sử dụng những hàm đó.\n",
    "\n",
    "Chúng ta sẽ sử dụng cùng thiết lập như `model_0` với chỉ tham số `train_dataloader` khác nhau:\n",
    "* Huấn luyện (train) trong 5 epochs.\n",
    "* Sử dụng `train_dataloader=train_dataloader_augmented` làm dữ liệu huấn luyện (training data) trong `train()`.\n",
    "* Sử dụng `torch.nn.CrossEntropyLoss()` làm hàm mất mát (loss function) (vì chúng ta đang làm việc với phân loại đa lớp).\n",
    "* Sử dụng `torch.optim.Adam()` với `lr=0.001` làm tốc độ học (learning rate) làm optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đặt random seeds (Set random seeds)\n",
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Đặt số epochs (Set number of epochs)\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# Thiết lập loss function và optimizer (Setup loss function and optimizer)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_1.parameters(), lr=0.001)\n",
    "\n",
    "# Bắt đầu timer (Start the timer)\n",
    "from timeit import default_timer as timer \n",
    "start_time = timer()\n",
    "\n",
    "# Huấn luyện model_1 (Train model_1)\n",
    "model_1_results = train(model=model_1, \n",
    "                        train_dataloader=train_dataloader_augmented,\n",
    "                        test_dataloader=test_dataloader_simple,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn, \n",
    "                        epochs=NUM_EPOCHS)\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm...\n",
    "\n",
    "Có vẻ như mô hình của chúng ta lại không hoạt động tốt lắm.\n",
    "\n",
    "Hãy kiểm tra các đường cong mất mát (loss curves) của nó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 Vẽ đồ thị đường cong mất mát của Mô hình 1\n",
    "\n",
    "Vì chúng ta đã lưu kết quả của `model_1` trong một từ điển kết quả, `model_1_results`, chúng ta có thể vẽ chúng bằng cách sử dụng `plot_loss_curves()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(model_1_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow...\n",
    "\n",
    "Những cái này cũng không trông tốt lắm...\n",
    "\n",
    "Mô hình của chúng ta đang **underfitting** hay **overfitting**?\n",
    "\n",
    "Hoặc cả hai?\n",
    "\n",
    "Lý tưởng nhất là chúng ta muốn nó có độ chính xác (accuracy) cao hơn và mất mát (loss) thấp hơn phải không?\n",
    "\n",
    "Một số phương pháp bạn có thể thử sử dụng để đạt được những điều này là gì?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. So sánh kết quả mô hình (Compare model results)\n",
    "\n",
    "Mặc dù các mô hình của chúng ta hoạt động khá kém, chúng ta vẫn có thể viết code để so sánh chúng.\n",
    "\n",
    "Hãy đầu tiên chuyển kết quả mô hình của chúng ta thành pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "model_0_df = pd.DataFrame(model_0_results)\n",
    "model_1_df = pd.DataFrame(model_1_results)\n",
    "model_0_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Và bây giờ chúng ta có thể viết một số code vẽ biểu đồ bằng cách sử dụng `matplotlib` để trực quan hóa kết quả của `model_0` và `model_1` cùng nhau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thiết lập một biểu đồ (Setup a plot)\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Lấy số epochs (Get number of epochs)\n",
    "epochs = range(len(model_0_df))\n",
    "\n",
    "# Vẽ train loss (Plot train loss)\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs, model_0_df[\"train_loss\"], label=\"Model 0\")\n",
    "plt.plot(epochs, model_1_df[\"train_loss\"], label=\"Model 1\")\n",
    "plt.title(\"Train Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "# Vẽ test loss (Plot test loss)\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs, model_0_df[\"test_loss\"], label=\"Model 0\")\n",
    "plt.plot(epochs, model_1_df[\"test_loss\"], label=\"Model 1\")\n",
    "plt.title(\"Test Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "# Vẽ train accuracy (Plot train accuracy)\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epochs, model_0_df[\"train_acc\"], label=\"Model 0\")\n",
    "plt.plot(epochs, model_1_df[\"train_acc\"], label=\"Model 1\")\n",
    "plt.title(\"Train Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "# Vẽ test accuracy (Plot test accuracy)\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(epochs, model_0_df[\"test_acc\"], label=\"Model 0\")\n",
    "plt.plot(epochs, model_1_df[\"test_acc\"], label=\"Model 1\")\n",
    "plt.title(\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có vẻ như cả hai mô hình của chúng ta đều hoạt động tệ như nhau và khá thất thường (các chỉ số tăng giảm đột ngột).\n",
    "\n",
    "Nếu bạn xây dựng `model_2`, bạn sẽ làm gì khác đi để cố gắng cải thiện hiệu suất (performance)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 11. Thực hiện dự đoán trên hình ảnh tùy chỉnh (Make a prediction on a custom image)\n",
    "\n",
    "Nếu bạn đã huấn luyện (trained) một mô hình trên một tập dữ liệu (dataset) nhất định, có thể bạn muốn thực hiện dự đoán (prediction) trên dữ liệu tùy chỉnh (custom data) của riêng mình.\n",
    "\n",
    "Trong trường hợp của chúng ta, vì chúng ta đã huấn luyện một mô hình trên các hình ảnh pizza, steak và sushi, làm thế nào chúng ta có thể sử dụng mô hình để thực hiện dự đoán trên một trong những hình ảnh của riêng chúng ta?\n",
    "\n",
    "Để làm điều đó, chúng ta có thể tải một hình ảnh và sau đó **tiền xử lý nó theo cách phù hợp với loại dữ liệu mà mô hình của chúng ta đã được huấn luyện**.\n",
    "\n",
    "Nói cách khác, chúng ta sẽ phải chuyển đổi hình ảnh tùy chỉnh của riêng mình thành tensor và đảm bảo nó có đúng kiểu dữ liệu (datatype) trước khi truyền vào mô hình.\n",
    "\n",
    "Hãy bắt đầu bằng cách tải xuống một hình ảnh tùy chỉnh.\n",
    "\n",
    "Vì mô hình của chúng ta dự đoán xem hình ảnh có chứa pizza, steak hay sushi, hãy tải xuống một bức ảnh [bố tôi giơ hai ngón tay cái lên với một chiếc pizza lớn từ Learn PyTorch for Deep Learning GitHub](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/images/04-pizza-dad.jpeg).\n",
    "\n",
    "Chúng ta tải xuống hình ảnh bằng cách sử dụng module `requests` của Python.\n",
    "\n",
    "> **Lưu ý:** Nếu bạn đang sử dụng Google Colab, bạn cũng có thể tải lên hình ảnh vào phiên hiện tại bằng cách vào menu bên trái -> Files -> Upload to session storage. Tuy nhiên hãy lưu ý rằng hình ảnh này sẽ bị xóa khi phiên Google Colab của bạn kết thúc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tải xuống hình ảnh tùy chỉnh (Download custom image)\n",
    "import requests\n",
    "\n",
    "# Thiết lập đường dẫn hình ảnh tùy chỉnh (Setup custom image path)\n",
    "custom_image_path = data_path / \"04-pizza-dad.jpeg\"\n",
    "\n",
    "# Tải xuống hình ảnh nếu nó chưa tồn tại (Download the image if it doesn't already exist)\n",
    "if not custom_image_path.is_file():\n",
    "    with open(custom_image_path, \"wb\") as f:\n",
    "        # Khi tải xuống từ GitHub, cần sử dụng liên kết file \"raw\" (When downloading from GitHub, need to use the \"raw\" file link)\n",
    "        request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pizza-dad.jpeg\")\n",
    "        print(f\"Downloading {custom_image_path}...\")\n",
    "        f.write(request.content)\n",
    "else:\n",
    "    print(f\"{custom_image_path} already exists, skipping download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 Tải hình ảnh tùy chỉnh với PyTorch (Loading in a custom image with PyTorch)\n",
    "\n",
    "Tuyệt vời!\n",
    "\n",
    "Có vẻ như chúng ta đã có một hình ảnh tùy chỉnh được tải xuống và sẵn sàng tại `data/04-pizza-dad.jpeg`.\n",
    "\n",
    "Đã đến lúc tải nó vào.\n",
    "\n",
    "`torchvision` của PyTorch có một số phương thức đầu vào và đầu ra (\"IO\" hay \"io\" cho ngắn gọn) để đọc và ghi hình ảnh và video trong [`torchvision.io`](https://pytorch.org/vision/stable/io.html).\n",
    "\n",
    "Vì chúng ta muốn tải vào một hình ảnh, chúng ta sẽ sử dụng [`torchvision.io.read_image()`](https://pytorch.org/vision/stable/generated/torchvision.io.read_image.html#torchvision.io.read_image).\n",
    "\n",
    "Phương thức này sẽ đọc một hình ảnh JPEG hoặc PNG và biến nó thành một `torch.Tensor` RGB hoặc grayscale 3 chiều với các giá trị có kiểu dữ liệu (datatype) `uint8` trong khoảng `[0, 255]`.\n",
    "\n",
    "Hãy thử nó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "# Đọc hình ảnh tùy chỉnh (Read in custom image)\n",
    "custom_image_uint8 = torchvision.io.read_image(str(custom_image_path))\n",
    "\n",
    "# In ra dữ liệu hình ảnh (Print out image data)\n",
    "print(f\"Custom image tensor:\\n{custom_image_uint8}\\n\")\n",
    "print(f\"Custom image shape: {custom_image_uint8.shape}\\n\")\n",
    "print(f\"Custom image dtype: {custom_image_uint8.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuyệt! Có vẻ như hình ảnh của chúng ta đã ở định dạng tensor, tuy nhiên, định dạng hình ảnh này có tương thích với mô hình của chúng ta không?\n",
    "\n",
    "Tensor `custom_image` của chúng ta có kiểu dữ liệu (datatype) `torch.uint8` và các giá trị của nó nằm trong khoảng `[0, 255]`.\n",
    "\n",
    "Nhưng mô hình của chúng ta nhận các tensor hình ảnh có kiểu dữ liệu `torch.float32` và với các giá trị nằm trong khoảng `[0, 1]`.\n",
    "\n",
    "Vì vậy, trước khi sử dụng hình ảnh tùy chỉnh với mô hình, **chúng ta cần chuyển đổi nó sang cùng định dạng với dữ liệu mà mô hình được huấn luyện**.\n",
    "\n",
    "Nếu chúng ta không làm điều này, mô hình sẽ báo lỗi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thử thực hiện dự đoán trên hình ảnh ở định dạng uint8 (điều này sẽ báo lỗi) (Try to make a prediction on image in uint8 format (this will error))\n",
    "model_1.eval()\n",
    "with torch.inference_mode():\n",
    "    model_1(custom_image_uint8.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu chúng ta cố gắng thực hiện dự đoán trên một hình ảnh có kiểu dữ liệu (datatype) khác với những gì mô hình đã được huấn luyện, chúng ta sẽ gặp lỗi như sau:\n",
    "\n",
    "> `RuntimeError: Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same`\n",
    "\n",
    "Hãy khắc phục điều này bằng cách chuyển đổi hình ảnh tùy chỉnh sang cùng kiểu dữ liệu với những gì mô hình đã được huấn luyện (`torch.float32`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tải hình ảnh tùy chỉnh và chuyển đổi các giá trị tensor sang float32 (Load in custom image and convert the tensor values to float32)\n",
    "custom_image = torchvision.io.read_image(str(custom_image_path)).type(torch.float32)\n",
    "\n",
    "# Chia các giá trị pixel hình ảnh cho 255 để đưa chúng về khoảng [0, 1] (Divide the image pixel values by 255 to get them between [0, 1])\n",
    "custom_image = custom_image / 255. \n",
    "\n",
    "# In ra dữ liệu hình ảnh (Print out image data)\n",
    "print(f\"Custom image tensor:\\n{custom_image}\\n\")\n",
    "print(f\"Custom image shape: {custom_image.shape}\\n\")\n",
    "print(f\"Custom image dtype: {custom_image.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Dự đoán trên hình ảnh tùy chỉnh với mô hình PyTorch đã được huấn luyện (Predicting on custom images with a trained PyTorch model)\n",
    "\n",
    "Tuyệt vời, có vẻ như dữ liệu hình ảnh của chúng ta hiện đã có cùng định dạng với những gì mô hình được huấn luyện.\n",
    "\n",
    "Ngoại trừ một điều...\n",
    "\n",
    "Đó là `shape` (hình dạng).\n",
    "\n",
    "Mô hình của chúng ta được huấn luyện trên các hình ảnh có shape `[3, 64, 64]`, trong khi hình ảnh tùy chỉnh của chúng ta hiện tại có shape `[3, 4032, 3024]`.\n",
    "\n",
    "Làm thế nào chúng ta có thể đảm bảo hình ảnh tùy chỉnh có cùng shape với các hình ảnh mà mô hình đã được huấn luyện?\n",
    "\n",
    "Có `torchvision.transforms` nào có thể giúp không?\n",
    "\n",
    "Trước khi trả lời câu hỏi đó, hãy vẽ hình ảnh bằng `matplotlib` để đảm bảo nó trông ổn, hãy nhớ rằng chúng ta sẽ phải permute (hoán vị) các chiều từ `CHW` thành `HWC` để phù hợp với yêu cầu của `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vẽ hình ảnh tùy chỉnh (Plot custom image)\n",
    "plt.imshow(custom_image.permute(1, 2, 0)) # cần permute các chiều hình ảnh từ CHW -> HWC nếu không matplotlib sẽ báo lỗi (need to permute image dimensions from CHW -> HWC otherwise matplotlib will error)\n",
    "plt.title(f\"Image shape: {custom_image.shape}\")\n",
    "plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hai ngón tay cái lên!\n",
    "\n",
    "Bây giờ làm thế nào chúng ta có thể đưa hình ảnh về cùng kích thước với các hình ảnh mà mô hình đã được huấn luyện?\n",
    "\n",
    "Một cách để làm điều đó là với `torchvision.transforms.Resize()`.\n",
    "\n",
    "Hãy tạo một pipeline transform để thực hiện điều đó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo pipeline transform để thay đổi kích thước hình ảnh (Create transform pipleine to resize image)\n",
    "custom_image_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "])\n",
    "\n",
    "# Transform hình ảnh đích (Transform target image)\n",
    "custom_image_transformed = custom_image_transform(custom_image)\n",
    "\n",
    "# In ra shape gốc và shape mới (Print out original shape and new shape)\n",
    "print(f\"Original shape: {custom_image.shape}\")\n",
    "print(f\"New shape: {custom_image_transformed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woohoo!\n",
    "\n",
    "Cuối cùng hãy thực hiện dự đoán trên hình ảnh tùy chỉnh của riêng chúng ta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.eval()\n",
    "with torch.inference_mode():\n",
    "    custom_image_pred = model_1(custom_image_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ôi trời ơi...\n",
    "\n",
    "Mặc dù đã chuẩn bị, hình ảnh tùy chỉnh và mô hình của chúng ta lại ở các thiết bị (devices) khác nhau.\n",
    "\n",
    "Và chúng ta gặp lỗi:\n",
    "\n",
    "> `RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper___slow_conv2d_forward)`\n",
    "\n",
    "Hãy khắc phục điều đó bằng cách đưa `custom_image_transformed` lên thiết bị đích (target device)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.eval()\n",
    "with torch.inference_mode():\n",
    "    custom_image_pred = model_1(custom_image_transformed.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sao thế này?\n",
    "\n",
    "Có vẻ như chúng ta đang gặp lỗi shape.\n",
    "\n",
    "Tại sao lại như vậy?\n",
    "\n",
    "Chúng ta đã chuyển đổi hình ảnh tùy chỉnh để có cùng kích thước với các hình ảnh mà mô hình đã được huấn luyện...\n",
    "\n",
    "Ồ đợi đã...\n",
    "\n",
    "Có một chiều (dimension) mà chúng ta đã quên.\n",
    "\n",
    "Kích thước batch (batch size).\n",
    "\n",
    "Mô hình của chúng ta mong đợi các tensor hình ảnh có chiều kích thước batch ở đầu (`NCHW` trong đó `N` là kích thước batch).\n",
    "\n",
    "Ngoại trừ hình ảnh tùy chỉnh của chúng ta hiện chỉ có `CHW`.\n",
    "\n",
    "Chúng ta có thể thêm chiều kích thước batch bằng cách sử dụng `torch.unsqueeze(dim=0)` để thêm một chiều bổ sung cho hình ảnh và *cuối cùng* thực hiện dự đoán.\n",
    "\n",
    "Về cơ bản, chúng ta sẽ yêu cầu mô hình dự đoán trên một hình ảnh duy nhất (một hình ảnh có `batch_size` là 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.eval()\n",
    "with torch.inference_mode():\n",
    "    # Thêm một chiều bổ sung cho hình ảnh (Add an extra dimension to image)\n",
    "    custom_image_transformed_with_batch_size = custom_image_transformed.unsqueeze(dim=0)\n",
    "    \n",
    "    # In ra các shape khác nhau (Print out different shapes)\n",
    "    print(f\"Custom image transformed shape: {custom_image_transformed.shape}\")\n",
    "    print(f\"Unsqueezed custom image shape: {custom_image_transformed_with_batch_size.shape}\")\n",
    "    \n",
    "    # Thực hiện dự đoán trên hình ảnh với chiều bổ sung (Make a prediction on image with an extra dimension)\n",
    "    custom_image_pred = model_1(custom_image_transformed.unsqueeze(dim=0).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vâng!!!\n",
    "\n",
    "Có vẻ như nó đã hoạt động!\n",
    "\n",
    "> **Lưu ý:** Những gì chúng ta vừa trải qua là ba vấn đề cổ điển và phổ biến nhất của deep learning và PyTorch:\n",
    "> 1. **Sai kiểu dữ liệu (datatypes)** - mô hình của chúng ta mong đợi `torch.float32` trong khi hình ảnh tùy chỉnh gốc của chúng ta là `uint8`.\n",
    "> 2. **Sai thiết bị (device)** - mô hình của chúng ta ở trên `device` đích (trong trường hợp của chúng ta là GPU) trong khi dữ liệu đích chưa được chuyển đến `device` đích.\n",
    "> 3. **Sai shapes** - mô hình của chúng ta mong đợi hình ảnh đầu vào có shape `[N, C, H, W]` hoặc `[batch_size, color_channels, height, width]` trong khi tensor hình ảnh tùy chỉnh của chúng ta có shape `[color_channels, height, width]`.\n",
    ">\n",
    "> Hãy nhớ rằng, những lỗi này không chỉ dành cho việc dự đoán trên hình ảnh tùy chỉnh.\n",
    ">\n",
    "> Chúng sẽ xuất hiện với hầu hết mọi loại dữ liệu (văn bản, âm thanh, dữ liệu có cấu trúc) và vấn đề mà bạn làm việc.\n",
    "\n",
    "Bây giờ hãy xem các dự đoán của mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_image_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Được rồi, những kết quả này vẫn ở *dạng logit* (các đầu ra thô của mô hình được gọi là logits).\n",
    "\n",
    "Hãy chuyển đổi chúng từ logits -> xác suất dự đoán (prediction probabilities) -> nhãn dự đoán (prediction labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In ra prediction logits (Print out prediction logits)\n",
    "print(f\"Prediction logits: {custom_image_pred}\")\n",
    "\n",
    "# Chuyển đổi logits -> xác suất dự đoán (sử dụng torch.softmax() cho phân loại đa lớp) (Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification))\n",
    "custom_image_pred_probs = torch.softmax(custom_image_pred, dim=1)\n",
    "print(f\"Prediction probabilities: {custom_image_pred_probs}\")\n",
    "\n",
    "# Chuyển đổi xác suất dự đoán -> nhãn dự đoán (Convert prediction probabilities -> prediction labels)\n",
    "custom_image_pred_label = torch.argmax(custom_image_pred_probs, dim=1)\n",
    "print(f\"Prediction label: {custom_image_pred_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Được rồi!\n",
    "\n",
    "Trông tốt đấy.\n",
    "\n",
    "Nhưng tất nhiên nhãn dự đoán của chúng ta vẫn ở dạng index/tensor.\n",
    "\n",
    "Chúng ta có thể chuyển đổi nó thành dự đoán tên lớp (class name) dạng chuỗi bằng cách lập chỉ mục (indexing) trên danh sách `class_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tìm nhãn được dự đoán (Find the predicted label)\n",
    "custom_image_pred_class = class_names[custom_image_pred_label.cpu()] # đưa pred label lên CPU, nếu không sẽ báo lỗi (put pred label to CPU, otherwise will error)\n",
    "custom_image_pred_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow.\n",
    "\n",
    "Có vẻ như mô hình dự đoán đúng, mặc dù nó hoạt động kém dựa trên các chỉ số đánh giá (evaluation metrics) của chúng ta.\n",
    "\n",
    "> **Lưu ý:** Mô hình ở dạng hiện tại sẽ dự đoán \"pizza\", \"steak\" hoặc \"sushi\" bất kể hình ảnh nào được đưa vào. Nếu bạn muốn mô hình dự đoán một lớp khác, bạn sẽ phải huấn luyện nó để làm như vậy.\n",
    "\n",
    "Nhưng nếu chúng ta kiểm tra `custom_image_pred_probs`, chúng ta sẽ nhận thấy rằng mô hình gần như cho trọng số bằng nhau (các giá trị tương tự) cho mọi lớp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The values of the prediction probabilities are quite similar\n",
    "custom_image_pred_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có xác suất dự đoán (prediction probabilities) tương tự như thế này có thể có nghĩa là một vài điều:\n",
    "1. Mô hình đang cố gắng dự đoán cả ba lớp cùng một lúc (có thể có một hình ảnh chứa pizza, steak và sushi).\n",
    "2. Mô hình không thực sự biết nó muốn dự đoán gì và do đó chỉ gán các giá trị tương tự cho mỗi lớp.\n",
    "\n",
    "Trường hợp của chúng ta là số 2, vì mô hình được huấn luyện kém, về cơ bản nó đang *đoán* dự đoán."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 Kết hợp dự đoán hình ảnh tùy chỉnh: xây dựng một hàm (Putting custom image prediction together: building a function)\n",
    "\n",
    "Thực hiện tất cả các bước trên mỗi khi bạn muốn thực hiện dự đoán trên hình ảnh tùy chỉnh sẽ nhanh chóng trở nên tẻ nhạt.\n",
    "\n",
    "Vì vậy, hãy kết hợp tất cả chúng lại trong một hàm mà chúng ta có thể dễ dàng sử dụng lặp đi lặp lại.\n",
    "\n",
    "Cụ thể, hãy tạo một hàm:\n",
    "1. Nhận đường dẫn hình ảnh đích (target image path) và chuyển đổi sang kiểu dữ liệu phù hợp cho mô hình (`torch.float32`).\n",
    "2. Đảm bảo các giá trị pixel hình ảnh đích nằm trong khoảng `[0, 1]`.\n",
    "3. Transform hình ảnh đích nếu cần thiết.\n",
    "4. Đảm bảo mô hình ở trên thiết bị đích (target device).\n",
    "5. Thực hiện dự đoán trên hình ảnh đích với mô hình đã được huấn luyện (đảm bảo hình ảnh có kích thước phù hợp và trên cùng thiết bị với mô hình).\n",
    "6. Chuyển đổi các logits đầu ra của mô hình thành xác suất dự đoán.\n",
    "7. Chuyển đổi xác suất dự đoán thành nhãn dự đoán.\n",
    "8. Vẽ hình ảnh đích cùng với dự đoán của mô hình và xác suất dự đoán.\n",
    "\n",
    "Khá nhiều bước nhưng chúng ta có thể làm được!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_and_plot_image(model: torch.nn.Module, \n",
    "                        image_path: str, \n",
    "                        class_names: List[str] = None, \n",
    "                        transform=None,\n",
    "                        device: torch.device = device):\n",
    "    \"\"\"Thực hiện dự đoán trên hình ảnh đích và vẽ hình ảnh với dự đoán của nó. (Makes a prediction on a target image and plots the image with its prediction.)\"\"\"\n",
    "    \n",
    "    # 1. Tải hình ảnh và chuyển đổi các giá trị tensor sang float32 (Load in image and convert the tensor values to float32)\n",
    "    target_image = torchvision.io.read_image(str(image_path)).type(torch.float32)\n",
    "    \n",
    "    # 2. Chia các giá trị pixel hình ảnh cho 255 để đưa chúng về khoảng [0, 1] (Divide the image pixel values by 255 to get them between [0, 1])\n",
    "    target_image = target_image / 255. \n",
    "    \n",
    "    # 3. Transform nếu cần thiết (Transform if necessary)\n",
    "    if transform:\n",
    "        target_image = transform(target_image)\n",
    "    \n",
    "    # 4. Đảm bảo mô hình ở trên thiết bị đích (Make sure the model is on the target device)\n",
    "    model.to(device)\n",
    "    \n",
    "    # 5. Bật chế độ đánh giá mô hình và chế độ inference (Turn on model evaluation mode and inference mode)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Thêm một chiều bổ sung cho hình ảnh (Add an extra dimension to the image)\n",
    "        target_image = target_image.unsqueeze(dim=0)\n",
    "    \n",
    "        # Thực hiện dự đoán trên hình ảnh với chiều bổ sung và gửi nó đến thiết bị đích (Make a prediction on image with an extra dimension and send it to the target device)\n",
    "        target_image_pred = model(target_image.to(device))\n",
    "        \n",
    "    # 6. Chuyển đổi logits -> xác suất dự đoán (sử dụng torch.softmax() cho phân loại đa lớp) (Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification))\n",
    "    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n",
    "\n",
    "    # 7. Chuyển đổi xác suất dự đoán -> nhãn dự đoán (Convert prediction probabilities -> prediction labels)\n",
    "    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n",
    "    \n",
    "    # 8. Vẽ hình ảnh cùng với dự đoán và xác suất dự đoán (Plot the image alongside the prediction and prediction probability)\n",
    "    plt.imshow(target_image.squeeze().permute(1, 2, 0)) # đảm bảo nó có kích thước phù hợp cho matplotlib (make sure it's the right size for matplotlib)\n",
    "    if class_names:\n",
    "        title = f\"Pred: {class_names[target_image_pred_label.cpu()]} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
    "    else: \n",
    "        title = f\"Pred: {target_image_pred_label} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
    "    plt.title(title)\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thật là một hàm đẹp, hãy thử nghiệm nó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán trên hình ảnh tùy chỉnh của chúng ta (Pred on our custom image)\n",
    "pred_and_plot_image(model=model_1,\n",
    "                    image_path=custom_image_path,\n",
    "                    class_names=class_names,\n",
    "                    transform=custom_image_transform,\n",
    "                    device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hai ngón tay cái lên một lần nữa!\n",
    "\n",
    "Có vẻ như mô hình của chúng ta dự đoán đúng chỉ bằng cách đoán.\n",
    "\n",
    "Tuy nhiên, điều này sẽ không phải lúc nào cũng xảy ra với các hình ảnh khác...\n",
    "\n",
    "Hình ảnh cũng bị pixelated (vì chúng ta đã thay đổi kích thước nó thành `[64, 64]` bằng cách sử dụng `custom_image_transform`.\n",
    "\n",
    "> **Bài tập:** Thử thực hiện dự đoán với một trong những hình ảnh pizza, steak hoặc sushi của riêng bạn và xem điều gì xảy ra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Những điểm chính (Main takeaways)\n",
    "\n",
    "Chúng ta đã đề cập khá nhiều điều trong module này.\n",
    "\n",
    "Hãy tóm tắt nó bằng một số điểm chính.\n",
    "\n",
    "* PyTorch có nhiều hàm tích hợp để xử lý tất cả các loại dữ liệu, từ thị giác đến văn bản đến âm thanh đến hệ thống đề xuất (recommendation systems).\n",
    "* Nếu các hàm tải dữ liệu tích hợp của PyTorch không phù hợp với yêu cầu của bạn, bạn có thể viết code để tạo các tập dữ liệu tùy chỉnh (custom datasets) của riêng mình bằng cách kế thừa `torch.utils.data.Dataset`.\n",
    "* `torch.utils.data.DataLoader` trong PyTorch giúp biến `Dataset` của bạn thành các iterables có thể được sử dụng khi huấn luyện và kiểm tra mô hình.\n",
    "* Một phần lớn của machine learning là xử lý sự cân bằng giữa **overfitting** và **underfitting** (chúng ta đã thảo luận các phương pháp khác nhau cho mỗi loại ở trên, vì vậy một bài tập tốt sẽ là nghiên cứu thêm và viết code để thử các kỹ thuật khác nhau).\n",
    "* Dự đoán trên dữ liệu tùy chỉnh của riêng bạn với mô hình đã được huấn luyện là có thể, miễn là bạn định dạng dữ liệu thành định dạng tương tự với những gì mô hình đã được huấn luyện. Hãy đảm bảo bạn chú ý đến ba lỗi lớn của PyTorch và deep learning:\n",
    "    1. **Sai kiểu dữ liệu (datatypes)** - Mô hình của bạn mong đợi `torch.float32` khi dữ liệu của bạn là `torch.uint8`.\n",
    "    2. **Sai shapes dữ liệu** - Mô hình của bạn mong đợi `[batch_size, color_channels, height, width]` khi dữ liệu của bạn là `[color_channels, height, width]`.\n",
    "    3. **Sai thiết bị (devices)** - Mô hình của bạn ở trên GPU nhưng dữ liệu của bạn ở trên CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bài tập (Exercises)\n",
    "\n",
    "Tất cả các bài tập đều tập trung vào việc thực hành code trong các phần ở trên.\n",
    "\n",
    "Bạn có thể hoàn thành chúng bằng cách tham khảo từng phần hoặc theo (các) tài liệu được liên kết.\n",
    "\n",
    "Tất cả bài tập nên được hoàn thành bằng cách sử dụng [device-agnostic code](https://pytorch.org/docs/stable/notes/cuda.html#device-agnostic-code).\n",
    "\n",
    "**Tài liệu:**\n",
    "* [Exercise template notebook cho 04](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/04_pytorch_custom_datasets_exercises.ipynb)\n",
    "* [Example solutions notebook cho 04](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/04_pytorch_custom_datasets_exercise_solutions.ipynb) (hãy thử các bài tập *trước khi* xem cái này)\n",
    "\n",
    "1. Các mô hình của chúng ta đang hoạt động kém (không fit dữ liệu tốt). 3 phương pháp để ngăn chặn underfitting là gì? Viết chúng ra và giải thích từng cái bằng một câu.\n",
    "2. Tái tạo các hàm tải dữ liệu mà chúng ta đã xây dựng trong các phần 1, 2, 3 và 4. Bạn nên có `DataLoader` train và test sẵn sàng để sử dụng.\n",
    "3. Tái tạo `model_0` mà chúng ta đã xây dựng trong phần 7.\n",
    "4. Tạo các hàm training và testing cho `model_0`.\n",
    "5. Thử huấn luyện mô hình mà bạn đã tạo trong bài tập 3 cho 5, 20 và 50 epochs, điều gì xảy ra với kết quả?\n",
    "    * Sử dụng `torch.optim.Adam()` với learning rate 0.001 làm optimizer.\n",
    "6. Tăng gấp đôi số hidden units trong mô hình của bạn và huấn luyện nó trong 20 epochs, điều gì xảy ra với kết quả?\n",
    "7. Tăng gấp đôi dữ liệu bạn đang sử dụng với mô hình và huấn luyện nó trong 20 epochs, điều gì xảy ra với kết quả?\n",
    "    * **Lưu ý:** Bạn có thể sử dụng [custom data creation notebook](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb) để mở rộng quy mô Food101 dataset của bạn.\n",
    "    * Bạn cũng có thể tìm thấy [already formatted double data (20% instead of 10% subset) dataset trên GitHub](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi_20_percent.zip), bạn sẽ cần viết code tải xuống như trong bài tập 2 để đưa nó vào notebook này.\n",
    "8. Thực hiện dự đoán trên hình ảnh tùy chỉnh của riêng bạn về pizza/steak/sushi (bạn thậm chí có thể tải xuống một cái từ internet) và chia sẻ dự đoán của bạn.\n",
    "    * Mô hình mà bạn đã huấn luyện trong bài tập 7 có dự đoán đúng không?\n",
    "    * Nếu không, bạn nghĩ bạn có thể làm gì để cải thiện nó?\n",
    "\n",
    "## Chương trình ngoại khóa (Extra-curriculum)\n",
    "\n",
    "* Để thực hành kiến thức của bạn về PyTorch `Dataset` và `DataLoader` thông qua PyTorch [datasets and dataloaders tutorial notebook](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html).\n",
    "* Dành 10 phút đọc [PyTorch `torchvision.transforms` documentation](https://pytorch.org/vision/stable/transforms.html).\n",
    "    * Bạn có thể xem các demo về transforms đang hoạt động trong [illustrations of transforms tutorial](https://pytorch.org/vision/main/auto_examples/transforms/plot_transforms_illustrations.html).\n",
    "* Dành 10 phút đọc PyTorch [`torchvision.datasets` documentation](https://pytorch.org/vision/stable/datasets.html).\n",
    "    * Một số datasets nào nổi bật với bạn?\n",
    "    * Bạn có thể thử xây dựng mô hình trên những cái này như thế nào?\n",
    "* [TorchData hiện đang ở phiên bản beta](https://pytorch.org/data/beta/index.html) (tính đến tháng 4 năm 2022), nó sẽ là cách tương lai để tải dữ liệu trong PyTorch, nhưng bạn có thể bắt đầu kiểm tra nó ngay bây giờ.\n",
    "* Để tăng tốc các mô hình deep learning, bạn có thể thực hiện một vài thủ thuật để cải thiện tính toán compute, memory và overhead, để biết thêm hãy đọc bài viết [*Making Deep Learning Go Brrrr From First Principles*](https://horace.io/brrr_intro.html) của Horace He."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fbe1355223f7b2ffc113ba3ade6a2b520cadace5d5ec3e828c83ce02eb221bf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
