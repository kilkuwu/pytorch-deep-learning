{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/00_pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSNK7duj5SeU"
   },
   "source": [
    "# 00. Kiến thức cơ bản về PyTorch\n",
    "\n",
    "## PyTorch là gì?\n",
    "\n",
    "[PyTorch](https://pytorch.org/) là một framework học máy và học sâu mã nguồn mở.\n",
    "\n",
    "## PyTorch có thể được sử dụng để làm gì?\n",
    "\n",
    "PyTorch cho phép bạn thao tác và xử lý dữ liệu cũng như viết các thuật toán học máy bằng mã Python.\n",
    "\n",
    "## Ai sử dụng PyTorch?\n",
    "\n",
    "Nhiều công ty công nghệ lớn nhất thế giới như [Meta (Facebook)](https://ai.facebook.com/blog/pytorch-builds-the-future-of-ai-and-machine-learning-at-facebook/), Tesla và Microsoft cũng như các công ty nghiên cứu trí tuệ nhân tạo như [OpenAI sử dụng PyTorch](https://openai.com/blog/openai-pytorch/) để hỗ trợ nghiên cứu và đưa học máy vào các sản phẩm của họ.\n",
    "\n",
    "![pytorch được sử dụng trong ngành và nghiên cứu](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-being-used-across-research-and-industry.png)\n",
    "\n",
    "Ví dụ, Andrej Karpathy (trưởng phòng AI tại Tesla) đã có nhiều bài thuyết trình ([PyTorch DevCon 2019](https://youtu.be/oBklltKXtDE), [Tesla AI Day 2021](https://youtu.be/j0z4FweCy4M?t=2904)) về cách Tesla sử dụng PyTorch để vận hành các mô hình thị giác máy tính tự lái của họ.\n",
    "\n",
    "PyTorch cũng được sử dụng trong các ngành khác như nông nghiệp để [hỗ trợ thị giác máy tính trên máy kéo](https://medium.com/pytorch/ai-for-ag-production-machine-learning-for-agriculture-e8cfdb9849a1).\n",
    "\n",
    "## Tại sao nên sử dụng PyTorch?\n",
    "\n",
    "Các nhà nghiên cứu học máy yêu thích sử dụng PyTorch. Và tính đến tháng 2 năm 2022, PyTorch là [framework học sâu được sử dụng nhiều nhất trên Papers With Code](https://paperswithcode.com/trends), một trang web để theo dõi các bài báo nghiên cứu học máy và các kho mã nguồn đi kèm.\n",
    "\n",
    "PyTorch cũng giúp xử lý nhiều việc như tăng tốc GPU (làm cho mã của bạn chạy nhanh hơn) ở hậu trường.\n",
    "\n",
    "Vì vậy bạn có thể tập trung vào thao tác dữ liệu và viết thuật toán còn PyTorch sẽ đảm bảo nó chạy nhanh.\n",
    "\n",
    "Và nếu các công ty như Tesla và Meta (Facebook) sử dụng nó để xây dựng các mô hình họ triển khai để vận hành hàng trăm ứng dụng, lái hàng nghìn xe hơi và cung cấp nội dung cho hàng tỷ người, thì rõ ràng nó cũng có khả năng phát triển mạnh mẽ.\n",
    "\n",
    "## Những gì chúng ta sẽ đề cập trong module này\n",
    "\n",
    "Khóa học này được chia thành các phần khác nhau (notebooks).\n",
    "\n",
    "Mỗi notebook bao gồm những ý tưởng và khái niệm quan trọng trong PyTorch.\n",
    "\n",
    "Các notebook tiếp theo xây dựng dựa trên kiến thức từ notebook trước đó (đánh số bắt đầu từ 00, 01, 02 và tiếp tục cho đến số cuối cùng).\n",
    "\n",
    "Notebook này đề cập đến khối xây dựng cơ bản của học máy và học sâu, đó là tensor.\n",
    "\n",
    "Cụ thể, chúng ta sẽ đề cập:\n",
    "\n",
    "| **Chủ đề** | **Nội dung** |\n",
    "| ----- | ----- |\n",
    "| **Giới thiệu về tensors** | Tensors là khối xây dựng cơ bản của tất cả học máy và học sâu. |\n",
    "| **Tạo tensors** | Tensors có thể biểu diễn hầu hết mọi loại dữ liệu (hình ảnh, từ ngữ, bảng số). |\n",
    "| **Lấy thông tin từ tensors** | Nếu bạn có thể đưa thông tin vào tensor, bạn cũng sẽ muốn lấy nó ra. |\n",
    "| **Thao tác tensors** | Các thuật toán học máy (như mạng nơ-ron) bao gồm việc thao tác tensors theo nhiều cách khác nhau như cộng, nhân, kết hợp. | \n",
    "| **Xử lý hình dạng tensor** | Một trong những vấn đề phổ biến nhất trong học máy là xử lý sự không khớp hình dạng (cố gắng trộn tensors có hình dạng sai với tensors khác). |\n",
    "| **Lập chỉ mục trên tensors** | Nếu bạn đã từng lập chỉ mục trên danh sách Python hoặc mảng NumPy, nó rất tương tự với tensors, ngoại trừ chúng có thể có nhiều chiều hơn rất nhiều. |\n",
    "| **Kết hợp tensors PyTorch và NumPy** | PyTorch làm việc với tensors ([`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html)), NumPy thích arrays ([`np.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html)) đôi khi bạn sẽ muốn kết hợp và sử dụng cả hai. | \n",
    "| **Tính tái tạo** | Học máy rất thực nghiệm và vì nó sử dụng nhiều *tính ngẫu nhiên* để hoạt động, đôi khi bạn sẽ muốn *tính ngẫu nhiên* đó không quá ngẫu nhiên. |\n",
    "| **Chạy tensors trên GPU** | GPUs (Graphics Processing Units) làm cho mã của bạn nhanh hơn, PyTorch giúp bạn dễ dàng chạy mã trên GPUs. |\n",
    "\n",
    "## Bạn có thể tìm trợ giúp ở đâu?\n",
    "\n",
    "Tất cả tài liệu cho khóa học này [có trên GitHub](https://github.com/mrdbourke/pytorch-deep-learning).\n",
    "\n",
    "Và nếu bạn gặp khó khăn, bạn có thể đặt câu hỏi trên [trang Discussions](https://github.com/mrdbourke/pytorch-deep-learning/discussions) ở đó.\n",
    "\n",
    "Ngoài ra còn có [diễn đàn nhà phát triển PyTorch](https://discuss.pytorch.org/), một nơi rất hữu ích cho mọi thứ liên quan đến PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5v3iRCRUTGeu"
   },
   "source": [
    "## Import PyTorch\n",
    "\n",
    "> **Lưu ý:** Trước khi chạy bất kỳ mã nào trong notebook này, bạn nên đã thực hiện [các bước cài đặt PyTorch](https://pytorch.org/get-started/locally/). \n",
    ">\n",
    "> Tuy nhiên, **nếu bạn đang chạy trên Google Colab**, mọi thứ sẽ hoạt động (Google Colab đi kèm với PyTorch và các thư viện khác đã được cài đặt).\n",
    "\n",
    "Hãy bắt đầu bằng cách import PyTorch và kiểm tra phiên bản chúng ta đang sử dụng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1VxEOik46Y4i",
    "outputId": "f3141076-29bc-4600-c1c3-1586b1fe2292"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1+cu116'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SqvI4S9TGew"
   },
   "source": [
    "Tuyệt vời, có vẻ như chúng ta đã có PyTorch 1.10.0+. \n",
    "\n",
    "Điều này có nghĩa nếu bạn đang theo dõi các tài liệu này, bạn sẽ thấy sự tương thích tốt nhất với PyTorch 1.10.0+, tuy nhiên nếu số phiên bản của bạn cao hơn nhiều so với đó, bạn có thể nhận thấy một số sự không nhất quán. \n",
    "\n",
    "Và nếu bạn gặp bất kỳ vấn đề nào, vui lòng đăng trên [trang GitHub Discussions của khóa học](https://github.com/mrdbourke/pytorch-deep-learning/discussions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-33BKR16iWc"
   },
   "source": [
    "## Giới thiệu về tensors \n",
    "\n",
    "Bây giờ chúng ta đã import PyTorch, đã đến lúc tìm hiểu về tensors.\n",
    "\n",
    "Tensors là khối xây dựng cơ bản của học máy.\n",
    "\n",
    "Công việc của chúng là biểu diễn dữ liệu theo cách số học.\n",
    "\n",
    "Ví dụ, bạn có thể biểu diễn một hình ảnh như một tensor với shape `[3, 224, 224]` có nghĩa là `[colour_channels, height, width]`, tức là hình ảnh có `3` kênh màu (đỏ, xanh lá, xanh dương), chiều cao `224` pixel và chiều rộng `224` pixel.\n",
    "\n",
    "![ví dụ về việc chuyển từ hình ảnh đầu vào thành biểu diễn tensor của hình ảnh, hình ảnh được chia thành 3 kênh màu cũng như các số để biểu diễn chiều cao và chiều rộng](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-tensor-shape-example-of-image.png)\n",
    "\n",
    "Trong ngôn ngữ tensor (ngôn ngữ được sử dụng để mô tả tensors), tensor sẽ có ba chiều, một cho `colour_channels`, `height` và `width`.\n",
    "\n",
    "Nhưng chúng ta đang vượt quá xa.\n",
    "\n",
    "Hãy tìm hiểu thêm về tensors bằng cách lập trình chúng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFF0N2TU7S7Q"
   },
   "source": [
    "### Tạo tensors \n",
    "\n",
    "PyTorch yêu thích tensors. Yêu thích đến mức có cả một trang tài liệu dành riêng cho lớp [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html).\n",
    "\n",
    "Bài tập đầu tiên của bạn là [đọc qua tài liệu về `torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) trong 10 phút. Nhưng bạn có thể để dành việc đó cho sau.\n",
    "\n",
    "Hãy bắt đầu lập trình.\n",
    "\n",
    "Điều đầu tiên chúng ta sẽ tạo là một **scalar**.\n",
    "\n",
    "Scalar là một số đơn và trong ngôn ngữ tensor nó là một tensor không chiều.\n",
    "\n",
    "> **Lưu ý:** Đó là một xu hướng cho khóa học này. Chúng ta sẽ tập trung vào viết mã cụ thể. Nhưng thường tôi sẽ đặt ra các bài tập liên quan đến việc đọc và làm quen với tài liệu PyTorch. Bởi vì suy cho cùng, một khi bạn hoàn thành khóa học này, chắc chắn bạn sẽ muốn học thêm. Và tài liệu là nơi bạn sẽ thường xuyên ghé thăm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YUDgG2zk7Us5",
    "outputId": "0ac22bd2-16bc-4307-f312-31ae89d6c375"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqSuhW7rTGey"
   },
   "source": [
    "Thấy cách phía trên in ra `tensor(7)` không?\n",
    "\n",
    "Điều đó có nghĩa là mặc dù `scalar` là một số đơn, nó có kiểu `torch.Tensor`.\n",
    "\n",
    "Chúng ta có thể kiểm tra số chiều của một tensor bằng cách sử dụng thuộc tính `ndim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lV98Yz868bav",
    "outputId": "502a625e-ff3c-4fc4-b523-f7634ea82128"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZO2YW_QGTGez"
   },
   "source": [
    "Nếu chúng ta muốn lấy số từ tensor thì sao?\n",
    "\n",
    "Tức là, chuyển nó từ `torch.Tensor` thành một số nguyên Python?\n",
    "\n",
    "Để làm điều đó chúng ta có thể sử dụng phương thức `item()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-k4cyKumPfbE",
    "outputId": "1f6a7916-0c7c-403f-8ebd-875454a94470"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the Python number within a tensor (only works with one-element tensors)\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYs7ulrATGe0"
   },
   "source": [
    "Được rồi, bây giờ hãy xem một **vector**.\n",
    "\n",
    "Vector là một tensor một chiều nhưng có thể chứa nhiều số.\n",
    "\n",
    "Tức là, bạn có thể có một vector `[3, 2]` để mô tả `[phòng ngủ, phòng tắm]` trong ngôi nhà của bạn. Hoặc bạn có thể có `[3, 2, 2]` để mô tả `[phòng ngủ, phòng tắm, chỗ đậu xe]` trong ngôi nhà của bạn.\n",
    "\n",
    "Xu hướng quan trọng ở đây là vector linh hoạt trong việc nó có thể biểu diễn gì (tương tự với tensors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-IZF6ASs8QH9",
    "outputId": "e556ed2a-e58a-440f-b103-0f06c91bc75c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXxRUUW2TGe1"
   },
   "source": [
    "Tuyệt vời, `vector` bây giờ chứa hai số 7, số yêu thích của tôi.\n",
    "\n",
    "Bạn nghĩ nó sẽ có bao nhiêu chiều?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03hm3VVv8kr4",
    "outputId": "2035bb26-0189-4b28-fa02-34220d44677f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of dimensions of vector\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0VYvSGbTGe1"
   },
   "source": [
    "Hmm, thật lạ, `vector` chứa hai số nhưng chỉ có một chiều duy nhất.\n",
    "\n",
    "Tôi sẽ cho bạn biết một mẹo.\n",
    "\n",
    "Bạn có thể biết số chiều của một tensor trong PyTorch bằng số dấu ngoặc vuông ở phía ngoài (`[`) và bạn chỉ cần đếm một bên.\n",
    "\n",
    "`vector` có bao nhiêu dấu ngoặc vuông?\n",
    "\n",
    "Một khái niệm quan trọng khác cho tensors là thuộc tính `shape` của chúng. Shape cho bạn biết các phần tử bên trong chúng được sắp xếp như thế nào.\n",
    "\n",
    "Hãy kiểm tra shape của `vector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6zREV1bDTGe2",
    "outputId": "2a6e7ceb-7eb2-422b-b006-2c6e4825272f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of vector\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aWKppNyTGe2"
   },
   "source": [
    "Phía trên trả về `torch.Size([2])` có nghĩa là vector của chúng ta có shape là `[2]`. Điều này là do hai phần tử chúng ta đặt bên trong dấu ngoặc vuông (`[7, 7]`).\n",
    "\n",
    "Bây giờ hãy xem một **matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5iNwCYL8QO9",
    "outputId": "88fc63a7-4130-4c7a-a574-c61e85d2e99e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "MATRIX = torch.tensor([[7, 8], \n",
    "                       [9, 10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3U1bCdjTGe3"
   },
   "source": [
    "Wow! Nhiều số hơn! Matrices linh hoạt như vectors, ngoại trừ chúng có thêm một chiều."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8LREUbeb8r8j",
    "outputId": "636246b0-b109-472a-c6d5-8601a9e08654"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of dimensions\n",
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhXXgq-dTGe3"
   },
   "source": [
    "`MATRIX` có hai chiều (bạn có đếm số dấu ngoặc vuông ở phía ngoài của một bên không?).\n",
    "\n",
    "Bạn nghĩ nó sẽ có `shape` như thế nào?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_TL26I31TGe3",
    "outputId": "f05ec0b6-0bc1-4381-9474-56cbe6c67139"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvLpUvrKTGe4"
   },
   "source": [
    "Chúng ta nhận được đầu ra `torch.Size([2, 2])` vì `MATRIX` có độ sâu hai phần tử và chiều rộng hai phần tử.\n",
    "\n",
    "Còn việc tạo một **tensor** thì sao?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEMDQr188QWW",
    "outputId": "4230e6bd-1844-4210-eea8-245bb8b8b265"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmJKkXD7TGe4"
   },
   "source": [
    "Woah! Một tensor đẹp quá!\n",
    "\n",
    "Tôi muốn nhấn mạnh rằng tensors có thể biểu diễn hầu hết mọi thứ. \n",
    "\n",
    "Tensor chúng ta vừa tạo có thể là số liệu bán hàng cho một cửa hàng thịt bò và bơ hạnh nhân (hai trong số những thực phẩm yêu thích của tôi).\n",
    "\n",
    "![một tensor đơn giản trong google sheets hiển thị ngày trong tuần, doanh số bán thịt bò và doanh số bán bơ hạnh nhân](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_simple_tensor.png)\n",
    "\n",
    "Bạn nghĩ nó có bao nhiêu chiều? (gợi ý: sử dụng mẹo đếm dấu ngoặc vuông)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8dhuEsjS8QcT",
    "outputId": "7a45df1b-fc32-4cc5-e330-527c6ef7ba5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of dimensions for TENSOR\n",
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ln9dys5VTGe4"
   },
   "source": [
    "Còn shape của nó thì sao?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hdVv4iNRTGe5",
    "outputId": "d8ac706c-020b-4926-b145-d44e41f35e90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of TENSOR\n",
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxk8GU7oTGe5"
   },
   "source": [
    "Được rồi, nó xuất ra `torch.Size([1, 3, 3])`.\n",
    "\n",
    "Các chiều đi từ ngoài vào trong.\n",
    "\n",
    "Điều đó có nghĩa là có 1 chiều của 3 x 3.\n",
    "\n",
    "![ví dụ về các chiều tensor khác nhau](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-different-tensor-dimensions.png)\n",
    "\n",
    "> **Lưu ý:** Bạn có thể nhận thấy tôi sử dụng chữ thường cho `scalar` và `vector` và chữ hoa cho `MATRIX` và `TENSOR`. Điều này là có chủ ý. Trong thực tế, bạn sẽ thường thấy scalars và vectors được ký hiệu bằng chữ thường như `y` hoặc `a`. Và matrices và tensors được ký hiệu bằng chữ hoa như `X` hoặc `W`.\n",
    ">\n",
    "> Bạn cũng có thể nhận thấy tên matrix và tensor được sử dụng thay thế cho nhau. Điều này phổ biến. Vì trong PyTorch bạn thường xuyên xử lý với `torch.Tensor`s (do đó có tên tensor), tuy nhiên, shape và chiều của những gì bên trong sẽ quyết định nó thực sự là gì.\n",
    "\n",
    "Hãy tóm tắt.\n",
    "\n",
    "| Tên | Nó là gì? | Số chiều | Chữ thường hay chữ hoa (thường/ví dụ) |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "| **scalar** | một số đơn | 0 | Thường (`a`) | \n",
    "| **vector** | một số có hướng (ví dụ: tốc độ gió với hướng) nhưng cũng có thể có nhiều số khác | 1 | Thường (`y`) |\n",
    "| **matrix** | một mảng 2 chiều các số | 2 | Hoa (`Q`) |\n",
    "| **tensor** | một mảng n chiều các số | có thể là bất kỳ số nào, tensor 0 chiều là scalar, tensor 1 chiều là vector | Hoa (`X`) | \n",
    "\n",
    "![scalar vector matrix tensor và chúng trông như thế nào](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-scalar-vector-matrix-tensor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dms7G4nkTGe5"
   },
   "source": [
    "### Random tensors\n",
    "\n",
    "Chúng ta đã thiết lập rằng tensors biểu diễn một số dạng dữ liệu.\n",
    "\n",
    "Và các mô hình học máy như mạng nơ-ron thao tác và tìm kiếm các mẫu trong tensors.\n",
    "\n",
    "Nhưng khi xây dựng các mô hình học máy với PyTorch, hiếm khi bạn tạo tensors bằng tay (như những gì chúng ta đang làm).\n",
    "\n",
    "Thay vào đó, một mô hình học máy thường bắt đầu với các tensors ngẫu nhiên lớn các số và điều chỉnh những số ngẫu nhiên này khi nó làm việc qua dữ liệu để biểu diễn tốt hơn.\n",
    "\n",
    "Về bản chất:\n",
    "\n",
    "`Bắt đầu với số ngẫu nhiên -> xem dữ liệu -> cập nhật số ngẫu nhiên -> xem dữ liệu -> cập nhật số ngẫu nhiên...`\n",
    "\n",
    "Với tư cách là một nhà khoa học dữ liệu, bạn có thể định nghĩa cách mô hình học máy bắt đầu (khởi tạo), xem dữ liệu (biểu diễn) và cập nhật (tối ưu hóa) các số ngẫu nhiên của nó.\n",
    "\n",
    "Chúng ta sẽ thực hành với các bước này sau.\n",
    "\n",
    "Bây giờ, hãy xem cách tạo một tensor các số ngẫu nhiên.\n",
    "\n",
    "Chúng ta có thể làm điều đó bằng cách sử dụng [`torch.rand()`](https://pytorch.org/docs/stable/generated/torch.rand.html) và truyền vào tham số `size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EOJEtDx--GnK",
    "outputId": "2680d44b-e31c-4ab1-d5b1-c0cd76706a0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6541, 0.4807, 0.2162, 0.6168],\n",
       "         [0.4428, 0.6608, 0.6194, 0.8620],\n",
       "         [0.2795, 0.6055, 0.4958, 0.5483]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3, 4)\n",
    "random_tensor = torch.rand(size=(3, 4))\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wB1c_cXTGe5"
   },
   "source": [
    "Thật tuyệt! Chúng ta có một tensor với 3 hàng và 4 cột với các giá trị ngẫu nhiên.\n",
    "\n",
    "Những số này đến từ đâu?\n",
    "\n",
    "Chúng được lấy mẫu từ phân phối đồng nhất trong khoảng `[0, 1)`.\n",
    "\n",
    "Và hình dạng của `random_tensor` là gì?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xMF_NUp3Ym__",
    "outputId": "8346b853-0b1e-481a-d9ee-a410ee21bab0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (224, 224, 3)\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MQNTY0eTGe6"
   },
   "source": [
    "Tuyệt vời!\n",
    "\n",
    "Bạn cũng có thể tạo một tensor ngẫu nhiên với cùng hình dạng như một tensor khác."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oCzhd0hl9Vp6",
    "outputId": "9c8ec87f-d8c9-4751-a13e-6a5e986daaa9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros, zeros.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDQBZJRUZWTN"
   },
   "source": [
    "### Tạo một tensor toàn số không hoặc toàn số một\n",
    "\n",
    "Đôi khi bạn sẽ muốn điền một tensor với toàn số một hoặc toàn số không.\n",
    "\n",
    "Bạn có thể làm điều đó với [`torch.zeros()`](https://pytorch.org/docs/stable/generated/torch.zeros.html) và [`torch.ones()`](https://pytorch.org/docs/stable/generated/torch.ones.html) tương ứng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HRe6sSXiTGe6",
    "outputId": "3f45b0b8-7f65-423d-c664-f5b5f7866fd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones, ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hib1NYrSarL2"
   },
   "source": [
    "### Tạo một dãy tensors\n",
    "\n",
    "Đôi khi bạn có thể muốn tạo một dãy số, chẳng hạn 1 đến 10 hoặc 0 đến 100.\n",
    "\n",
    "Bạn có thể sử dụng [`torch.arange(start, end, step)`](https://pytorch.org/docs/stable/generated/torch.arange.html) để làm điều đó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1IqUs81d9W4W",
    "outputId": "2a6f0c08-052e-4b36-b4eb-6a537239026f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695928/193451495.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.arange(), torch.range() is deprecated \n",
    "zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future\n",
    "\n",
    "# Create a range of values 0 to 10\n",
    "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-bXf0Ugbh-D"
   },
   "source": [
    "Bạn cũng có thể tạo tensors tương tự như các tensor khác."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZvXwUut5BhHq",
    "outputId": "096b2f8e-8c21-4ace-97b9-c36b92b2fe77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also create a tensor of zeros similar to another tensor\n",
    "ten_zeros = torch.zeros_like(input=zero_to_ten) # will have same shape\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huKZ6QlYTGe7"
   },
   "source": [
    "## Kiểu dữ liệu tensor\n",
    "\n",
    "Tensor datatype là một trong ba lỗi lớn bạn sẽ gặp phải với PyTorch & deep learning:\n",
    "1. Tensors không có đúng `datatype`\n",
    "2. Tensors không có đúng `shape` \n",
    "3. Tensors không ở trên đúng `device`\n",
    "\n",
    "Chúng ta sẽ khám phá mỗi cái một.\n",
    "\n",
    "Đầu tiên, datatype.\n",
    "\n",
    "Datatype của tensor đề cập đến kiểu dữ liệu của dữ liệu được lưu trữ bên trong.\n",
    "\n",
    "Ví dụ, nếu bạn tạo một tensor với `torch.float32`, tất cả dữ liệu bên trong đó sẽ có kiểu số thực dấu phẩy động 32-bit.\n",
    "\n",
    "Và nếu bạn tạo một tensor với `torch.int64` (hoặc `torch.long`), dữ liệu bên trong sẽ có kiểu số nguyên dài.\n",
    "\n",
    "Datatype nào bạn sử dụng sẽ phụ thuộc vào kiểu dữ liệu bạn đang lưu trữ và mức độ chính xác bạn muốn.\n",
    "\n",
    "Higher precision = sử dụng nhiều bộ nhớ hơn, lower precision = sử dụng ít bộ nhớ hơn.\n",
    "\n",
    "Nói chung, mặc định của PyTorch thường là `torch.float32` và `torch.long` là những lựa chọn tốt cho hầu hết các trường hợp sử dụng.\n",
    "\n",
    "  * Xem [tài liệu PyTorch để biết danh sách tất cả các kiểu dữ liệu tensor có sẵn](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
    "  * Đọc [trang Wikipedia để có cái nhìn tổng quan về độ chính xác trong điện toán](https://en.wikipedia.org/wiki/Precision_(computer_science)) là gì.\n",
    "\n",
    "Hãy xem cách tạo một số tensors với các kiểu dữ liệu cụ thể. Chúng ta có thể làm như vậy bằng cách sử dụng tham số `dtype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q3MoGnpw9XaF",
    "outputId": "61070939-8c52-4ac6-bed7-e64b3ce24615"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                               device=None, # defaults to None, which uses the default tensor type\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhP8kzDfe_ty"
   },
   "source": [
    "Ngoài các vấn đề về shape (hình dạng tensor không khớp), hai vấn đề phổ biến khác bạn sẽ gặp trong PyTorch là vấn đề về datatype và device.\n",
    "\n",
    "Ví dụ, một trong các tensors là `torch.float32` và cái khác là `torch.float16` (PyTorch thường thích tensors có cùng định dạng).\n",
    "\n",
    "Hoặc một trong các tensors của bạn ở trên CPU và cái khác ở trên GPU (PyTorch thích các phép tính giữa tensors ở trên cùng một device).\n",
    "\n",
    "Chúng ta sẽ thấy thêm về chuyện device này sau.\n",
    "\n",
    "Bây giờ hãy tạo một tensor với `dtype=torch.float16`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKSuajld_09s",
    "outputId": "cbac29d9-3371-4fe1-b47c-3af4623b5fbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=torch.float16) # torch.half would also work\n",
    "\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUjkB2AX7Upz"
   },
   "source": [
    "## Lấy thông tin từ tensors\n",
    "\n",
    "Một khi bạn đã tạo tensors (hoặc ai đó khác hoặc một module PyTorch đã tạo chúng cho bạn), bạn có thể muốn lấy một số thông tin từ chúng.\n",
    "\n",
    "Chúng ta đã thấy những điều này trước đây nhưng ba trong số những thuộc tính phổ biến nhất bạn sẽ muốn tìm hiểu về tensors là:\n",
    "* `shape` - tensor có hình dạng như thế nào? (một số phép toán yêu cầu các quy tắc shape cụ thể)\n",
    "* `dtype` - các phần tử trong tensor được lưu trữ trong kiểu dữ liệu nào?\n",
    "* `device` - tensor được lưu trữ trên device nào? (thường là GPU hoặc CPU)\n",
    "\n",
    "Hãy tạo một tensor ngẫu nhiên và tìm hiểu chi tiết về nó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hd_X4D0j7Umq",
    "outputId": "86045713-ab36-4c8e-840c-e788f80c5266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4688, 0.0055, 0.8551, 0.0646],\n",
      "        [0.6538, 0.5157, 0.4071, 0.2109],\n",
      "        [0.9960, 0.3061, 0.9369, 0.7008]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "\n",
    "# Find out details about it\n",
    "print(some_tensor)\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45K-E5uPg6cj"
   },
   "source": [
    "> **Lưu ý:** Khi bạn gặp vấn đề trong PyTorch, nó rất thường liên quan đến một trong ba thuộc tính ở trên. Vì vậy khi thông báo lỗi xuất hiện, hãy hát cho mình một bài hát nhỏ có tên \"gì gì ở đâu\": \n",
    "  * \"*tensor của tôi có hình dạng gì? chúng có kiểu dữ liệu gì và chúng được lưu ở đâu? hình dạng gì, kiểu dữ liệu gì, ở đâu ở đâu ở đâu*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdiWvoAi7UjL"
   },
   "source": [
    "## Thao tác tensors (các phép toán tensor)\n",
    "\n",
    "Trong deep learning, dữ liệu (hình ảnh, văn bản, video, âm thanh, cấu trúc protein, v.v.) được biểu diễn dưới dạng tensors.\n",
    "\n",
    "Một mô hình học bằng cách khám phá những tensors đó và thực hiện một loạt các phép toán (có thể là 1.000.000+ phép toán) trên tensors để tạo ra một biểu diễn của các mẫu trong dữ liệu đầu vào.\n",
    "\n",
    "Những phép toán này thường là một điệu nhảy tuyệt vời giữa:\n",
    "* Phép cộng\n",
    "* Phép trừ\n",
    "* Phép nhân (theo từng phần tử)\n",
    "* Phép chia\n",
    "* Phép nhân ma trận\n",
    "\n",
    "Và đó là tất cả. Chắc chắn còn có một vài phép toán khác ở đây và ở đó nhưng đây là những khối xây dựng cơ bản của mạng nơ-ron.\n",
    "\n",
    "Xếp chồng những khối xây dựng này theo cách đúng, bạn có thể tạo ra mạng nơ-ron tinh vi nhất (giống như lego!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sk_6Dd7L7Uce"
   },
   "source": [
    "### Các phép toán cơ bản\n",
    "\n",
    "Hãy bắt đầu với một vài phép toán cơ bản, phép cộng (`+`), phép trừ (`-`), phép nhân (`*`).\n",
    "\n",
    "Chúng hoạt động đúng như bạn nghĩ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X71WpQoPD7a4",
    "outputId": "ab30f13e-fc67-4ae4-c5ce-1006410dba07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of values and add a number to it\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sp4TlTWWEFeO",
    "outputId": "ce7d2296-881f-4eb3-802e-fd12bc25d6ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply it by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1VEHnuRkn8Q"
   },
   "source": [
    "Lưu ý cách các giá trị tensor ở trên không kết thúc bằng `tensor([110, 120, 130])`, điều này là do các giá trị bên trong tensor không thay đổi trừ khi chúng được gán lại."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XuB1UjCIEJIA",
    "outputId": "57cae862-c145-4681-d74b-fe6d77f2125a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensors don't change unless reassigned\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYvqGpUTk1o6"
   },
   "source": [
    "Hãy trừ một số và lần này chúng ta sẽ gán lại biến `tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U4iWKoLsENry",
    "outputId": "14d6771d-eb57-4b11-88a7-b1bb308ddc6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract and reassign\n",
    "tensor = tensor - 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFgZY-PaFNXa",
    "outputId": "3536ea54-a056-444c-cd5d-6d438ddda965"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add and reassign\n",
    "tensor = tensor + 10\n",
    "tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "CYXDoIOzk-6I"
   },
   "source": [
    "PyTorch cũng có một loạt các hàm tích hợp sẵn như [`torch.mul()`](https://pytorch.org/docs/stable/generated/torch.mul.html#torch.mul) (viết tắt của multiplication) và [`torch.add()`](https://pytorch.org/docs/stable/generated/torch.add.html) để thực hiện các phép toán cơ bản."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVysdk3kFWbY",
    "outputId": "3a5bf687-cf24-4224-9e76-975f84638ca8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also use torch functions\n",
    "torch.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IxuPJIpNFbqO",
    "outputId": "f04cafd9-eaea-4254-df1a-5ab3b524d74e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original tensor is still unchanged \n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70UNL33AlVQq"
   },
   "source": [
    "Tuy nhiên, việc sử dụng các ký hiệu toán tử như `*` thay vì `torch.mul()` phổ biến hơn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S5v3RkR0F2Jq",
    "outputId": "0137caab-5ea1-4d95-f4c5-a0baa0fd652d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication (each element multiplies its equivalent, index 0->0, 1->1, 2->2)\n",
    "print(tensor, \"*\", tensor)\n",
    "print(\"Equals:\", tensor * tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TT5fVuyu7q5z"
   },
   "source": [
    "### Phép nhân ma trận (là tất cả những gì bạn cần)\n",
    "\n",
    "Một trong những phép toán phổ biến nhất trong các thuật toán học máy và deep learning (như mạng nơ-ron) là [phép nhân ma trận](https://www.mathsisfun.com/algebra/matrix-multiplying.html).\n",
    "\n",
    "PyTorch triển khai chức năng nhân ma trận trong phương thức [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html).\n",
    "\n",
    "Hai quy tắc chính cho phép nhân ma trận cần nhớ là:\n",
    "\n",
    "1. **Các chiều trong** phải khớp:\n",
    "  * `(3, 2) @ (3, 2)` sẽ không hoạt động\n",
    "  * `(2, 3) @ (3, 2)` sẽ hoạt động\n",
    "  * `(3, 2) @ (2, 3)` sẽ hoạt động\n",
    "2. Ma trận kết quả có hình dạng của **các chiều ngoài**:\n",
    " * `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
    " * `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
    "\n",
    "> **Lưu ý:** \"`@`\" trong Python là ký hiệu cho phép nhân ma trận.\n",
    "\n",
    "> **Tài nguyên:** Bạn có thể xem tất cả các quy tắc cho phép nhân ma trận sử dụng `torch.matmul()` [trong tài liệu PyTorch](https://pytorch.org/docs/stable/generated/torch.matmul.html).\n",
    "\n",
    "Hãy tạo một tensor và thực hiện phép nhân theo từng phần tử và phép nhân ma trận trên nó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZE7loucmDlEM",
    "outputId": "44032bf9-c1f7-42fc-c842-dbe7a5c1221a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUAZ3_b0vOKv"
   },
   "source": [
    "Sự khác biệt giữa phép nhân theo từng phần tử và phép nhân ma trận là việc cộng các giá trị.\n",
    "\n",
    "Đối với biến `tensor` của chúng ta với các giá trị `[1, 2, 3]`:\n",
    "\n",
    "| Phép toán | Tính toán | Mã |\n",
    "| ----- | ----- | ----- |\n",
    "| **Phép nhân theo từng phần tử** | `[1*1, 2*2, 3*3]` = `[1, 4, 9]` | `tensor * tensor` |\n",
    "| **Phép nhân ma trận** | `[1*1 + 2*2 + 3*3]` = `[14]` | `tensor.matmul(tensor)` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i42gkUeHvI_1",
    "outputId": "18a630ce-bb56-4c40-81b4-9fdbb2ed7a4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element-wise matrix multiplication\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvCBiiTTDk8y",
    "outputId": "cf623247-8f1b-49f1-e788-16da3ed1e59c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4E_pROBDk2r",
    "outputId": "a09af00f-277b-479e-b0a2-ad6311ee5413"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also use the \"@\" symbol for matrix multiplication, though not recommended\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obbginUMv43A"
   },
   "source": [
    "Bạn có thể thực hiện phép nhân ma trận bằng tay nhưng không được khuyến nghị.\n",
    "\n",
    "Phương thức `torch.matmul()` tích hợp sẵn nhanh hơn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6qMSaLOoJscL",
    "outputId": "8bcad8a2-c900-4966-e13c-ff2cc02b9207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 773 µs, sys: 0 ns, total: 773 µs\n",
      "Wall time: 499 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Matrix multiplication by hand \n",
    "# (avoid doing operations with for loops at all cost, they are computationally expensive)\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "  value += tensor[i] * tensor[i]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vVWiKB0KwH74",
    "outputId": "fce58235-5c09-49ec-f34b-a90e5640281e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 146 µs, sys: 83 µs, total: 229 µs\n",
      "Wall time: 171 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJ4DDmo1TGe-"
   },
   "source": [
    "## Một trong những lỗi phổ biến nhất trong deep learning (lỗi shape)\n",
    "\n",
    "Bởi vì phần lớn deep learning là nhân và thực hiện các phép toán trên ma trận và ma trận có quy tắc nghiêm ngặt về hình dạng và kích thước nào có thể được kết hợp, một trong những lỗi phổ biến nhất bạn sẽ gặp trong deep learning là sự không khớp về shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "rN5RcoD4Jo6y",
    "outputId": "20f6c65b-86f4-4903-d253-f6cbf0583934"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb Cell 75\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y134sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m tensor_A \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y134sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                          [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y134sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m                          [\u001b[39m5\u001b[39m, \u001b[39m6\u001b[39m]], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y134sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m tensor_B \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m7\u001b[39m, \u001b[39m10\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y134sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m                          [\u001b[39m8\u001b[39m, \u001b[39m11\u001b[39m], \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y134sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m                          [\u001b[39m9\u001b[39m, \u001b[39m12\u001b[39m]], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y134sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m torch\u001b[39m.\u001b[39;49mmatmul(tensor_A, tensor_B)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes need to be in the right way  \n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "\n",
    "torch.matmul(tensor_A, tensor_B) # (this will error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNA6MZEFxWVt"
   },
   "source": [
    "Chúng ta có thể làm cho phép nhân ma trận hoạt động giữa `tensor_A` và `tensor_B` bằng cách làm cho các chiều trong của chúng khớp.\n",
    "\n",
    "Một trong những cách để làm điều này là với **transpose** (đổi chỗ các chiều của một tensor cho trước).\n",
    "\n",
    "Bạn có thể thực hiện transpose trong PyTorch bằng cách sử dụng:\n",
    "* `torch.transpose(input, dim0, dim1)` - trong đó `input` là tensor muốn transpose và `dim0` và `dim1` là các chiều sẽ được hoán đổi.\n",
    "* `tensor.T` - trong đó `tensor` là tensor muốn transpose.\n",
    "\n",
    "Hãy thử cách sau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lUqgaANiy1wq",
    "outputId": "e48bbf0c-8008-434e-d372-caa658b2f36b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7., 10.],\n",
      "        [ 8., 11.],\n",
      "        [ 9., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# View tensor_A and tensor_B\n",
    "print(tensor_A)\n",
    "print(tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DveqxO7iy_Fi",
    "outputId": "1bd2e85b-ea4d-4948-c408-8eb46ef3534c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# View tensor_A and tensor_B.T\n",
    "print(tensor_A)\n",
    "print(tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35rEIu-NKtVE",
    "outputId": "0b32c7f1-556e-45d4-de22-388419e93dc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "\n",
      "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
      "\n",
      "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
      "\n",
      "Output:\n",
      "\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# The operation works when tensor_B is transposed\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
    "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
    "print(\"Output:\\n\")\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output) \n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfcFEqfLjN24"
   },
   "source": [
    "Bạn cũng có thể sử dụng [`torch.mm()`](https://pytorch.org/docs/stable/generated/torch.mm.html) là viết tắt của `torch.matmul()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3rJvW_TTGe_",
    "outputId": "2c501972-20bf-4a83-ad4a-b5f1b2424097"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.,  30.,  33.],\n",
       "        [ 61.,  68.,  75.],\n",
       "        [ 95., 106., 117.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mm is a shortcut for matmul\n",
    "torch.mm(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXKozI4T0hFi"
   },
   "source": [
    "Không có transpose, các quy tắc của phép nhân ma trận không được thỏa mãn và chúng ta nhận được lỗi như ở trên.\n",
    "\n",
    "Còn một hình ảnh trực quan thì sao? \n",
    "\n",
    "![demo trực quan của phép nhân ma trận](https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/00-matrix-multiply-crop.gif)\n",
    "\n",
    "Bạn có thể tạo hình ảnh trực quan phép nhân ma trận của riêng mình như thế này tại http://matrixmultiplication.xyz/.\n",
    "\n",
    "> **Lưu ý:** Một phép nhân ma trận như thế này cũng được gọi là [**dot product**](https://www.mathsisfun.com/algebra/vectors-dot-product.html) của hai ma trận."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hA64Z4DmkB31"
   },
   "source": [
    "Mạng nơ-ron chứa đầy các phép nhân ma trận và dot products.\n",
    "\n",
    "Module [`torch.nn.Linear()`](https://pytorch.org/docs/1.9.1/generated/torch.nn.Linear.html) (chúng ta sẽ thấy điều này hoạt động sau), còn được gọi là feed-forward layer hoặc fully connected layer, triển khai một phép nhân ma trận giữa đầu vào `x` và ma trận trọng số `A`.\n",
    "\n",
    "$$\n",
    "y = x\\cdot{A^T} + b\n",
    "$$\n",
    "\n",
    "Trong đó:\n",
    "* `x` là đầu vào cho layer (deep learning là một chồng các layer như `torch.nn.Linear()` và các layer khác chồng lên nhau).\n",
    "* `A` là ma trận trọng số được tạo bởi layer, điều này bắt đầu như các số ngẫu nhiên được điều chỉnh khi mạng nơ-ron học để biểu diễn tốt hơn các mẫu trong dữ liệu (lưu ý \"`T`\", đó là vì ma trận trọng số được transpose).\n",
    "  * **Lưu ý:** Bạn cũng có thể thường thấy `W` hoặc chữ cái khác như `X` được sử dụng để thể hiện ma trận trọng số.\n",
    "* `b` là bias term được sử dụng để bù đắp nhẹ cho trọng số và đầu vào.\n",
    "* `y` là đầu ra (một thao tác của đầu vào với hy vọng khám phá các mẫu trong đó).\n",
    "\n",
    "Đây là một hàm tuyến tính (bạn có thể đã thấy một cái gì đó như $y = mx+b$ ở trường trung học hoặc ở nơi khác), và có thể được sử dụng để vẽ một đường thẳng!\n",
    "\n",
    "Hãy chơi với một linear layer.\n",
    "\n",
    "Thử thay đổi các giá trị của `in_features` và `out_features` bên dưới và xem điều gì xảy ra.\n",
    "\n",
    "Bạn có nhận thấy điều gì liên quan đến các hình dạng không?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mC_MjKW1LX7T",
    "outputId": "768f75d2-c978-4df3-e18a-4684d46bdfa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "\n",
      "Output:\n",
      "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
      "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
      "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "# Since the linear layer starts with a random weights matrix, let's make it reproducible (more on this later)\n",
    "torch.manual_seed(42)\n",
    "# This uses matrix multiplication\n",
    "linear = torch.nn.Linear(in_features=2, # in_features = matches inner dimension of input \n",
    "                         out_features=6) # out_features = describes outer value \n",
    "x = tensor_A\n",
    "output = linear(x)\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIGrP5j1pN7j"
   },
   "source": [
    "## Tổng hợp, min, max, mean, sum (aggregation)\n",
    "\n",
    "Thường khi làm việc với tensors, bạn có thể muốn làm một số tổng hợp các giá trị trong tensors (tìm giá trị tối thiểu, tối đa, trung bình, tổng, v.v.).\n",
    "\n",
    "Tôi thích gọi chúng là các phép toán tập hợp/tổng hợp (aggregation operations).\n",
    "\n",
    "Hãy tạo một tensor và thực hiện một số phép toán tổng hợp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPNF0nMWoGEj"
   },
   "source": [
    "Để tìm min, max, mean, sum, v.v. của một tensor, bạn có thể sử dụng `torch.min(tensor)`, `torch.max(tensor)`, `torch.mean(tensor)` và `torch.sum(tensor)` tương ứng.\n",
    "\n",
    "Hoặc bạn có thể sử dụng các phương thức tensor `tensor.min()`, `tensor.max()`, `tensor.mean()`, `tensor.sum()`.\n",
    "\n",
    "Cơ bản thì cả hai đều làm cùng một việc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjMmrJOOPv5e"
   },
   "source": [
    "Hoặc bạn có thể sử dụng phương thức tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrFQbe5fP1Rk",
    "outputId": "034013c1-b384-4a0d-edf8-295ed3a456f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-J-wfMdlsEco"
   },
   "source": [
    "Bây giờ hãy thực hiện một số phép tổng hợp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5wSP9YKP3Lb",
    "outputId": "3aa238c7-646f-434f-a55c-292aabef7227"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum: 0\n",
      "Maximum: 90\n",
      "Mean: 45.0\n",
      "Sum: 450\n"
     ]
    }
   ],
   "source": [
    "print(f\"Minimum: {x.min()}\")\n",
    "print(f\"Maximum: {x.max()}\")\n",
    "# print(f\"Mean: {x.mean()}\") # this will error\n",
    "print(f\"Mean: {x.type(torch.float32).mean()}\") # won't work without float datatype\n",
    "print(f\"Sum: {x.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHoKpsg3sKQE"
   },
   "source": [
    "> **Lưu ý:** Bạn có thể thấy một số phương thức như `torch.mean()` yêu cầu tensors phải ở `torch.float32` (phổ biến nhất) hoặc kiểu dữ liệu cụ thể khác, nếu không phép toán sẽ thất bại. \n",
    "\n",
    "Bạn cũng có thể làm tương tự như trên với các phương thức `torch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Cr23Y9uP3HO",
    "outputId": "9c86d805-eef2-465c-e2c8-2bccd515e6d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(0), tensor(45.), tensor(450))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7ApCaZjDkvp"
   },
   "source": [
    "### Vị trí min/max\n",
    "\n",
    "Bạn cũng có thể tìm chỉ mục của tensor nơi giá trị max hoặc minimum xuất hiện với [`torch.argmax()`](https://pytorch.org/docs/stable/generated/torch.argmax.html) và [`torch.argmin()`](https://pytorch.org/docs/stable/generated/torch.argmin.html) tương ứng.\n",
    "\n",
    "Điều này hữu ích trong trường hợp bạn chỉ muốn vị trí nơi giá trị cao nhất (hoặc thấp nhất) xuất hiện chứ không phải giá trị thực tế (chúng ta sẽ thấy điều này trong phần sau khi sử dụng [hàm kích hoạt softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FzNBl9JSGlHi",
    "outputId": "01e0740e-c34f-469b-9c8f-9e6e5f0363af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Index where max value occurs: 8\n",
      "Index where min value occurs: 0\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "tensor = torch.arange(10, 100, 10)\n",
    "print(f\"Tensor: {tensor}\")\n",
    "\n",
    "# Returns index of max and min values\n",
    "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
    "print(f\"Index where min value occurs: {tensor.argmin()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBu33WihOXBk"
   },
   "source": [
    "### Thay đổi kiểu dữ liệu tensor\n",
    "\n",
    "Như đã đề cập, một vấn đề phổ biến với các phép toán deep learning là có tensors trong các kiểu dữ liệu khác nhau.\n",
    "\n",
    "Nếu một tensor ở `torch.float64` và tensor khác ở `torch.float32`, bạn có thể gặp một số lỗi.\n",
    "\n",
    "Nhưng có một cách khắc phục.\n",
    "\n",
    "Bạn có thể thay đổi kiểu dữ liệu của tensors bằng [`torch.Tensor.type(dtype=None)`](https://pytorch.org/docs/stable/generated/torch.Tensor.type.html) trong đó tham số `dtype` là kiểu dữ liệu bạn muốn sử dụng.\n",
    "\n",
    "Đầu tiên chúng ta sẽ tạo một tensor và kiểm tra kiểu dữ liệu của nó (mặc định là `torch.float32`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rY2FEsCAOaLu",
    "outputId": "507f1ade-7c7a-4172-fa48-60c9ac4831c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor and check its datatype\n",
    "tensor = torch.arange(10., 100., 10.)\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jR30FHEc92of"
   },
   "source": [
    "Bây giờ chúng ta sẽ tạo một tensor khác giống như trước nhưng thay đổi kiểu dữ liệu thành `torch.float16`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cac8gRYjOeab",
    "outputId": "96e5ce12-bc29-4a2b-f81c-bfc89ea2d075"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a float16 tensor\n",
    "tensor_float16 = tensor.type(torch.float16)\n",
    "tensor_float16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndVlKJZ4-7_5"
   },
   "source": [
    "Và chúng ta có thể làm điều tương tự để tạo tensor `torch.int8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Yqovld2Oj6s",
    "outputId": "667da17f-e38f-404a-bd2d-63683e45c99a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an int8 tensor\n",
    "tensor_int8 = tensor.type(torch.int8)\n",
    "tensor_int8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44GxVabar-xe"
   },
   "source": [
    "> **Lưu ý:** Các kiểu dữ liệu khác nhau có thể gây nhầm lẫn ban đầu. Nhưng hãy nghĩ về nó như thế này, số càng thấp (ví dụ: 32, 16, 8), máy tính lưu trữ giá trị càng ít chính xác. Và với lượng lưu trữ thấp hơn, điều này thường dẫn đến tính toán nhanh hơn và mô hình tổng thể nhỏ hơn. Mạng nơ-ron dựa trên thiết bị di động thường hoạt động với số nguyên 8-bit, nhỏ hơn và chạy nhanh hơn nhưng ít chính xác hơn so với các đối tác float32 của chúng. Để biết thêm về điều này, tôi khuyên bạn nên đọc về [độ chính xác trong điện toán](https://en.wikipedia.org/wiki/Precision_(computer_science)).\n",
    "\n",
    "> **Bài tập:** Cho đến nay chúng ta đã đề cập khá nhiều phương thức tensor nhưng còn rất nhiều phương thức khác trong [tài liệu `torch.Tensor`](https://pytorch.org/docs/stable/tensors.html), tôi khuyên bạn nên dành 10 phút cuộn qua và xem bất cứ phương thức nào thu hút mắt bạn. Nhấp vào chúng và sau đó tự viết ra bằng mã để xem điều gì xảy ra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CkCtAYmGsHY"
   },
   "source": [
    "### Reshape, stack, squeeze và unsqueeze\n",
    "\n",
    "Thường xuyên bạn sẽ muốn reshape hoặc thay đổi chiều của tensors mà không thực sự thay đổi các giá trị bên trong chúng.\n",
    "\n",
    "Để làm như vậy, một số phương thức phổ biến là:\n",
    "\n",
    "| Phương thức | Mô tả một dòng |\n",
    "| ----- | ----- |\n",
    "| [`torch.reshape(input, shape)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) | Reshape `input` thành `shape` (nếu tương thích), cũng có thể sử dụng `torch.Tensor.reshape()`. |\n",
    "| [`Tensor.view(shape)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) | Trả về một view của tensor gốc với `shape` khác nhưng chia sẻ cùng dữ liệu với tensor gốc. |\n",
    "| [`torch.stack(tensors, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) | Nối một chuỗi `tensors` theo một chiều mới (`dim`), tất cả `tensors` phải có cùng kích thước. |\n",
    "| [`torch.squeeze(input)`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) | Squeeze `input` để loại bỏ tất cả các chiều có giá trị `1`. |\n",
    "| [`torch.unsqueeze(input, dim)`](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html) | Trả về `input` với giá trị chiều `1` được thêm vào `dim`. | \n",
    "| [`torch.permute(input, dims)`](https://pytorch.org/docs/stable/generated/torch.permute.html) | Trả về một *view* của `input` gốc với các chiều được hoán vị (sắp xếp lại) thành `dims`. | \n",
    "\n",
    "Tại sao phải làm những điều này?\n",
    "\n",
    "Bởi vì các mô hình deep learning (mạng nơ-ron) đều về việc thao tác tensors theo cách nào đó. Và do các quy tắc của phép nhân ma trận, nếu bạn có sự không khớp về shape, bạn sẽ gặp lỗi. Những phương thức này giúp bạn đảm bảo các phần tử đúng của tensors đang trộn với các phần tử đúng của tensors khác. \n",
    "\n",
    "Hãy thử chúng.\n",
    "\n",
    "Đầu tiên, chúng ta sẽ tạo một tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EYjRTLOzG4Ev",
    "outputId": "f7f2719c-15ce-406b-dc8f-4477046cd5d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "import torch\n",
    "x = torch.arange(1., 8.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_VarMO9CoT8"
   },
   "source": [
    "Bây giờ hãy thêm một chiều bổ sung với `torch.reshape()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "US4WjpQ3SG-8",
    "outputId": "c519d59e-85f1-4a10-eaaa-acb487028e3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1, 7)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tig5xm0jCxuU"
   },
   "source": [
    "Chúng ta cũng có thể thay đổi view với `torch.view()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDN2BNe5TGfB",
    "outputId": "3df1b0d6-2548-4ecc-ca25-0c4e28a6e536"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change view (keeps same data as original but changes view)\n",
    "# See more: https://stackoverflow.com/a/54507446/7900723\n",
    "z = x.view(1, 7)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8joAaUEC2NX"
   },
   "source": [
    "Tuy nhiên hãy nhớ rằng, thay đổi view của tensor với `torch.view()` thực sự chỉ tạo một view mới của *cùng* tensor.\n",
    "\n",
    "Vì vậy thay đổi view cũng thay đổi tensor gốc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2DxURVvXTGfC",
    "outputId": "668d194d-dd0a-4db1-da00-9c3fd8849186"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes x\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxnqDBlpDDJ_"
   },
   "source": [
    "Nếu chúng ta muốn xếp chồng tensor mới lên trên chính nó năm lần, chúng ta có thể làm như vậy với `torch.stack()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pX5Adf3ORiTK",
    "outputId": "703e8568-61df-4ebd-f4d3-a6366dc265c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0) # try changing dim to dim=1 and see what happens\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ET56QzNHDuOI"
   },
   "source": [
    "Còn việc loại bỏ tất cả các chiều đơn từ tensor thì sao?\n",
    "\n",
    "Để làm như vậy bạn có thể sử dụng `torch.squeeze()` (tôi nhớ điều này như việc *nén* tensor để chỉ có các chiều lớn hơn 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2Y2HEoDRxJZ",
    "outputId": "dd0645a6-1cdd-46bc-a3a2-433d9cd09336"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
      "Previous shape: torch.Size([1, 7])\n",
      "\n",
      "New tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
      "New shape: torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "# Remove extra dimension from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acjDLk8WD8NC"
   },
   "source": [
    "Và để làm ngược lại với `torch.squeeze()` bạn có thể sử dụng `torch.unsqueeze()` để thêm giá trị chiều 1 tại một chỉ mục cụ thể."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUC-DEEwSYv7",
    "outputId": "da60e019-3ea6-42f8-8e47-ba037ead737f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
      "Previous shape: torch.Size([7])\n",
      "\n",
      "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
      "New shape: torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "## Add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9DuJzXgFbM5"
   },
   "source": [
    "Bạn cũng có thể sắp xếp lại thứ tự các giá trị trục với `torch.permute(input, dims)`, trong đó `input` được chuyển thành một *view* với `dims` mới."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fCRGCX8DTGfC",
    "outputId": "6853328b-a1cf-4470-f366-106a231a189c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Create tensor with specific shape\n",
    "x_original = torch.rand(size=(224, 224, 3))\n",
    "\n",
    "# Permute the original tensor to rearrange the axis order\n",
    "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06LKaFemGBoE"
   },
   "source": [
    "> **Lưu ý**: Bởi vì permuting trả về một *view* (chia sẻ cùng dữ liệu với tensor gốc), các giá trị trong tensor được permuted sẽ giống với tensor gốc và nếu bạn thay đổi các giá trị trong view, nó sẽ thay đổi các giá trị của tensor gốc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEPqVL7fTGfC"
   },
   "source": [
    "## Lập chỉ mục (chọn dữ liệu từ tensors)\n",
    "\n",
    "Đôi khi bạn sẽ muốn chọn dữ liệu cụ thể từ tensors (ví dụ: chỉ cột đầu tiên hoặc hàng thứ hai).\n",
    "\n",
    "Để làm như vậy, bạn có thể sử dụng lập chỉ mục.\n",
    "\n",
    "Nếu bạn đã từng lập chỉ mục trên danh sách Python hoặc mảng NumPy, lập chỉ mục trong PyTorch với tensors rất tương tự."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oSXzdxCQTGfD",
    "outputId": "05a72c08-5f8c-433a-cd31-46065686f825"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hãy tạo một tensor 3-chiều và index trên nó.\n",
    "\n",
    "Lập chỉ mục các giá trị đi từ chiều ngoài -> chiều trong (hãy kiểm tra các dấu ngoặc vuông)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQG5krnKG43B"
   },
   "source": [
    "Lập chỉ mục các giá trị đi từ chiều ngoài -> chiều trong (hãy kiểm tra các dấu ngoặc vuông)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zv_Z3IAzTGfD",
    "outputId": "cf6c0936-7600-4af4-9b6f-f6b8ac9b4c05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First square bracket:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Second square bracket: tensor([1, 2, 3])\n",
      "Third square bracket: 1\n"
     ]
    }
   ],
   "source": [
    "# Let's index bracket by bracket\n",
    "print(f\"First square bracket:\\n{x[0]}\") \n",
    "print(f\"Second square bracket: {x[0][0]}\") \n",
    "print(f\"Third square bracket: {x[0][0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaLjaIFxHe89"
   },
   "source": [
    "Bạn cũng có thể sử dụng `:` để chỉ định \"tất cả giá trị trong chiều này\" và sau đó sử dụng dấu phẩy (`,`) để thêm chiều khác."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCT09pqeTGfD",
    "outputId": "a91f9b73-f8f0-476a-9c69-fcd03b042f6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th dimension and the 0 index of 1st dimension\n",
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwDx_gMsTGfD",
    "outputId": "8165cfd9-a88d-4212-8c45-1eb84ef5be83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th & 1st dimensions but only index 1 of 2nd dimension\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xiw3_1E3TGfD",
    "outputId": "12fa4749-cf52-4e88-c2c0-44d26aeb633c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFVEgrKhTGfD",
    "outputId": "69eadeb9-11b3-4b48-cb95-0b3305c1274c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension \n",
    "x[0, 0, :] # same as x[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Ik0r11RIxtm"
   },
   "source": [
    "Lập chỉ mục có thể khá gây nhầm lẫn ban đầu, đặc biệt với các tensors lớn hơn (tôi vẫn phải thử lập chỉ mục nhiều lần để làm đúng). Nhưng với một chút luyện tập và tuân theo phương châm của nhà thám hiểm dữ liệu (***trực quan hóa, trực quan hóa, trực quan hóa***), bạn sẽ bắt đầu nắm được."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8ZaW0Bq7rCm"
   },
   "source": [
    "## PyTorch tensors & NumPy\n",
    "\n",
    "Vì NumPy là một thư viện tính toán số học Python phổ biến, PyTorch có chức năng tương tác với nó một cách tốt đẹp.  \n",
    "\n",
    "Hai phương thức chính bạn sẽ muốn sử dụng để chuyển từ NumPy sang PyTorch (và ngược lại) là: \n",
    "* [`torch.from_numpy(ndarray)`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html) - NumPy array -> PyTorch tensor. \n",
    "* [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) - PyTorch tensor -> NumPy array.\n",
    "\n",
    "Hãy thử chúng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yDrDCnvY7rKS",
    "outputId": "86155a63-01f9-4372-e889-61a65ebf0fb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array to tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16JG6cONLPnO"
   },
   "source": [
    "> **Lưu ý:** Mặc định, các mảng NumPy được tạo với kiểu dữ liệu `float64` và nếu bạn chuyển đổi nó thành tensor PyTorch, nó sẽ giữ cùng kiểu dữ liệu (như trên). \n",
    ">\n",
    "> Tuy nhiên, nhiều phép tính PyTorch mặc định sử dụng `float32`. \n",
    "> \n",
    "> Vì vậy nếu bạn muốn chuyển đổi mảng NumPy (float64) -> tensor PyTorch (float64) -> tensor PyTorch (float32), bạn có thể sử dụng `tensor = torch.from_numpy(array).type(torch.float32)`.\n",
    "\n",
    "Bởi vì chúng ta đã gán lại `tensor` ở trên, nếu bạn thay đổi tensor, array vẫn giữ nguyên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ovwl7VCREv8L",
    "outputId": "efd21eb9-0010-436a-dc29-f851e3d7d77a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the array, keep the tensor\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geVvu1p0MTWc"
   },
   "source": [
    "Và nếu bạn muốn chuyển từ tensor PyTorch sang mảng NumPy, bạn có thể gọi `tensor.numpy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xw_7ZyVaTKxQ",
    "outputId": "54d6f347-d3f6-44df-9155-83d980c31780"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to NumPy array\n",
    "tensor = torch.ones(7) # create a tensor of ones with dtype=float32\n",
    "numpy_tensor = tensor.numpy() # will be dtype=float32 unless changed\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt8yEV1jMfi2"
   },
   "source": [
    "Và quy tắc tương tự áp dụng như trên, nếu bạn thay đổi `tensor` gốc, `numpy_tensor` mới vẫn giữ nguyên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mMp6ZSkET4_Y",
    "outputId": "100678a4-c220-4a44-e4a5-0542359cb9de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the tensor, keep the array the same\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gU3ubCrUkI-"
   },
   "source": [
    "## Tính tái tạo (cố gắng loại bỏ tính ngẫu nhiên khỏi ngẫu nhiên)\n",
    "\n",
    "Khi bạn tìm hiểu thêm về mạng nơ-ron và học máy, bạn sẽ bắt đầu khám phá ra tính ngẫu nhiên đóng vai trò quan trọng như thế nào.\n",
    "\n",
    "Vâng, đó là tính giả ngẫu nhiên. Bởi vì suy cho cùng, theo cách chúng được thiết kế, máy tính về cơ bản là xác định (mỗi bước đều có thể dự đoán được) vì vậy tính ngẫu nhiên mà chúng tạo ra là tính ngẫu nhiên mô phỏng (mặc dù cũng có tranh luận về điều này, nhưng vì tôi không phải là nhà khoa học máy tính, tôi sẽ để bạn tự tìm hiểu thêm).\n",
    "\n",
    "Điều này liên quan đến mạng nơ-ron và deep learning như thế nào?\n",
    "\n",
    "Chúng ta đã thảo luận về việc mạng nơ-ron bắt đầu với các số ngẫu nhiên để mô tả các mẫu trong dữ liệu (những số này là mô tả kém) và cố gắng cải thiện những số ngẫu nhiên đó bằng cách sử dụng các phép toán tensor (và một vài thứ khác mà chúng ta chưa thảo luận) để mô tả tốt hơn các mẫu trong dữ liệu.\n",
    "\n",
    "Tóm lại: \n",
    "\n",
    "``bắt đầu với số ngẫu nhiên -> phép toán tensor -> cố gắng làm tốt hơn (lặp đi lặp lại)``\n",
    "\n",
    "Mặc dù tính ngẫu nhiên tốt và mạnh mẽ, đôi khi bạn muốn có ít tính ngẫu nhiên hơn.\n",
    "\n",
    "Tại sao?\n",
    "\n",
    "Để bạn có thể thực hiện các thí nghiệm lặp lại được.\n",
    "\n",
    "Ví dụ, bạn tạo một thuật toán có thể đạt được hiệu suất X.\n",
    "\n",
    "Và sau đó bạn bè của bạn thử nó để xác minh bạn không điên.\n",
    "\n",
    "Họ có thể làm điều đó như thế nào?\n",
    "\n",
    "Đó là lúc **tính tái tạo** xuất hiện.\n",
    "\n",
    "Nói cách khác, bạn có thể có được kết quả giống nhau (hoặc rất tương tự) trên máy tính của bạn chạy cùng mã với những gì tôi có trên máy của tôi không?\n",
    "\n",
    "Hãy xem một ví dụ ngắn về tính tái tạo trong PyTorch.\n",
    "\n",
    "Chúng ta sẽ bắt đầu bằng cách tạo hai tensor ngẫu nhiên, vì chúng ngẫu nhiên, bạn mong đợi chúng khác nhau phải không?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSwxnwEbTGfF",
    "outputId": "73b34154-734f-496f-9b55-b6aaa137e854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A:\n",
      "tensor([[0.8016, 0.3649, 0.6286, 0.9663],\n",
      "        [0.7687, 0.4566, 0.5745, 0.9200],\n",
      "        [0.3230, 0.8613, 0.0919, 0.3102]])\n",
      "\n",
      "Tensor B:\n",
      "tensor([[0.9536, 0.6002, 0.0351, 0.6826],\n",
      "        [0.3743, 0.5220, 0.1336, 0.9666],\n",
      "        [0.9754, 0.8474, 0.8988, 0.1105]])\n",
      "\n",
      "Does Tensor A equal Tensor B? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create two random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
    "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
    "print(f\"Does Tensor A equal Tensor B? (anywhere)\")\n",
    "random_tensor_A == random_tensor_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPU6mDKJnr8M"
   },
   "source": [
    "Đúng như bạn có thể mong đợi, các tensors ra với các giá trị khác nhau.\n",
    "\n",
    "Nhưng nếu bạn muốn tạo hai tensor ngẫu nhiên với các giá trị *giống nhau* thì sao.\n",
    "\n",
    "Tức là, các tensors vẫn sẽ chứa các giá trị ngẫu nhiên nhưng chúng sẽ có cùng hương vị.\n",
    "\n",
    "Đó là lúc [`torch.manual_seed(seed)`](https://pytorch.org/docs/stable/generated/torch.manual_seed.html) xuất hiện, trong đó `seed` là một số nguyên (như `42` nhưng có thể là bất cứ gì) tạo hương vị cho tính ngẫu nhiên.\n",
    "\n",
    "Hãy thử bằng cách tạo một số tensor ngẫu nhiên *có hương vị*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sB6d1GfYTGfF",
    "outputId": "4d11d38e-4406-4aff-9a81-cf13aa89ee5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor C:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Tensor D:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Does Tensor C equal Tensor D? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "# # Set the random seed\n",
    "RANDOM_SEED=42 # try changing this to different values and see what happens to the numbers below\n",
    "torch.manual_seed(seed=RANDOM_SEED) \n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "# Have to reset the seed every time a new rand() is called \n",
    "# Without this, tensor_D would be different to tensor_C \n",
    "torch.random.manual_seed(seed=RANDOM_SEED) # try commenting this line out and seeing what happens\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
    "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
    "print(f\"Does Tensor C equal Tensor D? (anywhere)\")\n",
    "random_tensor_C == random_tensor_D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uct53Xr5QRC_"
   },
   "source": [
    "Tuyệt!\n",
    "\n",
    "Có vẻ như việc thiết lập seed đã hoạt động. \n",
    "\n",
    "> **Tài nguyên:** Những gì chúng ta vừa đề cập chỉ chạm vào bề mặt của tính tái tạo trong PyTorch. Để biết thêm về tính tái tạo nói chung và random seeds, tôi khuyên bạn nên xem:\n",
    "> * [Tài liệu tính tái tạo PyTorch](https://pytorch.org/docs/stable/notes/randomness.html) (một bài tập tốt sẽ là đọc qua điều này trong 10 phút và ngay cả khi bạn không hiểu nó bây giờ, việc nhận biết nó là quan trọng).\n",
    "> * [Trang Wikipedia về random seed](https://en.wikipedia.org/wiki/Random_seed) (điều này sẽ cung cấp cái nhìn tổng quan tốt về random seeds và tính giả ngẫu nhiên nói chung)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxIIM7t27rQ-"
   },
   "source": [
    "## Chạy tensors trên GPUs (và tính toán nhanh hơn)\n",
    "\n",
    "Các thuật toán deep learning yêu cầu rất nhiều phép toán số học.\n",
    "\n",
    "Và mặc định những phép toán này thường được thực hiện trên CPU (computer processing unit).\n",
    "\n",
    "Tuy nhiên, có một phần cứng phổ biến khác gọi là GPU (graphics processing unit), thường nhanh hơn nhiều trong việc thực hiện các loại phép toán cụ thể mà mạng nơ-ron cần (phép nhân ma trận) so với CPU.\n",
    "\n",
    "Máy tính của bạn có thể có một cái.\n",
    "\n",
    "Nếu có, bạn nên tìm cách sử dụng nó bất cứ khi nào có thể để huấn luyện mạng nơ-ron vì có khả năng nó sẽ tăng tốc thời gian huấn luyện đáng kể.\n",
    "\n",
    "Có một vài cách để đầu tiên có quyền truy cập vào GPU và thứ hai là làm cho PyTorch sử dụng GPU.\n",
    "\n",
    "> **Lưu ý:** Khi tôi tham chiếu \"GPU\" trong suốt khóa học này, tôi đang tham chiếu một [Nvidia GPU với CUDA](https://developer.nvidia.com/cuda-gpus) được bật (CUDA là một nền tảng tính toán và API giúp cho phép GPUs được sử dụng cho tính toán mục đích chung & không chỉ đồ họa) trừ khi được chỉ định khác."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UiR6QpoYQH_"
   },
   "source": [
    "### 1. Có GPU\n",
    "\n",
    "Bạn có thể đã biết điều gì đang xảy ra khi tôi nói GPU. Nhưng nếu không, có một vài cách để có quyền truy cập vào một cái.\n",
    "\n",
    "| **Phương pháp** | **Độ khó cài đặt** | **Ưu điểm** | **Nhược điểm** | **Cách cài đặt** |\n",
    "| ----- | ----- | ----- | ----- | ----- |\n",
    "| Google Colab | Dễ | Miễn phí sử dụng, gần như không cần cài đặt, có thể chia sẻ công việc với người khác dễ dàng như một link | Không lưu đầu ra dữ liệu của bạn, tính toán hạn chế, có thể bị timeout | [Theo dõi Hướng dẫn Google Colab](https://colab.research.google.com/notebooks/gpu.ipynb) |\n",
    "| Sử dụng của riêng bạn | Trung bình | Chạy mọi thứ cục bộ trên máy của riêng bạn | GPUs không miễn phí, yêu cầu chi phí trả trước | Theo dõi [hướng dẫn cài đặt PyTorch](https://pytorch.org/get-started/locally/) |\n",
    "| Cloud computing (AWS, GCP, Azure) | Trung bình-Khó | Chi phí trả trước nhỏ, truy cập vào tính toán gần như vô hạn | Có thể trở nên đắt đỏ nếu chạy liên tục, mất thời gian để cài đặt đúng | Theo dõi [hướng dẫn cài đặt PyTorch](https://pytorch.org/get-started/cloud-partners/) |\n",
    "\n",
    "Có nhiều tùy chọn khác để sử dụng GPUs nhưng ba cái trên sẽ đủ cho bây giờ.\n",
    "\n",
    "Cá nhân, tôi sử dụng kết hợp Google Colab và máy tính cá nhân của riêng tôi cho các thí nghiệm quy mô nhỏ (và tạo khóa học này) và chuyển sang tài nguyên cloud khi tôi cần nhiều sức mạnh tính toán hơn.\n",
    "\n",
    "> **Tài nguyên:** Nếu bạn đang muốn mua GPU của riêng mình nhưng không chắc nên mua gì, [Tim Dettmers có một hướng dẫn xuất sắc](https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/).\n",
    "\n",
    "Để kiểm tra xem bạn có quyền truy cập vào Nvidia GPU không, bạn có thể chạy `!nvidia-smi` trong đó `!` (còn gọi là bang) có nghĩa là \"chạy điều này trên command line\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vEMcO-9zYc-w",
    "outputId": "77405db7-3494-4add-cfc7-8415e52a0412"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jan 21 08:34:23 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA TITAN RTX    On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| 40%   30C    P8     7W / 280W |    177MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1061      G   /usr/lib/xorg/Xorg                 53MiB |\n",
      "|    0   N/A  N/A   2671131      G   /usr/lib/xorg/Xorg                 97MiB |\n",
      "|    0   N/A  N/A   2671256      G   /usr/bin/gnome-shell                9MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvkB9p5zYf8E"
   },
   "source": [
    "Nếu bạn không có Nvidia GPU có thể truy cập, lệnh trên sẽ xuất ra một cái gì đó như:\n",
    "\n",
    "```\n",
    "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
    "```\n",
    "\n",
    "Trong trường hợp đó, hãy quay lại và làm theo các bước cài đặt.\n",
    "\n",
    "Nếu bạn có GPU, dòng trên sẽ xuất ra một cái gì đó như:\n",
    "\n",
    "```\n",
    "Wed Jan 19 22:09:08 2022       \n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
    "| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "                                                                               \n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                                  |\n",
    "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "|        ID   ID                                                   Usage      |\n",
    "|=============================================================================|\n",
    "|  No running processes found                                                 |\n",
    "+-----------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvibZ6e0YcDk"
   },
   "source": [
    "### 2. Làm cho PyTorch chạy trên GPU\n",
    "\n",
    "Một khi bạn đã có GPU sẵn sàng để truy cập, bước tiếp theo là làm cho PyTorch sử dụng để lưu trữ dữ liệu (tensors) và tính toán trên dữ liệu (thực hiện các phép toán trên tensors).\n",
    "\n",
    "Để làm như vậy, bạn có thể sử dụng gói [`torch.cuda`](https://pytorch.org/docs/stable/cuda.html).\n",
    "\n",
    "Thay vì nói về nó, hãy thử nó.\n",
    "\n",
    "Bạn có thể kiểm tra xem PyTorch có quyền truy cập vào GPU bằng cách sử dụng [`torch.cuda.is_available()`](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OweDLgwjEvZ2",
    "outputId": "3a278a24-3ec3-4b1f-8f96-298086fa6ea6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jedZcx2PZFpL"
   },
   "source": [
    "Nếu lệnh trên xuất ra `True`, PyTorch có thể thấy và sử dụng GPU, nếu nó xuất ra `False`, nó không thể thấy GPU và trong trường hợp đó, bạn sẽ phải quay lại qua các bước cài đặt.\n",
    "\n",
    "Bây giờ, giả sử bạn muốn thiết lập mã của mình để nó chạy trên CPU *hoặc* GPU nếu có sẵn.\n",
    "\n",
    "Theo cách đó, nếu bạn hoặc ai đó quyết định chạy mã của bạn, nó sẽ hoạt động bất kể thiết bị tính toán họ đang sử dụng. \n",
    "\n",
    "Hãy tạo biến `device` để lưu trữ loại thiết bị nào có sẵn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "j92HBCKB7rYa",
    "outputId": "8cca1643-645c-4b67-f1f5-37066f6b9549"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device type\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjFyPP2WaCch"
   },
   "source": [
    "Nếu lệnh trên xuất ra `\"cuda\"` có nghĩa là chúng ta có thể thiết lập tất cả mã PyTorch để sử dụng thiết bị CUDA có sẵn (một GPU) và nếu nó xuất ra `\"cpu\"`, mã PyTorch của chúng ta sẽ sử dụng CPU.\n",
    "\n",
    "> **Lưu ý:** Trong PyTorch, thực hành tốt nhất là viết [**mã không phụ thuộc thiết bị**](https://pytorch.org/docs/master/notes/cuda.html#device-agnostic-code). Điều này có nghĩa là mã sẽ chạy trên CPU (luôn có sẵn) hoặc GPU (nếu có sẵn).\n",
    "\n",
    "Nếu bạn muốn tính toán nhanh hơn, bạn có thể sử dụng GPU nhưng nếu bạn muốn tính toán *nhanh hơn nhiều*, bạn có thể sử dụng nhiều GPUs.\n",
    "\n",
    "Bạn có thể đếm số GPUs mà PyTorch có quyền truy cập bằng cách sử dụng [`torch.cuda.device_count()`](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda.device_count)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MArsn0DFTGfG",
    "outputId": "de717df5-bb67-4900-805e-a6f00ad0b409"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVNf1hiqa-gO"
   },
   "source": [
    "Biết số GPUs mà PyTorch có quyền truy cập là hữu ích trong trường hợp bạn muốn chạy một quy trình cụ thể trên một GPU và quy trình khác trên GPU khác (PyTorch cũng có các tính năng để cho phép bạn chạy một quy trình trên *tất cả* GPUs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Làm PyTorch chạy trên Apple Silicon\n",
    "\n",
    "Để chạy PyTorch trên GPUs M1/M2/M3 của Apple, bạn có thể sử dụng module [`torch.backends.mps`](https://pytorch.org/docs/stable/notes/mps.html).\n",
    "\n",
    "Hãy đảm bảo rằng các phiên bản macOS và Pytorch được cập nhật."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Apple Silicon GPU\n",
    "import torch\n",
    "torch.backends.mps.is_available() # Note this will print false if you're not running on a Mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device type\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như trước, nếu lệnh trên xuất ra `\"mps\"` có nghĩa là chúng ta có thể thiết lập tất cả mã PyTorch để sử dụng GPU Apple Silicon có sẵn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" # Use NVIDIA GPU (if available)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\" # Use Apple Silicon GPU (if available)\n",
    "else:\n",
    "    device = \"cpu\" # Default to CPU if no GPU is available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqQLcuj68OA-"
   },
   "source": [
    "### 3. Đưa tensors (và models) lên GPU\n",
    "\n",
    "Bạn có thể đưa tensors (và models, chúng ta sẽ thấy điều này sau) lên một thiết bị cụ thể bằng cách gọi [`to(device)`](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html) trên chúng. Trong đó `device` là thiết bị đích mà bạn muốn tensor (hoặc model) chuyển đến.\n",
    "\n",
    "Tại sao làm điều này?\n",
    "\n",
    "GPUs cung cấp tính toán số học nhanh hơn rất nhiều so với CPUs và nếu GPU không có sẵn, do **mã không phụ thuộc thiết bị** của chúng ta (xem ở trên), nó sẽ chạy trên CPU.\n",
    "\n",
    "> **Lưu ý:** Đưa tensor lên GPU bằng cách sử dụng `to(device)` (ví dụ: `some_tensor.to(device)`) trả về một bản sao của tensor đó, tức là cùng một tensor sẽ ở trên cả CPU và GPU. Để ghi đè tensors, hãy gán lại chúng:\n",
    ">\n",
    "> `some_tensor = some_tensor.to(device)`\n",
    "\n",
    "Hãy thử tạo một tensor và đưa nó lên GPU (nếu có sẵn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FhI3srFXEHfP",
    "outputId": "2f4f6435-fdc4-4e99-e87c-9421c2100f36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='mps:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor (default on CPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Tensor not on GPU\n",
    "print(tensor, tensor.device)\n",
    "\n",
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxXeRKO0TGfG"
   },
   "source": [
    "Nếu bạn có GPU có sẵn, mã trên sẽ xuất ra một cái gì đó như:\n",
    "\n",
    "```\n",
    "tensor([1, 2, 3]) cpu\n",
    "tensor([1, 2, 3], device='cuda:0')\n",
    "```\n",
    "\n",
    "Lưu ý tensor thứ hai có `device='cuda:0'`, điều này có nghĩa là nó được lưu trữ trên GPU thứ 0 có sẵn (GPUs được indexed từ 0, nếu hai GPUs có sẵn, chúng sẽ là `'cuda:0'` và `'cuda:1'` tương ứng, lên đến `'cuda:n'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4puyUX4Bci5D"
   },
   "source": [
    "### 4. Chuyển tensors trở lại CPU\n",
    "\n",
    "Nếu chúng ta muốn chuyển tensor trở lại CPU thì sao?\n",
    "\n",
    "Ví dụ, bạn sẽ muốn làm điều này nếu bạn muốn tương tác với tensors của mình với NumPy (NumPy không tận dụng GPU).\n",
    "\n",
    "Hãy thử sử dụng phương thức [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) trên `tensor_on_gpu` của chúng ta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "id": "3ChSLJgPTGfG",
    "outputId": "32e92f62-db28-4dc7-ce93-c2ab33229252"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb Cell 157\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y312sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# If tensor is on GPU, can't transform it to NumPy (this will error)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y312sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m tensor_on_gpu\u001b[39m.\u001b[39;49mnumpy()\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# If tensor is on GPU, can't transform it to NumPy (this will error)\n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhymtkRDTGfG"
   },
   "source": [
    "Thay vào đó, để có tensor trở lại CPU và có thể sử dụng được với NumPy, chúng ta có thể sử dụng [`Tensor.cpu()`](https://pytorch.org/docs/stable/generated/torch.Tensor.cpu.html).\n",
    "\n",
    "Điều này sao chép tensor vào bộ nhớ CPU để nó có thể sử dụng được với CPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gN15s-NdTGfG",
    "outputId": "9fffb6f2-c200-4f9c-d987-d9ab5d9cba49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead, copy the tensor back to cpu\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyzNH5lrTGfH"
   },
   "source": [
    "Lệnh trên trả về một bản sao của tensor GPU trong bộ nhớ CPU vì vậy tensor gốc vẫn ở trên GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S5u83PCRTGfH",
    "outputId": "4cb931e2-7c8d-49b9-a7de-db3d3c6589b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlmBpnuPTGfH"
   },
   "source": [
    "## Bài tập\n",
    "\n",
    "Tất cả các bài tập đều tập trung vào việc luyện tập mã ở trên.\n",
    "\n",
    "Bạn sẽ có thể hoàn thành chúng bằng cách tham khảo từng phần hoặc theo (các) tài nguyên được liên kết.\n",
    "\n",
    "**Tài nguyên:**\n",
    "\n",
    "* [Notebook template bài tập cho 00](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/00_pytorch_fundamentals_exercises.ipynb).\n",
    "* [Notebook lời giải ví dụ cho 00](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/00_pytorch_fundamentals_exercise_solutions.ipynb) (hãy thử các bài tập *trước khi* xem cái này).\n",
    "\n",
    "1. Đọc tài liệu - Một phần lớn của deep learning (và học lập trình nói chung) là làm quen với tài liệu của framework cụ thể mà bạn đang sử dụng. Chúng ta sẽ sử dụng tài liệu PyTorch rất nhiều trong suốt phần còn lại của khóa học này. Vì vậy tôi khuyên bạn nên dành 10 phút đọc những điều sau (không sao nếu bạn không hiểu một số thứ ngay bây giờ, trọng tâm chưa phải là hiểu đầy đủ, mà là nhận thức). Xem tài liệu về [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch-tensor) và cho [`torch.cuda`](https://pytorch.org/docs/master/notes/cuda.html#cuda-semantics).\n",
    "2. Tạo một tensor ngẫu nhiên với shape `(7, 7)`.\n",
    "3. Thực hiện phép nhân ma trận trên tensor từ 2 với một tensor ngẫu nhiên khác có shape `(1, 7)` (gợi ý: bạn có thể phải transpose tensor thứ hai).\n",
    "4. Đặt random seed thành `0` và làm lại bài tập 2 & 3.\n",
    "5. Nói về random seeds, chúng ta đã thấy cách đặt nó với `torch.manual_seed()` nhưng có tương đương GPU không? (gợi ý: bạn sẽ cần xem vào tài liệu cho `torch.cuda` cho cái này). Nếu có, đặt GPU random seed thành `1234`.\n",
    "6. Tạo hai tensor ngẫu nhiên có shape `(2, 3)` và gửi cả hai lên GPU (bạn sẽ cần quyền truy cập vào GPU cho việc này). Đặt `torch.manual_seed(1234)` khi tạo tensors (điều này không cần phải là GPU random seed).\n",
    "7. Thực hiện phép nhân ma trận trên các tensors bạn đã tạo ở 6 (một lần nữa, bạn có thể phải điều chỉnh shapes của một trong các tensors).\n",
    "8. Tìm giá trị maximum và minimum của đầu ra của 7.\n",
    "9. Tìm các giá trị chỉ mục maximum và minimum của đầu ra của 7.\n",
    "10. Tạo một tensor ngẫu nhiên với shape `(1, 1, 1, 10)` và sau đó tạo một tensor mới với tất cả các chiều `1` được loại bỏ để còn lại một tensor có shape `(10)`. Đặt seed thành `7` khi bạn tạo nó và in ra tensor đầu tiên và shape của nó cũng như tensor thứ hai và shape của nó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlmBpnuPTGfH"
   },
   "source": [
    "## Ngoại khóa\n",
    "\n",
    "* Dành 1 giờ đi qua [tutorial cơ bản PyTorch](https://pytorch.org/tutorials/beginner/basics/intro.html) (tôi khuyên các phần [Quickstart](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html) và [Tensors](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)).\n",
    "* Để tìm hiểu thêm về cách một tensor có thể biểu diễn dữ liệu, xem video này: [What's a tensor?](https://youtu.be/f5liqUk0ZTw)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "00_pytorch_fundamentals.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "3fbe1355223f7b2ffc113ba3ade6a2b520cadace5d5ec3e828c83ce02eb221bf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
